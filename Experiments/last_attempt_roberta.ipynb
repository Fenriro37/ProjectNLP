{
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 7435709,
          "sourceType": "datasetVersion",
          "datasetId": 4327472
        },
        {
          "sourceId": 7562301,
          "sourceType": "datasetVersion",
          "datasetId": 4403347
        },
        {
          "sourceId": 7571998,
          "sourceType": "datasetVersion",
          "datasetId": 4408101
        }
      ],
      "dockerImageVersionId": 30648,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5df5257ed0584335bb0d0fa6ead90232": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c382c40bc1ca4a269224acff1d8135b6",
              "IPY_MODEL_20248e31c2af48b795bf46cad97e494a",
              "IPY_MODEL_92f2c5dab3e94b1481362d475e2797a0"
            ],
            "layout": "IPY_MODEL_781eb3b4bf9947eba38d250601aed229"
          }
        },
        "c382c40bc1ca4a269224acff1d8135b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_38ebba9ac34e414086b28c1c61b1ef18",
            "placeholder": "​",
            "style": "IPY_MODEL_73c7c68486e6469687a3afef60f24ec9",
            "value": "config.json: 100%"
          }
        },
        "20248e31c2af48b795bf46cad97e494a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ad1a8b6906eb4fcfa5cd99f50b77744a",
            "max": 481,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dda29232ad9c404b9a8a4c375137bdc8",
            "value": 481
          }
        },
        "92f2c5dab3e94b1481362d475e2797a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_380b56151f9649ed82657007d5ae1de2",
            "placeholder": "​",
            "style": "IPY_MODEL_595b4334333a4a93a09b1c4beb01b756",
            "value": " 481/481 [00:00&lt;00:00, 21.9kB/s]"
          }
        },
        "781eb3b4bf9947eba38d250601aed229": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "38ebba9ac34e414086b28c1c61b1ef18": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "73c7c68486e6469687a3afef60f24ec9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ad1a8b6906eb4fcfa5cd99f50b77744a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dda29232ad9c404b9a8a4c375137bdc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "380b56151f9649ed82657007d5ae1de2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "595b4334333a4a93a09b1c4beb01b756": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "74f20d1d232a4f5082e7527701259a23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3536a11e012c46a0af99b997656f1238",
              "IPY_MODEL_68e1fe7e231945fdb6f7d7700027d1ff",
              "IPY_MODEL_27f646ed9958421e8901c4c0266df159"
            ],
            "layout": "IPY_MODEL_ba0cb34514ad428598e5b9dd4339ea73"
          }
        },
        "3536a11e012c46a0af99b997656f1238": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d010fa40e5cc48e59394c3e352f3945a",
            "placeholder": "​",
            "style": "IPY_MODEL_43c2adeaddb14a26878b643248dbc314",
            "value": "vocab.json: 100%"
          }
        },
        "68e1fe7e231945fdb6f7d7700027d1ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_db4232ba1f844ff5b7af419a3317019a",
            "max": 898823,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_79adb14a257e42179e83e81c81cd453e",
            "value": 898823
          }
        },
        "27f646ed9958421e8901c4c0266df159": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e4175f6fc727416787ebf08f71de0db2",
            "placeholder": "​",
            "style": "IPY_MODEL_cc94bd5ac1224a0eb6f8471655b85fb5",
            "value": " 899k/899k [00:00&lt;00:00, 12.5MB/s]"
          }
        },
        "ba0cb34514ad428598e5b9dd4339ea73": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d010fa40e5cc48e59394c3e352f3945a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "43c2adeaddb14a26878b643248dbc314": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "db4232ba1f844ff5b7af419a3317019a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "79adb14a257e42179e83e81c81cd453e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e4175f6fc727416787ebf08f71de0db2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc94bd5ac1224a0eb6f8471655b85fb5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e0b430182c42479eabc9ec50a6ebf383": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a38961d7e7064e50a2f2279f80a61883",
              "IPY_MODEL_201632ae0d6845c9b98958ca2f51848c",
              "IPY_MODEL_f1f4b9f7b83345f88d05d61d1a7714df"
            ],
            "layout": "IPY_MODEL_4f2f56a288684038969c9106ea606839"
          }
        },
        "a38961d7e7064e50a2f2279f80a61883": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2570888de769491594d30b7128613083",
            "placeholder": "​",
            "style": "IPY_MODEL_d127286d7edd40cb960a8ec60d339dc7",
            "value": "merges.txt: 100%"
          }
        },
        "201632ae0d6845c9b98958ca2f51848c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_49b1c1222a1846cf8e72ede74ebec848",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d219f9c923944b07aa62c75189c5de1d",
            "value": 456318
          }
        },
        "f1f4b9f7b83345f88d05d61d1a7714df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1395a4b9c8534636aba51520ba1f8f2a",
            "placeholder": "​",
            "style": "IPY_MODEL_95be59ae7c174fd9b396c5d0672cbbae",
            "value": " 456k/456k [00:00&lt;00:00, 24.7MB/s]"
          }
        },
        "4f2f56a288684038969c9106ea606839": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2570888de769491594d30b7128613083": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d127286d7edd40cb960a8ec60d339dc7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "49b1c1222a1846cf8e72ede74ebec848": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d219f9c923944b07aa62c75189c5de1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1395a4b9c8534636aba51520ba1f8f2a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "95be59ae7c174fd9b396c5d0672cbbae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "00c98afa25da42a98955de93296f6b62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d5f48be9176d4ff0bf4a0f8ab74cd13d",
              "IPY_MODEL_e5b7aa254a534741975a57a5c54cd504",
              "IPY_MODEL_77b9be9c9b0b49fa84e0d79400e4b318"
            ],
            "layout": "IPY_MODEL_554bcfa289fc4c6287c62c66f2ce2c68"
          }
        },
        "d5f48be9176d4ff0bf4a0f8ab74cd13d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d98e2510b9f44908854e286cf3fc65b5",
            "placeholder": "​",
            "style": "IPY_MODEL_e733672c1b284412b6cdde467e2e9bd4",
            "value": "tokenizer.json: 100%"
          }
        },
        "e5b7aa254a534741975a57a5c54cd504": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f76e0d67b763467fbe5e8d51b65666ab",
            "max": 1355863,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3166b97bdd1343e3b846daf079939b80",
            "value": 1355863
          }
        },
        "77b9be9c9b0b49fa84e0d79400e4b318": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3d1050cb39414a099a70adce939260ce",
            "placeholder": "​",
            "style": "IPY_MODEL_99613caedb6d4206957df14a313e1810",
            "value": " 1.36M/1.36M [00:00&lt;00:00, 12.8MB/s]"
          }
        },
        "554bcfa289fc4c6287c62c66f2ce2c68": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d98e2510b9f44908854e286cf3fc65b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e733672c1b284412b6cdde467e2e9bd4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f76e0d67b763467fbe5e8d51b65666ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3166b97bdd1343e3b846daf079939b80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3d1050cb39414a099a70adce939260ce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "99613caedb6d4206957df14a313e1810": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e1c2ded6f02e4431b89de086eeeb304b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6b5dc8302417496d9fe559cca0719462",
              "IPY_MODEL_97dd83365d57470cb7077091961b54f0",
              "IPY_MODEL_ab71628150384c19b8a613e1ba5c8db0"
            ],
            "layout": "IPY_MODEL_8d49c8c7ef324becb418bd91a669d411"
          }
        },
        "6b5dc8302417496d9fe559cca0719462": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f6f0fac7dd4345f9a9f4e2774a488c9a",
            "placeholder": "​",
            "style": "IPY_MODEL_868abc7f8e3d4261a635e5d97c5de07d",
            "value": "model.safetensors: 100%"
          }
        },
        "97dd83365d57470cb7077091961b54f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fafaef3c6398457e9366e2b048ac2ed0",
            "max": 498818054,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e604978c15c4493bb0424196bffd5def",
            "value": 498818054
          }
        },
        "ab71628150384c19b8a613e1ba5c8db0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b783d978c5294b6c98a1dba1aee902ef",
            "placeholder": "​",
            "style": "IPY_MODEL_dc71a963770241668a8a571a898b9468",
            "value": " 499M/499M [00:02&lt;00:00, 187MB/s]"
          }
        },
        "8d49c8c7ef324becb418bd91a669d411": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f6f0fac7dd4345f9a9f4e2774a488c9a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "868abc7f8e3d4261a635e5d97c5de07d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fafaef3c6398457e9366e2b048ac2ed0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e604978c15c4493bb0424196bffd5def": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b783d978c5294b6c98a1dba1aee902ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc71a963770241668a8a571a898b9468": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#!pip install torch==1.13.0+cu116 --extra-index-url https://download.pytorch.org/whl/cu116\n",
        "!pip install transformers==4.30.0\n",
        "!pip install datasets==2.13.2\n",
        "!pip install accelerate -U\n",
        "!pip install evaluate"
      ],
      "metadata": {
        "id": "vc-YdlGVyh9_",
        "execution": {
          "iopub.status.busy": "2024-02-09T18:08:08.339009Z",
          "iopub.execute_input": "2024-02-09T18:08:08.339342Z",
          "iopub.status.idle": "2024-02-09T18:08:57.585386Z",
          "shell.execute_reply.started": "2024-02-09T18:08:08.339314Z",
          "shell.execute_reply": "2024-02-09T18:08:57.584229Z"
        },
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71b3aaaf-9061-4cf4-dd0e-288eb13aa210"
      },
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers==4.30.0 in /usr/local/lib/python3.10/dist-packages (4.30.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.30.0) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.30.0) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.30.0) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.30.0) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.30.0) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.30.0) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.30.0) (2.31.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.30.0) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.30.0) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.30.0) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers==4.30.0) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers==4.30.0) (4.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.30.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.30.0) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.30.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.30.0) (2024.2.2)\n",
            "Requirement already satisfied: datasets==2.13.2 in /usr/local/lib/python3.10/dist-packages (2.13.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets==2.13.2) (1.23.5)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets==2.13.2) (10.0.1)\n",
            "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets==2.13.2) (0.3.6)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets==2.13.2) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets==2.13.2) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets==2.13.2) (4.66.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets==2.13.2) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets==2.13.2) (0.70.14)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets==2.13.2) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets==2.13.2) (3.9.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from datasets==2.13.2) (0.20.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets==2.13.2) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets==2.13.2) (6.0.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.13.2) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.13.2) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.13.2) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.13.2) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.13.2) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.13.2) (4.0.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets==2.13.2) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets==2.13.2) (4.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets==2.13.2) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets==2.13.2) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets==2.13.2) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets==2.13.2) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets==2.13.2) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets==2.13.2) (2023.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets==2.13.2) (1.16.0)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.27.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.1.0+cu121)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.20.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.9.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.10/dist-packages (0.4.1)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.13.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.23.5)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.3.6)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.66.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.70.14)\n",
            "Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2023.6.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.20.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (23.2)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.18.0)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (10.0.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.9.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2023.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->evaluate) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# system packages\n",
        "from pathlib import Path\n",
        "import shutil\n",
        "import urllib\n",
        "import tarfile\n",
        "import sys\n",
        "import os\n",
        "# data and numerical management packages\n",
        "import pandas as pd\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import BertTokenizer, BertModel, BertForSequenceClassification, AdamW, Trainer, TrainingArguments\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "# useful during debugging (progress bars)\n",
        "from tqdm import tqdm\n",
        "from transformers import set_seed\n",
        "\n",
        "seed = 852\n",
        "torch.manual_seed(seed)\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "set_seed(seed)\n",
        "\n",
        "\n",
        "# Set seed for PyTorch on GPU (if available)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed(seed)"
      ],
      "metadata": {
        "id": "pD7fWLEPyh-B",
        "execution": {
          "iopub.status.busy": "2024-02-09T18:09:01.496707Z",
          "iopub.execute_input": "2024-02-09T18:09:01.497080Z",
          "iopub.status.idle": "2024-02-09T18:09:21.735201Z",
          "shell.execute_reply.started": "2024-02-09T18:09:01.497050Z",
          "shell.execute_reply": "2024-02-09T18:09:21.734199Z"
        },
        "trusted": true
      },
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_folder = Path.cwd().joinpath('sample_data/MELD_train_efr.json')\n",
        "# dataset_folder = '/kaggle/input/MELD_train_efr.json'\n",
        "#dataset_path = dataset_folder.joinpath('/MELD_train_efr.json')\n",
        "#dataset_folder = \"/kaggle/input/plaplapla/MELD_train_efr.json\"\n",
        "df = pd.read_json(dataset_folder)\n",
        "#df['triggers'] = df['triggers'].fillna(value=0, inplace=False)#.replace('None', 0.0)"
      ],
      "metadata": {
        "id": "6Vnl6q1Qyh-C",
        "execution": {
          "iopub.status.busy": "2024-02-09T18:09:21.736809Z",
          "iopub.execute_input": "2024-02-09T18:09:21.737381Z",
          "iopub.status.idle": "2024-02-09T18:09:22.039644Z",
          "shell.execute_reply.started": "2024-02-09T18:09:21.737355Z",
          "shell.execute_reply": "2024-02-09T18:09:22.038882Z"
        },
        "trusted": true
      },
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "oq9_ohFH3yeX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 597
        },
        "outputId": "78f38fc4-d7c5-47ee-b202-6901bad4dfa0",
        "execution": {
          "iopub.status.busy": "2024-02-09T18:09:22.040598Z",
          "iopub.execute_input": "2024-02-09T18:09:22.040877Z",
          "iopub.status.idle": "2024-02-09T18:09:22.077360Z",
          "shell.execute_reply.started": "2024-02-09T18:09:22.040854Z",
          "shell.execute_reply": "2024-02-09T18:09:22.076509Z"
        },
        "trusted": true
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             episode                                           speakers  \\\n",
              "0        utterance_0  [Chandler, The Interviewer, Chandler, The Inte...   \n",
              "1        utterance_1  [Chandler, The Interviewer, Chandler, The Inte...   \n",
              "2        utterance_2  [Chandler, The Interviewer, Chandler, The Inte...   \n",
              "3        utterance_3  [Chandler, The Interviewer, Chandler, The Inte...   \n",
              "4        utterance_4                       [Joey, Rachel, Joey, Rachel]   \n",
              "...              ...                                                ...   \n",
              "3995  utterance_3995  [Chandler, All, Monica, Chandler, Ross, Chandl...   \n",
              "3996  utterance_3996  [Chandler, All, Monica, Chandler, Ross, Chandl...   \n",
              "3997  utterance_3997  [Chandler, All, Monica, Chandler, Ross, Chandl...   \n",
              "3998  utterance_3998  [Chandler, All, Monica, Chandler, Ross, Chandl...   \n",
              "3999  utterance_3999  [Chandler, All, Monica, Chandler, Ross, Chandl...   \n",
              "\n",
              "                                               emotions  \\\n",
              "0        [neutral, neutral, neutral, neutral, surprise]   \n",
              "1     [neutral, neutral, neutral, neutral, surprise,...   \n",
              "2     [neutral, neutral, neutral, neutral, surprise,...   \n",
              "3     [neutral, neutral, neutral, neutral, surprise,...   \n",
              "4                   [surprise, sadness, surprise, fear]   \n",
              "...                                                 ...   \n",
              "3995  [neutral, joy, neutral, neutral, surprise, dis...   \n",
              "3996  [neutral, joy, neutral, neutral, surprise, dis...   \n",
              "3997  [neutral, joy, neutral, neutral, surprise, dis...   \n",
              "3998  [neutral, joy, neutral, neutral, surprise, dis...   \n",
              "3999  [neutral, joy, neutral, neutral, surprise, dis...   \n",
              "\n",
              "                                             utterances  \\\n",
              "0     [also I was the point person on my company's t...   \n",
              "1     [also I was the point person on my company's t...   \n",
              "2     [also I was the point person on my company's t...   \n",
              "3     [also I was the point person on my company's t...   \n",
              "4     [But then who? The waitress I went out with la...   \n",
              "...                                                 ...   \n",
              "3995  [Hey., Hey!, So how was Joan?, I broke up with...   \n",
              "3996  [Hey., Hey!, So how was Joan?, I broke up with...   \n",
              "3997  [Hey., Hey!, So how was Joan?, I broke up with...   \n",
              "3998  [Hey., Hey!, So how was Joan?, I broke up with...   \n",
              "3999  [Hey., Hey!, So how was Joan?, I broke up with...   \n",
              "\n",
              "                                               triggers  \n",
              "0                             [0.0, 0.0, 0.0, 1.0, 0.0]  \n",
              "1                   [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]  \n",
              "2     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...  \n",
              "3     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
              "4                                  [0.0, 0.0, 1.0, 0.0]  \n",
              "...                                                 ...  \n",
              "3995  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
              "3996  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
              "3997  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
              "3998  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
              "3999  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
              "\n",
              "[4000 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c4479aa5-c73e-4e21-934a-6da0dc6d3a24\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>episode</th>\n",
              "      <th>speakers</th>\n",
              "      <th>emotions</th>\n",
              "      <th>utterances</th>\n",
              "      <th>triggers</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>utterance_0</td>\n",
              "      <td>[Chandler, The Interviewer, Chandler, The Inte...</td>\n",
              "      <td>[neutral, neutral, neutral, neutral, surprise]</td>\n",
              "      <td>[also I was the point person on my company's t...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 1.0, 0.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>utterance_1</td>\n",
              "      <td>[Chandler, The Interviewer, Chandler, The Inte...</td>\n",
              "      <td>[neutral, neutral, neutral, neutral, surprise,...</td>\n",
              "      <td>[also I was the point person on my company's t...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>utterance_2</td>\n",
              "      <td>[Chandler, The Interviewer, Chandler, The Inte...</td>\n",
              "      <td>[neutral, neutral, neutral, neutral, surprise,...</td>\n",
              "      <td>[also I was the point person on my company's t...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>utterance_3</td>\n",
              "      <td>[Chandler, The Interviewer, Chandler, The Inte...</td>\n",
              "      <td>[neutral, neutral, neutral, neutral, surprise,...</td>\n",
              "      <td>[also I was the point person on my company's t...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>utterance_4</td>\n",
              "      <td>[Joey, Rachel, Joey, Rachel]</td>\n",
              "      <td>[surprise, sadness, surprise, fear]</td>\n",
              "      <td>[But then who? The waitress I went out with la...</td>\n",
              "      <td>[0.0, 0.0, 1.0, 0.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3995</th>\n",
              "      <td>utterance_3995</td>\n",
              "      <td>[Chandler, All, Monica, Chandler, Ross, Chandl...</td>\n",
              "      <td>[neutral, joy, neutral, neutral, surprise, dis...</td>\n",
              "      <td>[Hey., Hey!, So how was Joan?, I broke up with...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3996</th>\n",
              "      <td>utterance_3996</td>\n",
              "      <td>[Chandler, All, Monica, Chandler, Ross, Chandl...</td>\n",
              "      <td>[neutral, joy, neutral, neutral, surprise, dis...</td>\n",
              "      <td>[Hey., Hey!, So how was Joan?, I broke up with...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3997</th>\n",
              "      <td>utterance_3997</td>\n",
              "      <td>[Chandler, All, Monica, Chandler, Ross, Chandl...</td>\n",
              "      <td>[neutral, joy, neutral, neutral, surprise, dis...</td>\n",
              "      <td>[Hey., Hey!, So how was Joan?, I broke up with...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3998</th>\n",
              "      <td>utterance_3998</td>\n",
              "      <td>[Chandler, All, Monica, Chandler, Ross, Chandl...</td>\n",
              "      <td>[neutral, joy, neutral, neutral, surprise, dis...</td>\n",
              "      <td>[Hey., Hey!, So how was Joan?, I broke up with...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3999</th>\n",
              "      <td>utterance_3999</td>\n",
              "      <td>[Chandler, All, Monica, Chandler, Ross, Chandl...</td>\n",
              "      <td>[neutral, joy, neutral, neutral, surprise, dis...</td>\n",
              "      <td>[Hey., Hey!, So how was Joan?, I broke up with...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4000 rows × 5 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c4479aa5-c73e-4e21-934a-6da0dc6d3a24')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c4479aa5-c73e-4e21-934a-6da0dc6d3a24 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c4479aa5-c73e-4e21-934a-6da0dc6d3a24');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-cc51cf46-07ce-4fdf-8a42-bf9f05c37fa5\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-cc51cf46-07ce-4fdf-8a42-bf9f05c37fa5')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-cc51cf46-07ce-4fdf-8a42-bf9f05c37fa5 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "triggers = df['triggers']\n",
        "for row in range(triggers.shape[0]):\n",
        "    for trigger in range(len(triggers[row])):\n",
        "        if triggers[row][trigger] == None:\n",
        "            triggers[row][trigger] = 0.0\n",
        "\n",
        "df['triggers'] = triggers"
      ],
      "metadata": {
        "id": "PK4MQkLvyh-C",
        "execution": {
          "iopub.status.busy": "2024-02-09T18:09:22.136654Z",
          "iopub.execute_input": "2024-02-09T18:09:22.136918Z",
          "iopub.status.idle": "2024-02-09T18:09:22.333437Z",
          "shell.execute_reply.started": "2024-02-09T18:09:22.136896Z",
          "shell.execute_reply": "2024-02-09T18:09:22.332588Z"
        },
        "trusted": true
      },
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Speakers start"
      ],
      "metadata": {
        "id": "8ZFC7SJjuZKr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "speakers = df['speakers'].explode().unique()\n",
        "speaker_to_idx = {}\n",
        "idx_to_speaker = {}\n",
        "for idx, speaker in enumerate(speakers):\n",
        "  speaker_to_idx[speaker] = idx\n",
        "  idx_to_speaker[idx] = speaker"
      ],
      "metadata": {
        "id": "PiBHpvFHo_Wx",
        "execution": {
          "iopub.status.busy": "2024-02-09T18:09:22.336451Z",
          "iopub.execute_input": "2024-02-09T18:09:22.336718Z",
          "iopub.status.idle": "2024-02-09T18:09:22.350187Z",
          "shell.execute_reply.started": "2024-02-09T18:09:22.336689Z",
          "shell.execute_reply": "2024-02-09T18:09:22.349357Z"
        },
        "trusted": true
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_speakers = []\n",
        "for dialogue in df['speakers']:\n",
        "  dialogue_speakers = []\n",
        "  for speaker in dialogue:\n",
        "    dialogue_speakers.append(speaker_to_idx[speaker])\n",
        "  encoded_speakers.append(dialogue_speakers)"
      ],
      "metadata": {
        "id": "4l__6i9wrXYj",
        "execution": {
          "iopub.status.busy": "2024-02-09T18:09:22.351069Z",
          "iopub.execute_input": "2024-02-09T18:09:22.351325Z",
          "iopub.status.idle": "2024-02-09T18:09:22.369618Z",
          "shell.execute_reply.started": "2024-02-09T18:09:22.351303Z",
          "shell.execute_reply": "2024-02-09T18:09:22.368794Z"
        },
        "trusted": true
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Speakers end\n",
        "\n"
      ],
      "metadata": {
        "id": "SklD0kywtyIj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "emotions = df['emotions'].explode().unique()\n",
        "emotions"
      ],
      "metadata": {
        "id": "QFfykazN2xDw",
        "outputId": "734a248d-1cd2-4732-aab9-44340c583159",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.status.busy": "2024-02-09T18:09:22.370669Z",
          "iopub.execute_input": "2024-02-09T18:09:22.371779Z",
          "iopub.status.idle": "2024-02-09T18:09:22.386543Z",
          "shell.execute_reply.started": "2024-02-09T18:09:22.371745Z",
          "shell.execute_reply": "2024-02-09T18:09:22.385711Z"
        },
        "trusted": true
      },
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['neutral', 'surprise', 'fear', 'sadness', 'joy', 'disgust',\n",
              "       'anger'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "triggers = df['triggers'].explode().unique()\n",
        "triggers"
      ],
      "metadata": {
        "id": "p10v1luzDn1M",
        "outputId": "3f1ab36b-d8df-4448-b776-f0b8f37601e0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.status.busy": "2024-02-09T18:09:22.387756Z",
          "iopub.execute_input": "2024-02-09T18:09:22.388014Z",
          "iopub.status.idle": "2024-02-09T18:09:22.400313Z",
          "shell.execute_reply.started": "2024-02-09T18:09:22.387992Z",
          "shell.execute_reply": "2024-02-09T18:09:22.399332Z"
        },
        "trusted": true
      },
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.0, 1.0], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dialogues = df['utterances'][:3200]\n",
        "max_len_utterance = 0\n",
        "index = 0\n",
        "utterances_len = []\n",
        "for dialogue in dialogues:\n",
        "  for utterance in dialogue:\n",
        "     utterances_len.append(len(utterance.split()))\n",
        "np.mean(np.array(utterances_len))"
      ],
      "metadata": {
        "id": "q39q6ZPh-tCy",
        "outputId": "667437aa-d13f-4c4a-cbc0-375a4d18bf92",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.status.busy": "2024-02-09T18:09:22.401415Z",
          "iopub.execute_input": "2024-02-09T18:09:22.401666Z",
          "iopub.status.idle": "2024-02-09T18:09:22.439868Z",
          "shell.execute_reply.started": "2024-02-09T18:09:22.401643Z",
          "shell.execute_reply": "2024-02-09T18:09:22.439118Z"
        },
        "trusted": true
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8.077553661956639"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelBinarizer\n",
        "sorted_emotions = sorted(emotions)  #sort the array because Binarizer will automatically do that for one hot encoding\n",
        "label_binarizer = LabelBinarizer()\n",
        "label_binarizer.fit(sorted_emotions)\n",
        "\n",
        "dialogues = df['emotions']\n",
        "one_hot_emotions = []\n",
        "for dialogue_emotion in dialogues:\n",
        "  dialogue_emotions_list = []\n",
        "  for emotion in dialogue_emotion:\n",
        "    encoded_emotion=label_binarizer.transform([emotion])\n",
        "    dialogue_emotions_list.append(np.ravel(encoded_emotion).tolist())\n",
        "  one_hot_emotions.append(dialogue_emotions_list)"
      ],
      "metadata": {
        "id": "H6K5IJ0-NLlL",
        "execution": {
          "iopub.status.busy": "2024-02-09T18:09:22.440848Z",
          "iopub.execute_input": "2024-02-09T18:09:22.441110Z",
          "iopub.status.idle": "2024-02-09T18:09:36.095474Z",
          "shell.execute_reply.started": "2024-02-09T18:09:22.441087Z",
          "shell.execute_reply": "2024-02-09T18:09:36.094617Z"
        },
        "trusted": true
      },
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['emotions'] = one_hot_emotions"
      ],
      "metadata": {
        "id": "fNaWF4KIgIys",
        "execution": {
          "iopub.status.busy": "2024-02-09T18:09:36.096504Z",
          "iopub.execute_input": "2024-02-09T18:09:36.096797Z",
          "iopub.status.idle": "2024-02-09T18:09:36.103123Z",
          "shell.execute_reply.started": "2024-02-09T18:09:36.096773Z",
          "shell.execute_reply": "2024-02-09T18:09:36.102071Z"
        },
        "trusted": true
      },
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_data, test_data = train_test_split(df, train_size=0.5, shuffle=False)\n",
        "#val_data, test_data = train_test_split(temp_data, test_size=0.5, shuffle=False)\n",
        "#val_data.reset_index(drop=True, inplace=True)\n",
        "test_data.reset_index(drop=True, inplace=True)"
      ],
      "metadata": {
        "id": "ALZyV8V-kk5k",
        "execution": {
          "iopub.status.busy": "2024-02-09T18:09:36.104343Z",
          "iopub.execute_input": "2024-02-09T18:09:36.104761Z",
          "iopub.status.idle": "2024-02-09T18:09:36.129286Z",
          "shell.execute_reply.started": "2024-02-09T18:09:36.104730Z",
          "shell.execute_reply": "2024-02-09T18:09:36.128526Z"
        },
        "trusted": true
      },
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 597
        },
        "id": "oCwMJsVFAxLm",
        "outputId": "afab8e44-d50b-4107-fa60-3f9a4173ab9e"
      },
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             episode                                           speakers  \\\n",
              "0        utterance_0  [Chandler, The Interviewer, Chandler, The Inte...   \n",
              "1        utterance_1  [Chandler, The Interviewer, Chandler, The Inte...   \n",
              "2        utterance_2  [Chandler, The Interviewer, Chandler, The Inte...   \n",
              "3        utterance_3  [Chandler, The Interviewer, Chandler, The Inte...   \n",
              "4        utterance_4                       [Joey, Rachel, Joey, Rachel]   \n",
              "...              ...                                                ...   \n",
              "1995  utterance_1995                            [A Student, Ross, Ross]   \n",
              "1996  utterance_1996                      [A Student, Ross, Ross, Ross]   \n",
              "1997  utterance_1997                [A Student, Ross, Ross, Ross, Ross]   \n",
              "1998  utterance_1998          [A Student, Ross, Ross, Ross, Ross, Ross]   \n",
              "1999  utterance_1999  [A Student, Ross, Ross, Ross, Ross, Ross, Ross...   \n",
              "\n",
              "                                               emotions  \\\n",
              "0     [[0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 1, 0, 0],...   \n",
              "1     [[0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 1, 0, 0],...   \n",
              "2     [[0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 1, 0, 0],...   \n",
              "3     [[0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 1, 0, 0],...   \n",
              "4     [[0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 1, 0],...   \n",
              "...                                                 ...   \n",
              "1995  [[0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 1],...   \n",
              "1996  [[0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 1],...   \n",
              "1997  [[0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 1],...   \n",
              "1998  [[0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 1],...   \n",
              "1999  [[0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 1],...   \n",
              "\n",
              "                                             utterances  \\\n",
              "0     [also I was the point person on my company's t...   \n",
              "1     [also I was the point person on my company's t...   \n",
              "2     [also I was the point person on my company's t...   \n",
              "3     [also I was the point person on my company's t...   \n",
              "4     [But then who? The waitress I went out with la...   \n",
              "...                                                 ...   \n",
              "1995  [What's happening to your accent?, Come again?...   \n",
              "1996  [What's happening to your accent?, Come again?...   \n",
              "1997  [What's happening to your accent?, Come again?...   \n",
              "1998  [What's happening to your accent?, Come again?...   \n",
              "1999  [What's happening to your accent?, Come again?...   \n",
              "\n",
              "                                               triggers  \n",
              "0                             [0.0, 0.0, 0.0, 1.0, 0.0]  \n",
              "1                   [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]  \n",
              "2     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...  \n",
              "3     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
              "4                                  [0.0, 0.0, 1.0, 0.0]  \n",
              "...                                                 ...  \n",
              "1995                                    [0.0, 0.0, 0.0]  \n",
              "1996                               [0.0, 0.0, 0.0, 1.0]  \n",
              "1997                          [0.0, 0.0, 0.0, 0.0, 1.0]  \n",
              "1998                     [0.0, 0.0, 0.0, 0.0, 0.0, 1.0]  \n",
              "1999           [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]  \n",
              "\n",
              "[2000 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c71e4946-80e9-40b3-a53f-f124c002d635\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>episode</th>\n",
              "      <th>speakers</th>\n",
              "      <th>emotions</th>\n",
              "      <th>utterances</th>\n",
              "      <th>triggers</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>utterance_0</td>\n",
              "      <td>[Chandler, The Interviewer, Chandler, The Inte...</td>\n",
              "      <td>[[0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 1, 0, 0],...</td>\n",
              "      <td>[also I was the point person on my company's t...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 1.0, 0.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>utterance_1</td>\n",
              "      <td>[Chandler, The Interviewer, Chandler, The Inte...</td>\n",
              "      <td>[[0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 1, 0, 0],...</td>\n",
              "      <td>[also I was the point person on my company's t...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>utterance_2</td>\n",
              "      <td>[Chandler, The Interviewer, Chandler, The Inte...</td>\n",
              "      <td>[[0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 1, 0, 0],...</td>\n",
              "      <td>[also I was the point person on my company's t...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>utterance_3</td>\n",
              "      <td>[Chandler, The Interviewer, Chandler, The Inte...</td>\n",
              "      <td>[[0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 1, 0, 0],...</td>\n",
              "      <td>[also I was the point person on my company's t...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>utterance_4</td>\n",
              "      <td>[Joey, Rachel, Joey, Rachel]</td>\n",
              "      <td>[[0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 1, 0],...</td>\n",
              "      <td>[But then who? The waitress I went out with la...</td>\n",
              "      <td>[0.0, 0.0, 1.0, 0.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1995</th>\n",
              "      <td>utterance_1995</td>\n",
              "      <td>[A Student, Ross, Ross]</td>\n",
              "      <td>[[0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 1],...</td>\n",
              "      <td>[What's happening to your accent?, Come again?...</td>\n",
              "      <td>[0.0, 0.0, 0.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1996</th>\n",
              "      <td>utterance_1996</td>\n",
              "      <td>[A Student, Ross, Ross, Ross]</td>\n",
              "      <td>[[0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 1],...</td>\n",
              "      <td>[What's happening to your accent?, Come again?...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 1.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1997</th>\n",
              "      <td>utterance_1997</td>\n",
              "      <td>[A Student, Ross, Ross, Ross, Ross]</td>\n",
              "      <td>[[0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 1],...</td>\n",
              "      <td>[What's happening to your accent?, Come again?...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1998</th>\n",
              "      <td>utterance_1998</td>\n",
              "      <td>[A Student, Ross, Ross, Ross, Ross, Ross]</td>\n",
              "      <td>[[0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 1],...</td>\n",
              "      <td>[What's happening to your accent?, Come again?...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1999</th>\n",
              "      <td>utterance_1999</td>\n",
              "      <td>[A Student, Ross, Ross, Ross, Ross, Ross, Ross...</td>\n",
              "      <td>[[0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 1],...</td>\n",
              "      <td>[What's happening to your accent?, Come again?...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2000 rows × 5 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c71e4946-80e9-40b3-a53f-f124c002d635')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c71e4946-80e9-40b3-a53f-f124c002d635 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c71e4946-80e9-40b3-a53f-f124c002d635');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-1ac7229d-68cb-4ece-a309-18f699e5089f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1ac7229d-68cb-4ece-a309-18f699e5089f')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-1ac7229d-68cb-4ece-a309-18f699e5089f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSequenceClassification, RobertaModel\n",
        "from transformers import TFAutoModelForSequenceClassification\n",
        "from transformers import AutoTokenizer, AutoConfig\n",
        "\n",
        "#tokenizer = AutoTokenizer.from_pretrained(\"j-hartmann/emotion-english-distilroberta-base\")\n",
        "tokenizer = AutoTokenizer.from_pretrained('roberta-base')\n",
        "\n",
        "#tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "MODEL = 'roberta-base'#\"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
        "#tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
        "#config = AutoConfig.from_pretrained(MODEL)\n",
        "#model = RobertaModel.from_pretrained(MODEL)#AutoModelForSequenceClassification.from_pretrained(MODEL)\n",
        "\n",
        "\n",
        "def tokenize_padding(speakers_list, utterances_list):\n",
        "    tokenized_dialogues = []\n",
        "    max_length = 128  # Adjust the maximum sequence length as needed\n",
        "    for speakers, utterances in zip(speakers_list, utterances_list):#, total=len(utterances_list):\n",
        "        dialogue_with_speakers = []\n",
        "        for speaker, utterance in zip(speakers, utterances):\n",
        "            dialogue_with_speakers.append(\"[\"+speaker+\"] \" + utterance)\n",
        "        tokenized_dialogues.append(dialogue_with_speakers)\n",
        "\n",
        "\n",
        "    tokenization = []\n",
        "    for dialogue in tqdm(tokenized_dialogues):\n",
        "      tokenized_dialogue = tokenizer(\n",
        "          dialogue,\n",
        "          #max_length=9,\n",
        "          padding=True,\n",
        "          truncation=False,\n",
        "          return_tensors='pt'\n",
        "      )\n",
        "      tokenization.append(tokenized_dialogue)\n",
        "\n",
        "    input_ids = [dialogue['input_ids'] for dialogue in tokenization]\n",
        "    attention_mask = [dialogue['attention_mask'] for dialogue in tokenization]\n",
        "    return input_ids,attention_mask\n",
        "\n",
        "# Example usage with your dataset:\n",
        "input_ids_train, attention_mask_train = tokenize_padding(train_data['speakers'], train_data['utterances'])\n",
        "input_ids_val, attention_mask_val = tokenize_padding(val_data['speakers'], val_data['utterances'])\n",
        "input_ids_test, attention_mask_test = tokenize_padding(test_data['speakers'], test_data['utterances'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197,
          "referenced_widgets": [
            "5df5257ed0584335bb0d0fa6ead90232",
            "c382c40bc1ca4a269224acff1d8135b6",
            "20248e31c2af48b795bf46cad97e494a",
            "92f2c5dab3e94b1481362d475e2797a0",
            "781eb3b4bf9947eba38d250601aed229",
            "38ebba9ac34e414086b28c1c61b1ef18",
            "73c7c68486e6469687a3afef60f24ec9",
            "ad1a8b6906eb4fcfa5cd99f50b77744a",
            "dda29232ad9c404b9a8a4c375137bdc8",
            "380b56151f9649ed82657007d5ae1de2",
            "595b4334333a4a93a09b1c4beb01b756",
            "74f20d1d232a4f5082e7527701259a23",
            "3536a11e012c46a0af99b997656f1238",
            "68e1fe7e231945fdb6f7d7700027d1ff",
            "27f646ed9958421e8901c4c0266df159",
            "ba0cb34514ad428598e5b9dd4339ea73",
            "d010fa40e5cc48e59394c3e352f3945a",
            "43c2adeaddb14a26878b643248dbc314",
            "db4232ba1f844ff5b7af419a3317019a",
            "79adb14a257e42179e83e81c81cd453e",
            "e4175f6fc727416787ebf08f71de0db2",
            "cc94bd5ac1224a0eb6f8471655b85fb5",
            "e0b430182c42479eabc9ec50a6ebf383",
            "a38961d7e7064e50a2f2279f80a61883",
            "201632ae0d6845c9b98958ca2f51848c",
            "f1f4b9f7b83345f88d05d61d1a7714df",
            "4f2f56a288684038969c9106ea606839",
            "2570888de769491594d30b7128613083",
            "d127286d7edd40cb960a8ec60d339dc7",
            "49b1c1222a1846cf8e72ede74ebec848",
            "d219f9c923944b07aa62c75189c5de1d",
            "1395a4b9c8534636aba51520ba1f8f2a",
            "95be59ae7c174fd9b396c5d0672cbbae",
            "00c98afa25da42a98955de93296f6b62",
            "d5f48be9176d4ff0bf4a0f8ab74cd13d",
            "e5b7aa254a534741975a57a5c54cd504",
            "77b9be9c9b0b49fa84e0d79400e4b318",
            "554bcfa289fc4c6287c62c66f2ce2c68",
            "d98e2510b9f44908854e286cf3fc65b5",
            "e733672c1b284412b6cdde467e2e9bd4",
            "f76e0d67b763467fbe5e8d51b65666ab",
            "3166b97bdd1343e3b846daf079939b80",
            "3d1050cb39414a099a70adce939260ce",
            "99613caedb6d4206957df14a313e1810"
          ]
        },
        "id": "L0QsWfBjFLFa",
        "outputId": "0a2d804e-e799-4626-954b-608cdeede396",
        "execution": {
          "iopub.status.busy": "2024-02-09T18:09:36.130389Z",
          "iopub.execute_input": "2024-02-09T18:09:36.130648Z",
          "iopub.status.idle": "2024-02-09T18:09:41.509138Z",
          "shell.execute_reply.started": "2024-02-09T18:09:36.130625Z",
          "shell.execute_reply": "2024-02-09T18:09:41.505651Z"
        },
        "trusted": true
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5df5257ed0584335bb0d0fa6ead90232"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "74f20d1d232a4f5082e7527701259a23"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e0b430182c42479eabc9ec50a6ebf383"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "00c98afa25da42a98955de93296f6b62"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3200/3200 [00:03<00:00, 872.66it/s] \n",
            "100%|██████████| 400/400 [00:00<00:00, 1105.94it/s]\n",
            "100%|██████████| 400/400 [00:00<00:00, 1102.41it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#print(input_ids_train[0])\n",
        "print(tokenizer.decode(input_ids_train[0][-1]))\n",
        "print(train_data['utterances'][0][-1])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0_CDSiYqUASC",
        "outputId": "536ba5ae-c313-4524-e6d1-ed33f1bd1cdb",
        "execution": {
          "iopub.status.busy": "2024-02-09T18:09:41.510039Z",
          "iopub.status.idle": "2024-02-09T18:09:41.510406Z",
          "shell.execute_reply.started": "2024-02-09T18:09:41.510232Z",
          "shell.execute_reply": "2024-02-09T18:09:41.510248Z"
        },
        "trusted": true
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s>[Chandler] My duties?  All right.</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "My duties?  All right.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "def tokenize_padding(dialogues):\n",
        "  tokenized_dialogues = []\n",
        "\n",
        "  for dialogue in tqdm(dialogues):\n",
        "      tokenized_dialogue = tokenizer(\n",
        "          dialogue,\n",
        "          #max_length=9,\n",
        "          padding=True,\n",
        "          truncation=False,\n",
        "          return_tensors='pt'\n",
        "      )\n",
        "      tokenized_dialogues.append(tokenized_dialogue)\n",
        "\n",
        "  #padded_input_ids = pad_sequence([dialogue['input_ids'] for dialogue in tokenized_dialogues], batch_first=True)\n",
        "  input_ids = [dialogue['input_ids'] for dialogue in tokenized_dialogues]\n",
        "  attention_mask = [dialogue['attention_mask'] for dialogue in tokenized_dialogues]\n",
        "  return input_ids,attention_mask\n",
        "\n",
        "#padded_input_ids_train,padded_attention_mask_train = tokenize_padding(train_data['utterances'])\n",
        "input_ids_train,attention_mask_train = tokenize_padding(train_data['utterances'])\n",
        "input_ids_val,attention_mask_val = tokenize_padding(val_data['utterances'])\n",
        "input_ids_test,attention_mask_test = tokenize_padding(test_data['utterances'])\"\"\""
      ],
      "metadata": {
        "id": "RLe5H6fW5tMN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "outputId": "ab7bf7b4-4213-4e82-fcbc-13a16b9df5b3",
        "execution": {
          "iopub.status.busy": "2024-02-09T18:09:41.511602Z",
          "iopub.status.idle": "2024-02-09T18:09:41.511925Z",
          "shell.execute_reply.started": "2024-02-09T18:09:41.511763Z",
          "shell.execute_reply": "2024-02-09T18:09:41.511776Z"
        },
        "trusted": true
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\\ndef tokenize_padding(dialogues):\\n  tokenized_dialogues = []\\n\\n  for dialogue in tqdm(dialogues):\\n      tokenized_dialogue = tokenizer(\\n          dialogue,\\n          #max_length=9,\\n          padding=True,\\n          truncation=False,\\n          return_tensors='pt'\\n      )\\n      tokenized_dialogues.append(tokenized_dialogue)\\n\\n  #padded_input_ids = pad_sequence([dialogue['input_ids'] for dialogue in tokenized_dialogues], batch_first=True)\\n  input_ids = [dialogue['input_ids'] for dialogue in tokenized_dialogues]\\n  attention_mask = [dialogue['attention_mask'] for dialogue in tokenized_dialogues]\\n  return input_ids,attention_mask\\n\\n#padded_input_ids_train,padded_attention_mask_train = tokenize_padding(train_data['utterances'])\\ninput_ids_train,attention_mask_train = tokenize_padding(train_data['utterances'])\\ninput_ids_val,attention_mask_val = tokenize_padding(val_data['utterances'])\\ninput_ids_test,attention_mask_test = tokenize_padding(test_data['utterances'])\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "def compute_sequence_f1(predictions, labels):\n",
        "    # predictions and labels should be lists of tensors for each dialogue\n",
        "    emotion_f1_scores = []\n",
        "    trigger_f1_scores = []\n",
        "    for emotion_pred, trigger_pred, emotion_lab, trigger_lab in zip(predictions[0], predictions[1], labels[0], labels[1]):\n",
        "        emotion_predicted_classes = torch.argmax(emotion_pred, dim=1)\n",
        "        trigger_predicted_classes = torch.argmax(trigger_pred, dim=1)\n",
        "        emotion_true_classes = torch.argmax(emotion_lab, dim=1)\n",
        "        trigger_true_classes = trigger_lab\n",
        "        emotion_f1 = f1_score(emotion_true_classes.cpu().numpy(), emotion_predicted_classes.cpu().numpy(), average='macro')\n",
        "        trigger_f1 = f1_score(trigger_true_classes.cpu().numpy(), trigger_predicted_classes.cpu().numpy(), average='macro')\n",
        "        emotion_f1_scores.append(emotion_f1)\n",
        "        trigger_f1_scores.append(trigger_f1)\n",
        "    average_emotion_f1 = torch.tensor(emotion_f1_scores, dtype=torch.float32).mean()\n",
        "    average_trigger_f1 = torch.tensor(trigger_f1_scores, dtype=torch.float32).mean()\n",
        "    return average_emotion_f1, average_trigger_f1\n",
        "\n",
        "def compute_unrolled_sequence_f1(predictions, labels):\n",
        "    # Flatten all utterances and compute the F1 score\n",
        "    all_emotion_predicted_classes = torch.argmax(torch.cat(predictions[0], dim=0), dim=1)\n",
        "    all_trigger_predicted_classes = torch.argmax(torch.cat(predictions[1], dim=0), dim=1)\n",
        "    all_emotion_true_classes = torch.argmax(torch.cat(labels[0], dim=0), dim=1)\n",
        "    all_trigger_true_classes = torch.cat(labels[1], dim=0)\n",
        "    unrolled_emotion_f1 = f1_score(all_emotion_true_classes.cpu().numpy(), all_emotion_predicted_classes.cpu().numpy(), average='macro')\n",
        "    unrolled_trigger_f1 = f1_score(all_trigger_true_classes.cpu().numpy(), all_trigger_predicted_classes.cpu().numpy(), average='macro')\n",
        "    unrolled_emotion_f1_tensor = torch.tensor(unrolled_emotion_f1, dtype=torch.float32)\n",
        "    unrolled_trigger_f1_tensor = torch.tensor(unrolled_trigger_f1, dtype=torch.float32)\n",
        "    return unrolled_emotion_f1_tensor, unrolled_trigger_f1_tensor"
      ],
      "metadata": {
        "id": "yx9yj1Kuq7qt",
        "execution": {
          "iopub.status.busy": "2024-02-09T18:09:41.513008Z",
          "iopub.status.idle": "2024-02-09T18:09:41.513377Z",
          "shell.execute_reply.started": "2024-02-09T18:09:41.513200Z",
          "shell.execute_reply": "2024-02-09T18:09:41.513219Z"
        },
        "trusted": true
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, input_ids, attention_mask, emotions, triggers):\n",
        "        self.input_ids = input_ids\n",
        "        self.attention_mask = attention_mask\n",
        "        self.emotions = emotions\n",
        "        self.triggers = triggers\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.emotions)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        input_ids = self.input_ids[idx]\n",
        "        attention_mask = self.attention_mask[idx]\n",
        "        emotion = self.emotions[idx]\n",
        "        trigger = self.triggers[idx]\n",
        "        emotion_labels = torch.tensor(emotion, dtype=torch.float32)\n",
        "        trigger_label = torch.tensor(trigger, dtype=torch.long)\n",
        "        return {\n",
        "            'input_ids': input_ids,\n",
        "            'attention_mask': attention_mask,\n",
        "            'emotion_labels': emotion_labels,\n",
        "            'trigger_label': trigger_label\n",
        "        }"
      ],
      "metadata": {
        "id": "HiiN1Qs9k0DM",
        "execution": {
          "iopub.status.busy": "2024-02-09T18:10:17.421342Z",
          "iopub.execute_input": "2024-02-09T18:10:17.421700Z",
          "iopub.status.idle": "2024-02-09T18:10:17.429447Z",
          "shell.execute_reply.started": "2024-02-09T18:10:17.421673Z",
          "shell.execute_reply": "2024-02-09T18:10:17.428101Z"
        },
        "trusted": true
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Old CustomBertModel with LSTM Layer"
      ],
      "metadata": {
        "id": "McdxBACONTFt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import BertModel\n",
        "\n",
        "\n",
        "class CustomBERTModel(torch.nn.Module):\n",
        "    def __init__(self, freeze_embeddings=True, hidden_size=128, num_layers=1, bidirectional=True):\n",
        "        super(CustomBERTModel, self).__init__()\n",
        "        #self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
        "        self.bert = RobertaModel.from_pretrained('roberta-base')\n",
        "\n",
        "        if freeze_embeddings:\n",
        "            for name, param in self.bert.named_parameters():\n",
        "                if 'embeddings' in name:\n",
        "                    param.requires_grad = False\n",
        "        self.emotion_head = torch.nn.Linear(self.bert.config.hidden_size, len(emotions))\n",
        "\n",
        "        # Linear layer for trigger classification\n",
        "        self.trigger_head = torch.nn.Linear(self.bert.config.hidden_size, len(triggers))\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask, return_dict=True)\n",
        "\n",
        "        pooled_output = outputs['pooler_output']\n",
        "\n",
        "\n",
        "        emotion_logits = self.emotion_head(pooled_output)\n",
        "        trigger_logits = self.trigger_head(pooled_output)\n",
        "\n",
        "        return emotion_logits, trigger_logits"
      ],
      "metadata": {
        "id": "MfLGTU4Mkw3V",
        "execution": {
          "iopub.status.busy": "2024-02-09T18:09:41.515953Z",
          "iopub.status.idle": "2024-02-09T18:09:41.516304Z",
          "shell.execute_reply.started": "2024-02-09T18:09:41.516109Z",
          "shell.execute_reply": "2024-02-09T18:09:41.516121Z"
        },
        "trusted": true
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"class CustomBERTModel(torch.nn.Module):\n",
        "    def __init__(self, freeze_embeddings=True, hidden_size=128, num_layers=1, bidirectional=True):\n",
        "        super(CustomBERTModel, self).__init__()\n",
        "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
        "        if freeze_embeddings:\n",
        "            for name, param in self.bert.named_parameters():\n",
        "                if 'embeddings' in name:\n",
        "                    param.requires_grad = False\n",
        "\n",
        "        # GRU layer\n",
        "        self.gru = torch.nn.GRU(input_size=self.bert.config.hidden_size,\n",
        "                                hidden_size=hidden_size,\n",
        "                                num_layers=num_layers,\n",
        "                                bidirectional=bidirectional,\n",
        "                                batch_first=True)\n",
        "\n",
        "        self.emotion_head = torch.nn.Linear(hidden_size * 2 if bidirectional else hidden_size, len(emotions))\n",
        "\n",
        "        # Linear layer for trigger classification\n",
        "        self.trigger_head = torch.nn.Linear(hidden_size * 2 if bidirectional else hidden_size, len(triggers))\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask, return_dict=True)\n",
        "        pooled_output = outputs['pooler_output']\n",
        "\n",
        "        # Pass BERT output through GRU\n",
        "        gru_output, _ = self.gru(pooled_output.unsqueeze(1))  # Adding the unsqueeze for the sequence dimension\n",
        "\n",
        "        # Take the output from the last time step\n",
        "        gru_output_last = gru_output[:, -1, :]\n",
        "\n",
        "        emotion_logits = self.emotion_head(gru_output_last)\n",
        "        trigger_logits = self.trigger_head(gru_output_last)\n",
        "\n",
        "        return emotion_logits, trigger_logits\"\"\""
      ],
      "metadata": {
        "id": "BRMM5JywI2Ur",
        "execution": {
          "iopub.status.busy": "2024-02-09T18:09:41.517698Z",
          "iopub.status.idle": "2024-02-09T18:09:41.518004Z",
          "shell.execute_reply.started": "2024-02-09T18:09:41.517851Z",
          "shell.execute_reply": "2024-02-09T18:09:41.517864Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "outputId": "7c6d71e1-63b8-4001-9415-d510fe057058"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"class CustomBERTModel(torch.nn.Module):\\n    def __init__(self, freeze_embeddings=True, hidden_size=128, num_layers=1, bidirectional=True):\\n        super(CustomBERTModel, self).__init__()\\n        self.bert = BertModel.from_pretrained('bert-base-uncased')\\n        if freeze_embeddings:\\n            for name, param in self.bert.named_parameters():\\n                if 'embeddings' in name:\\n                    param.requires_grad = False\\n\\n        # GRU layer\\n        self.gru = torch.nn.GRU(input_size=self.bert.config.hidden_size,\\n                                hidden_size=hidden_size,\\n                                num_layers=num_layers,\\n                                bidirectional=bidirectional,\\n                                batch_first=True)\\n\\n        self.emotion_head = torch.nn.Linear(hidden_size * 2 if bidirectional else hidden_size, len(emotions))\\n\\n        # Linear layer for trigger classification\\n        self.trigger_head = torch.nn.Linear(hidden_size * 2 if bidirectional else hidden_size, len(triggers))\\n\\n    def forward(self, input_ids, attention_mask):\\n        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask, return_dict=True)\\n        pooled_output = outputs['pooler_output']\\n\\n        # Pass BERT output through GRU\\n        gru_output, _ = self.gru(pooled_output.unsqueeze(1))  # Adding the unsqueeze for the sequence dimension\\n\\n        # Take the output from the last time step\\n        gru_output_last = gru_output[:, -1, :]\\n\\n        emotion_logits = self.emotion_head(gru_output_last)\\n        trigger_logits = self.trigger_head(gru_output_last)\\n\\n        return emotion_logits, trigger_logits\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = CustomDataset(input_ids_train, attention_mask_train, train_data['emotions'],\n",
        "                              train_data['triggers'])\n",
        "#validation_dataset = CustomDataset(input_ids_val, attention_mask_val, val_data['emotions'],\n",
        "#                             val_data['triggers'])\n",
        "test_dataset = CustomDataset(input_ids_test, attention_mask_test, test_data['emotions'],\n",
        "                             test_data['triggers'])"
      ],
      "metadata": {
        "id": "bUR8qBNelMMl",
        "execution": {
          "iopub.status.busy": "2024-02-09T18:09:41.518873Z",
          "iopub.status.idle": "2024-02-09T18:09:41.519222Z",
          "shell.execute_reply.started": "2024-02-09T18:09:41.519033Z",
          "shell.execute_reply": "2024-02-09T18:09:41.519047Z"
        },
        "trusted": true
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "def collate_fn(batch):\n",
        "    input_ids = [item['input_ids'] for item in batch]\n",
        "    attention_mask = [item['attention_mask'] for item in batch]\n",
        "    emotion_labels = [item['emotion_labels'] for item in batch]#torch.stack([item['emotion_labels'] for item in batch], dim=0)\n",
        "    trigger_label = [item['trigger_label'] for item in batch]#torch.stack([item['trigger_label'] for item in batch], dim=0)\n",
        "\n",
        "    #input_ids = pad_sequence([torch.stack(item['input_ids']) for item in batch], batch_first=True)\n",
        "    #attention_mask = pad_sequence([torch.stack(item['attention_mask']) for item in batch], batch_first=True)\n",
        "    return input_ids,attention_mask,emotion_labels,trigger_label\n",
        "    #return {'input_ids': input_ids, 'attention_mask': attention_mask, 'emotion_labels': emotion_labels, 'trigger_label': trigger_label"
      ],
      "metadata": {
        "id": "ybP2gK92AU7o",
        "execution": {
          "iopub.status.busy": "2024-02-09T18:10:10.398916Z",
          "iopub.execute_input": "2024-02-09T18:10:10.399314Z",
          "iopub.status.idle": "2024-02-09T18:10:10.406259Z",
          "shell.execute_reply.started": "2024-02-09T18:10:10.399284Z",
          "shell.execute_reply": "2024-02-09T18:10:10.405043Z"
        },
        "trusted": true
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_bert(mode,model):\n",
        "\n",
        "# Usage in the eval loop\n",
        "  sequence_f1_scores_emotion = []\n",
        "  sequence_f1_scores_trigger = []\n",
        "  unrolled_predictions_emotion = []\n",
        "  unrolled_predictions_trigger = []\n",
        "  unrolled_labels_emotion = []\n",
        "  unrolled_labels_trigger = []\n",
        "  sequence_f1_scores = []\n",
        "\n",
        "  batch_size = 1\n",
        "  #test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "  if mode == 'validation':\n",
        "    loader = DataLoader(validation_dataset, batch_size=batch_size, shuffle=False)\n",
        "  elif mode == 'test':\n",
        "    loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "      for batch in tqdm(loader, desc='Evaluation', leave=False):\n",
        "          input_ids = batch['input_ids'].squeeze().to(device)\n",
        "          attention_mask = batch['attention_mask'].squeeze().to(device)\n",
        "          emotion_labels = batch['emotion_labels'].squeeze().to(device)\n",
        "          trigger_label = batch['trigger_label'].squeeze().to(device)\n",
        "\n",
        "          emotion_logits, trigger_logits = model(input_ids, attention_mask)\n",
        "\n",
        "          # Store predictions and labels for later unrolled F1 computation\n",
        "          unrolled_predictions_emotion.append(emotion_logits)\n",
        "          unrolled_labels_emotion.append(emotion_labels)\n",
        "          unrolled_predictions_trigger.append(trigger_logits)\n",
        "          unrolled_labels_trigger.append(trigger_label)\n",
        "\n",
        "          # Convert logits to probabilities and then to class predictions\n",
        "          #predicted_classes = torch.argmax(emotion_logits, dim=1)\n",
        "          #true_classes = torch.argmax(emotion_labels, dim=1)\n",
        "\n",
        "          # Compute F1 for the current sequence (dialogue)\n",
        "          #sequence_f1 = f1_score(true_classes.cpu().numpy(), predicted_classes.cpu().numpy(), average='macro')\n",
        "          #sequence_f1_scores.append(sequence_f1)\n",
        "\n",
        "  # Compute the average Sequence F1 for emotions and triggers\n",
        "  average_sequence_f1_emotion, average_sequence_f1_trigger = compute_sequence_f1(\n",
        "      [unrolled_predictions_emotion, unrolled_predictions_trigger],\n",
        "      [unrolled_labels_emotion, unrolled_labels_trigger]\n",
        "  )\n",
        "\n",
        "  # Compute the Unrolled Sequence F1 for emotions and triggers\n",
        "  unrolled_sequence_f1_emotion, unrolled_sequence_f1_trigger = compute_unrolled_sequence_f1(\n",
        "      [unrolled_predictions_emotion, unrolled_predictions_trigger],\n",
        "      [unrolled_labels_emotion, unrolled_labels_trigger]\n",
        "  )\n",
        "  model.train()\n",
        "  # Print the F1 scores for emotions and triggers\n",
        "  print(f\"Average Sequence F1 (Emotion):  {average_sequence_f1_emotion:03f}\")\n",
        "  print(f\"Average Sequence F1 (Trigger): {average_sequence_f1_trigger:03f}\")\n",
        "  print(f\"Unrolled Sequence F1 (Emotion): {unrolled_sequence_f1_emotion.item():03f}\")\n",
        "  print(f\"Unrolled Sequence F1 (Trigger): {unrolled_sequence_f1_trigger.item():03f}\")\n",
        "  return average_sequence_f1_emotion, average_sequence_f1_trigger, unrolled_sequence_f1_emotion, unrolled_sequence_f1_trigger"
      ],
      "metadata": {
        "id": "PhPnLK7ZAQxE",
        "execution": {
          "iopub.status.busy": "2024-02-09T18:09:41.522183Z",
          "iopub.status.idle": "2024-02-09T18:09:41.522505Z",
          "shell.execute_reply.started": "2024-02-09T18:09:41.522349Z",
          "shell.execute_reply": "2024-02-09T18:09:41.522363Z"
        },
        "trusted": true
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bert"
      ],
      "metadata": {
        "id": "5-oF31k5JxDt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = torch.nn.CrossEntropyLoss() # can tinker with the loss function, change to a different one\n",
        "#criterion_trigger = torch.nn.BCEWithLogitsLoss()\n",
        "\n",
        "\n",
        "num_epochs = 5\n",
        "batch_size = 16\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
        "freezed_embeddings = True\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "BERT_baseline = CustomBERTModel().to(device)\n",
        "optimizer = torch.optim.AdamW(BERT_baseline.parameters(), lr=1e-5)\n",
        "#optimizer = torch.optim.AdamW([{'params': BERT_baseline.emotion_head.parameters()}, {'params': BERT_baseline.trigger_head.parameters()}], lr=1e-5, weight_decay=1e-4)"
      ],
      "metadata": {
        "id": "X9yT4HSYPXV1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156,
          "referenced_widgets": [
            "e1c2ded6f02e4431b89de086eeeb304b",
            "6b5dc8302417496d9fe559cca0719462",
            "97dd83365d57470cb7077091961b54f0",
            "ab71628150384c19b8a613e1ba5c8db0",
            "8d49c8c7ef324becb418bd91a669d411",
            "f6f0fac7dd4345f9a9f4e2774a488c9a",
            "868abc7f8e3d4261a635e5d97c5de07d",
            "fafaef3c6398457e9366e2b048ac2ed0",
            "e604978c15c4493bb0424196bffd5def",
            "b783d978c5294b6c98a1dba1aee902ef",
            "dc71a963770241668a8a571a898b9468"
          ]
        },
        "outputId": "d8d76c49-2c9a-4534-d130-c91deca65201",
        "execution": {
          "iopub.status.busy": "2024-02-09T18:09:41.523472Z",
          "iopub.status.idle": "2024-02-09T18:09:41.523838Z",
          "shell.execute_reply.started": "2024-02-09T18:09:41.523643Z",
          "shell.execute_reply": "2024-02-09T18:09:41.523658Z"
        },
        "trusted": true
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e1c2ded6f02e4431b89de086eeeb304b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(num_epochs):\n",
        "    BERT_baseline.train()\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for batch in tqdm(train_loader, desc=f'Epoch {epoch + 1}', leave=False):\n",
        "        input_ids,attention_mask,emotion_labels,trigger_label = batch\n",
        "\n",
        "        # Zero the gradients on the optimizer\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        for el in range(batch_size):\n",
        "          emotion_loss = 0.0\n",
        "          trigger_loss = 0.0\n",
        "\n",
        "          input_ids_el = input_ids[el].squeeze().to(device)\n",
        "          attention_mask_el = attention_mask[el].squeeze().to(device)\n",
        "          emotion_labels_el = emotion_labels[el].squeeze().to(device)\n",
        "          trigger_label_el = trigger_label[el].squeeze().to(device)\n",
        "\n",
        "          # Forward pass\n",
        "          emotion_logits, trigger_logits = BERT_baseline(input_ids_el, attention_mask_el)\n",
        "          # Compute the loss for both emotion and trigger\n",
        "\n",
        "          emotion_loss += criterion(emotion_logits, torch.argmax(emotion_labels_el, dim=1))\n",
        "          #trigger_loss += criterion(torch.argmax(trigger_logits, dim=1).float(), trigger_label_el.float())\n",
        "          trigger_loss += criterion(trigger_logits, trigger_label_el)\n",
        "\n",
        "        # Combine losses for backpropagation\n",
        "        loss = (emotion_loss + trigger_loss)/batch_size\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "    # Compute the average loss\n",
        "    average_loss = total_loss / len(train_loader)\n",
        "    print(f\"Epoch {epoch + 1}, Average Loss: {average_loss}\")\n",
        "    test_bert('validation',BERT_baseline)"
      ],
      "metadata": {
        "id": "RiM7PzNfsHBm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "outputId": "5c60cd36-e635-4359-ec04-e62ff1f7cb40",
        "execution": {
          "iopub.status.busy": "2024-02-09T18:09:41.525382Z",
          "iopub.status.idle": "2024-02-09T18:09:41.525711Z",
          "shell.execute_reply.started": "2024-02-09T18:09:41.525536Z",
          "shell.execute_reply": "2024-02-09T18:09:41.525549Z"
        },
        "trusted": true
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-825b10474b6e>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0memotion_loss\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtrigger_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    490\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             )\n\u001b[0;32m--> 492\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    493\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[0mgrad_tensors_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_tensor_or_tensors_to_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m     \u001b[0mgrad_tensors_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_make_grads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_grads_batched\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mretain_graph\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36m_make_grads\u001b[0;34m(outputs, grads, is_grads_batched)\u001b[0m\n\u001b[1;32m    125\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m                 new_grads.append(\n\u001b[0;32m--> 127\u001b[0;31m                     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreserve_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m                 )\n\u001b[1;32m    129\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_ = test_bert('test',BERT_baseline)"
      ],
      "metadata": {
        "id": "dnFkphFUgo8R",
        "execution": {
          "iopub.status.busy": "2024-02-09T18:09:41.526896Z",
          "iopub.status.idle": "2024-02-09T18:09:41.527274Z",
          "shell.execute_reply.started": "2024-02-09T18:09:41.527067Z",
          "shell.execute_reply": "2024-02-09T18:09:41.527084Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GRIDSEARCH"
      ],
      "metadata": {
        "id": "5dJ1-1ZSwrWf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "#best_loss = float('inf')\n",
        "# Define the grid search parameters\n",
        "lr_values = [1e-5, 5e-5]\n",
        "hidden_size_values = [64, 128]\n",
        "batch_size_values = [20, 32]\n",
        "\n",
        "# Iterate through all combinations\n",
        "for lr, hidden_size, batch_size in itertools.product(lr_values, hidden_size_values, batch_size_values):\n",
        "    # Define your model, optimizer, and other necessary components with the current parameters\n",
        "    custom_Bert_Model = CustomBERTModel(hidden_size=hidden_size)\n",
        "    custom_Bert_Model = custom_Bert_Model.to(device)\n",
        "    optimizer = torch.optim.AdamW(custom_Bert_Model.parameters(), lr=lr)\n",
        "\n",
        "    # DataLoader with the current batch size\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
        "\n",
        "    num_epochs = 7\n",
        "    # Training loop and validation code here, using the current lr, hidden_size, and batch_size\n",
        "    for epoch in range(num_epochs):\n",
        "      custom_Bert_Model.train()\n",
        "      total_loss = 0.0\n",
        "\n",
        "      for batch in tqdm(train_loader, desc=f'Epoch {epoch + 1}', leave=False):\n",
        "          input_ids,attention_mask,emotion_labels,trigger_label = batch\n",
        "\n",
        "          # Zero the gradients on the optimizer\n",
        "          optimizer.zero_grad()\n",
        "\n",
        "          for el in range(batch_size):\n",
        "            emotion_loss = 0.0\n",
        "            trigger_loss = 0.0\n",
        "\n",
        "            input_ids_el = input_ids[el].squeeze().to(device)\n",
        "            attention_mask_el = attention_mask[el].squeeze().to(device)\n",
        "            emotion_labels_el = emotion_labels[el].squeeze().to(device)\n",
        "            trigger_label_el = trigger_label[el].squeeze().to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            emotion_logits, trigger_logits = custom_Bert_Model(input_ids_el, attention_mask_el)\n",
        "            # Compute the loss for both emotion and trigger\n",
        "\n",
        "            emotion_loss += criterion_emotion(emotion_logits, torch.argmax(emotion_labels_el, dim=1))\n",
        "            trigger_loss += criterion_trigger(torch.argmax(trigger_logits, dim=1).float(), trigger_label_el.float())\n",
        "\n",
        "          # Combine losses for backpropagation\n",
        "          loss = (emotion_loss + trigger_loss)/batch_size\n",
        "\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "\n",
        "          total_loss += loss.item()\n",
        "      # Compute the average loss\n",
        "      average_loss = total_loss / len(train_loader)\n",
        "      print(f\"Epoch {epoch + 1}, Average Loss: {average_loss}\")\n",
        "      validation_loss = test_bert('validation')\n",
        "      #best_loss = save_best_model(custom_Bert_Model, optimizer, epoch, validation_loss, best_loss)\n",
        "\n",
        "    # Print or log the results for each combination\n",
        "    print(f\"LR: {lr}, Hidden Size: {hidden_size}, Batch Size: {batch_size}\")#, Best Validation Loss: {best_loss}\")\n",
        "    test_loss = test_bert('test')\n"
      ],
      "metadata": {
        "id": "9zNDsSeRrzE-",
        "execution": {
          "iopub.status.busy": "2024-02-09T18:09:41.528563Z",
          "iopub.status.idle": "2024-02-09T18:09:41.528932Z",
          "shell.execute_reply.started": "2024-02-09T18:09:41.528754Z",
          "shell.execute_reply": "2024-02-09T18:09:41.528772Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Majority classifier"
      ],
      "metadata": {
        "id": "XcYo46z3J0jV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Reinitialise train, val and test loaders without collate_fn for Majority and Random\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(validation_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "XStwXzaS-Z6B",
        "execution": {
          "iopub.status.busy": "2024-02-09T18:09:41.530310Z",
          "iopub.status.idle": "2024-02-09T18:09:41.530643Z",
          "shell.execute_reply.started": "2024-02-09T18:09:41.530463Z",
          "shell.execute_reply": "2024-02-09T18:09:41.530476Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "def find_majority_class(train_loader):\n",
        "    # Initialize counters\n",
        "    emotion_counts = torch.zeros(7) # Assuming there are 7 unique emotions\n",
        "    trigger_counts = torch.zeros(2) # There are 2 classes for triggers: present or not\n",
        "    negative_trigger_counts = 0\n",
        "    positive_trigger_counts = 0\n",
        "    # Iterate over the training dataset to count the labels\n",
        "    for batch in train_loader:\n",
        "        emotion_labels = batch['emotion_labels'].squeeze()\n",
        "        trigger_labels = batch['trigger_label'].squeeze()\n",
        "        #print(trigger_labels,torch.sum(trigger_labels, dim=0),(trigger_labels == 0).sum())\n",
        "        # Sum up the counts for each class\n",
        "        positive_trigger_counts += torch.sum(trigger_labels, dim=0)\n",
        "        # Count the zeros for the negative class (absence of a trigger)\n",
        "        # Since one-hot encoding, the absence is just the inverse of the presence\n",
        "        negative_trigger_counts += torch.sum(1 - trigger_labels, dim=0)\n",
        "        emotion_counts += torch.sum(emotion_labels, dim=0)\n",
        "\n",
        "    trigger_counts[0] = negative_trigger_counts\n",
        "    trigger_counts[1] = positive_trigger_counts\n",
        "    print(trigger_counts)\n",
        "    print(emotion_counts)\n",
        "    # Find the index with the maximum count for emotions and triggers\n",
        "    majority_emotion = torch.zeros_like(emotion_counts)\n",
        "    majority_emotion[torch.argmax(emotion_counts)] = 1\n",
        "    majority_trigger = torch.zeros_like(trigger_counts)\n",
        "    majority_trigger[torch.argmax(trigger_counts)] = 1\n",
        "\n",
        "    return majority_emotion, majority_trigger\n",
        "\n",
        "# Let's assume that 'train_loader' is a DataLoader for your training dataset\n",
        "# You need to replace 'train_loader' with the actual DataLoader for your dataset\n",
        "majority_emotion, majority_trigger = find_majority_class(train_loader)\n",
        "majority_emotion, majority_trigger"
      ],
      "metadata": {
        "id": "EdfQ_Tkn0Hzj",
        "execution": {
          "iopub.status.busy": "2024-02-09T18:09:41.531576Z",
          "iopub.status.idle": "2024-02-09T18:09:41.531912Z",
          "shell.execute_reply.started": "2024-02-09T18:09:41.531748Z",
          "shell.execute_reply": "2024-02-09T18:09:41.531763Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "def majority_classifier(majority_emotion, majority_trigger, test_loader):\n",
        "    all_emotion_predictions = []\n",
        "    all_trigger_predictions = []\n",
        "    all_emotion_labels = []\n",
        "    all_trigger_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(test_loader, desc='Evaluation', leave=False):\n",
        "            emotion_labels = batch['emotion_labels']\n",
        "            trigger_labels = batch['trigger_label']\n",
        "\n",
        "            for emotion_lab, trigger_lab in zip(emotion_labels, trigger_labels):\n",
        "                # Ensure we have at least 1 dimension\n",
        "                if emotion_lab.ndim == 1 and emotion_lab.size(0) == 1:\n",
        "                    emotion_lab = emotion_lab.unsqueeze(0)\n",
        "                if trigger_lab.ndim == 1 and trigger_lab.size(0) == 1:\n",
        "                    trigger_lab = trigger_lab.unsqueeze(0)\n",
        "\n",
        "                # Store the labels\n",
        "                all_emotion_labels.append(emotion_lab)\n",
        "                all_trigger_labels.append(trigger_lab)\n",
        "\n",
        "                # Repeat the majority class prediction to match the number of utterances\n",
        "                emotion_predictions = majority_emotion.repeat(emotion_lab.size(0), 1)\n",
        "                #print(emotion_predictions)\n",
        "\n",
        "                trigger_predictions = majority_trigger.repeat(trigger_lab.size(0), 1)\n",
        "\n",
        "                # Store the predictions\n",
        "                all_emotion_predictions.append(emotion_predictions)\n",
        "                all_trigger_predictions.append(trigger_predictions)\n",
        "\n",
        "    # Use the stored predictions and labels to calculate sequence F1 and unrolled sequence F1\n",
        "    average_sequence_f1_emotion, average_sequence_f1_trigger = compute_sequence_f1(\n",
        "        [all_emotion_predictions, all_trigger_predictions],\n",
        "        [all_emotion_labels, all_trigger_labels]\n",
        "    )\n",
        "\n",
        "    unrolled_sequence_f1_emotion, unrolled_sequence_f1_trigger = compute_unrolled_sequence_f1(\n",
        "        [all_emotion_predictions, all_trigger_predictions],\n",
        "        [all_emotion_labels, all_trigger_labels]\n",
        "    )\n",
        "\n",
        "    return average_sequence_f1_emotion, average_sequence_f1_trigger, unrolled_sequence_f1_emotion, unrolled_sequence_f1_trigger\n",
        "\n",
        "# Assume majority_emotion and majority_trigger are tensors of the majority class (one-hot encoded)\n",
        "# and test_loader is your DataLoader instance for the test dataset.\n",
        "average_f1_emotion, average_f1_trigger, unrolled_f1_emotion, unrolled_f1_trigger = majority_classifier(majority_emotion, majority_trigger, test_loader)\n",
        "\n",
        "print(f\"Average Sequence F1 (Emotion): {average_f1_emotion}\")\n",
        "print(f\"Average Sequence F1 (Trigger): {average_f1_trigger}\")\n",
        "print(f\"Unrolled Sequence F1 (Emotion): {unrolled_f1_emotion}\")\n",
        "print(f\"Unrolled Sequence F1 (Trigger): {unrolled_f1_trigger}\")"
      ],
      "metadata": {
        "id": "J6KeegKyC0d9",
        "execution": {
          "iopub.status.busy": "2024-02-09T18:09:41.533726Z",
          "iopub.status.idle": "2024-02-09T18:09:41.534032Z",
          "shell.execute_reply.started": "2024-02-09T18:09:41.533880Z",
          "shell.execute_reply": "2024-02-09T18:09:41.533893Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Random"
      ],
      "metadata": {
        "id": "iA_NcO9QTaXW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "def random_classifier(test_loader, emotion_distribution, trigger_distribution):\n",
        "    all_emotion_predictions = []\n",
        "    all_trigger_predictions = []\n",
        "    all_emotion_labels = []\n",
        "    all_trigger_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(test_loader, desc='Evaluation', leave=False):\n",
        "            emotion_labels = batch['emotion_labels']\n",
        "            trigger_labels = batch['trigger_label']\n",
        "\n",
        "            for emotion_lab, trigger_lab in zip(emotion_labels, trigger_labels):\n",
        "                # Ensure we have at least 1 dimension\n",
        "                if emotion_lab.ndim == 1 and emotion_lab.size(0) == 1:\n",
        "                    emotion_lab = emotion_lab.unsqueeze(0)\n",
        "                if trigger_lab.ndim == 1 and trigger_lab.size(0) == 1:\n",
        "                    trigger_lab = trigger_lab.unsqueeze(0)\n",
        "\n",
        "                # Store the labels\n",
        "                all_emotion_labels.append(emotion_lab)\n",
        "                all_trigger_labels.append(trigger_lab)\n",
        "\n",
        "                # Generate random predictions for emotions\n",
        "                random_emotion_predictions = torch.randint(0, 2, (emotion_lab.size(0), 7))  # Randomly 0 or 1 for each emotion\n",
        "                all_emotion_predictions.append(random_emotion_predictions.float())\n",
        "\n",
        "                # Generate random predictions for triggers based on the training distribution\n",
        "                random_trigger_probs = torch.rand((trigger_lab.size(0), 1))\n",
        "                random_trigger_predictions = (random_trigger_probs < trigger_distribution).long()  # Binary prediction based on distribution\n",
        "                random_trigger_predictions = torch.cat((random_trigger_predictions, 1 - random_trigger_predictions), dim=1)  # Make it one-hot\n",
        "                all_trigger_predictions.append(random_trigger_predictions.float())\n",
        "\n",
        "    # Calculate the F1 scores using your metric functions\n",
        "    average_sequence_f1_emotion, average_sequence_f1_trigger = compute_sequence_f1(\n",
        "        [all_emotion_predictions, all_trigger_predictions],\n",
        "        [all_emotion_labels, all_trigger_labels]\n",
        "    )\n",
        "\n",
        "    unrolled_sequence_f1_emotion, unrolled_sequence_f1_trigger = compute_unrolled_sequence_f1(\n",
        "        [all_emotion_predictions, all_trigger_predictions],\n",
        "        [all_emotion_labels, all_trigger_labels]\n",
        "    )\n",
        "\n",
        "    return average_sequence_f1_emotion, average_sequence_f1_trigger, unrolled_sequence_f1_emotion, unrolled_sequence_f1_trigger\n",
        "\n",
        "# You need to provide the distribution for the trigger class from your training data\n",
        "# For example, if 30% of your training samples have a trigger, trigger_distribution should be 0.3\n",
        "trigger_distribution = 0.5  # Replace with your actual distribution\n",
        "\n",
        "# Now call your random classifier function\n",
        "average_f1_emotion, average_f1_trigger, unrolled_f1_emotion, unrolled_f1_trigger = random_classifier(\n",
        "    test_loader,\n",
        "    emotion_distribution=None,  # Not used currently as we're assuming a uniform distribution\n",
        "    trigger_distribution=trigger_distribution\n",
        ")\n",
        "\n",
        "print(f\"Random Classifier Average Sequence F1 (Emotion): {average_f1_emotion}\")\n",
        "print(f\"Random Classifier Average Sequence F1 (Trigger): {average_f1_trigger}\")\n",
        "print(f\"Random Classifier Unrolled Sequence F1 (Emotion): {unrolled_f1_emotion}\")\n",
        "print(f\"Random Classifier Unrolled Sequence F1 (Trigger): {unrolled_f1_trigger}\")"
      ],
      "metadata": {
        "id": "PyrbLyM5QezV",
        "execution": {
          "iopub.status.busy": "2024-02-09T18:09:41.535087Z",
          "iopub.status.idle": "2024-02-09T18:09:41.535447Z",
          "shell.execute_reply.started": "2024-02-09T18:09:41.535282Z",
          "shell.execute_reply": "2024-02-09T18:09:41.535296Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bert with context"
      ],
      "metadata": {
        "id": "mX3i2xOzVri2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import BertModel\n",
        "import torch.nn as nn\n",
        "\n",
        "class BERT_LSTM_5(torch.nn.Module):\n",
        "    def __init__(self, num_emotions, num_triggers, freeze_embeddings=True):\n",
        "        super(BERT_LSTM_5, self).__init__()\n",
        "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "        if freeze_embeddings:\n",
        "            for name, param in self.bert.named_parameters():\n",
        "                if 'embeddings' in name:\n",
        "                    param.requires_grad = False\n",
        "\n",
        "        self.lstm_hidden_size = self.bert.config.hidden_size\n",
        "\n",
        "        self.lstm = nn.LSTM(input_size=self.lstm_hidden_size,\n",
        "                            hidden_size=self.lstm_hidden_size,\n",
        "                            num_layers=1,\n",
        "                            batch_first=True,\n",
        "                            bidirectional=True)\n",
        "\n",
        "        # Dropout for L1 Regularization\n",
        "        self.dropout = nn.Dropout(p=0.1)\n",
        "\n",
        "        # Instead of applying custom attention, we'll use the output from LSTM directly for classification\n",
        "        self.emotion_head = nn.Linear(self.lstm_hidden_size * 2, num_emotions)  # *2 for bidirectional\n",
        "        self.trigger_head = nn.Linear(self.lstm_hidden_size * 2, num_triggers)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        bert_outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask, return_dict=True)\n",
        "        bert_sequence_output = bert_outputs.last_hidden_state\n",
        "\n",
        "        lstm_output, (h_n, c_n) = self.lstm(bert_sequence_output)\n",
        "\n",
        "        # Instead of applying attention, use the last hidden states directly\n",
        "        # Concatenate the final forward and backward hidden states\n",
        "        h_n = torch.cat((h_n[-2,:,:], h_n[-1,:,:]), dim=1)\n",
        "\n",
        "        # Apply dropout to the concatenated LSTM outputs\n",
        "        h_n = self.dropout(h_n)\n",
        "\n",
        "        emotion_logits = self.emotion_head(h_n)\n",
        "        trigger_logits = self.trigger_head(h_n)\n",
        "\n",
        "        return emotion_logits, trigger_logits\n"
      ],
      "metadata": {
        "id": "mBTnJPl1Z3Y_",
        "execution": {
          "iopub.status.busy": "2024-02-09T18:09:41.536834Z",
          "iopub.status.idle": "2024-02-09T18:09:41.537180Z",
          "shell.execute_reply.started": "2024-02-09T18:09:41.536999Z",
          "shell.execute_reply": "2024-02-09T18:09:41.537013Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.optim import AdamW\n",
        "from torch.nn import CrossEntropyLoss, BCEWithLogitsLoss\n",
        "from tqdm import tqdm\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "num_epochs = 7\n",
        "batch_size = 10\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
        "\n",
        "num_emotions = 7\n",
        "num_triggers = 2\n",
        "\n",
        "# Instantiate the model\n",
        "BERT_lstm = BERT_LSTM_5(num_emotions, num_triggers, freeze_embeddings=True).to(device)\n",
        "BERT_baseline = CustomBERTModel().to(device)\n",
        "# Define separate optimizers for shared model parts + emotion head, and trigger head\n",
        "# you can comment out a specific params dict if you dont want to update it\n",
        "optimizer_shared = AdamW([\n",
        "    {'params': BERT_baseline.bert.parameters()},\n",
        "    #{'params': BERT_lstm.lstm.parameters()},\n",
        "    {'params': BERT_baseline.emotion_head.parameters()}\n",
        "], lr=1e-5, weight_decay=1e-5)\n",
        "\n",
        "optimizer_trigger = AdamW(BERT_baseline.trigger_head.parameters(), lr=1e-4, weight_decay=0)\n",
        "\n",
        "optimizer_shared = torch.optim.AdamW([{'params': BERT_BASELINEmodel.emotion_head.parameters()}, {'params': BERT_BASELINEmodel.trigger_head.parameters()}], lr=1e-5, weight_decay=1e-4)\n",
        "criterion_emotion = CrossEntropyLoss()\n",
        "criterion_trigger = BCEWithLogitsLoss()\n",
        "\n",
        "# Assuming the learning rate scheduler is applied to the shared optimizer\n",
        "scheduler = ReduceLROnPlateau(optimizer_shared, mode='min', factor=0.5, patience=1, verbose=True)"
      ],
      "metadata": {
        "id": "oWASQX8D-ANz",
        "execution": {
          "iopub.status.busy": "2024-02-09T18:09:41.538417Z",
          "iopub.status.idle": "2024-02-09T18:09:41.538860Z",
          "shell.execute_reply.started": "2024-02-09T18:09:41.538623Z",
          "shell.execute_reply": "2024-02-09T18:09:41.538641Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    BERT_lstm.train()\n",
        "    total_loss = 0.0\n",
        "    loss_emotion = 0.0\n",
        "    loss_trigger = 0.0\n",
        "\n",
        "    for batch in tqdm(train_loader, desc=f'Epoch {epoch + 1}', leave=False):\n",
        "        # collate_fn returns lists, so we do not call .to(device) here\n",
        "        input_ids, attention_mask, emotion_labels, trigger_label = batch\n",
        "\n",
        "        # Zero the gradients for both optimizers\n",
        "        optimizer_shared.zero_grad()\n",
        "        optimizer_trigger.zero_grad()\n",
        "\n",
        "        emotion_loss = 0.0\n",
        "        trigger_loss = 0.0\n",
        "        for el in range(batch_size):  # Process each item in the batch\n",
        "            # Convert list items to tensors and send them to the device\n",
        "            input_ids_el = input_ids[el].squeeze().to(device)\n",
        "            attention_mask_el = attention_mask[el].squeeze().to(device)\n",
        "            emotion_labels_el = emotion_labels[el].squeeze().to(device)\n",
        "            trigger_label_el = trigger_label[el].squeeze().to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            emotion_logits, trigger_logits = BERT_baseline(input_ids_el, attention_mask_el)\n",
        "\n",
        "            # Compute the loss for both emotion and trigger\n",
        "            emotion_loss += criterion_emotion(emotion_logits, torch.argmax(emotion_labels_el, dim=1))\n",
        "            trigger_loss += criterion_trigger(torch.argmax(trigger_logits, dim=1).float(), trigger_label_el.float())\n",
        "\n",
        "        # Average the losses\n",
        "        emotion_loss /= batch_size\n",
        "        trigger_loss /= batch_size\n",
        "        trigger_loss.requires_grad_()\n",
        "\n",
        "        # print(\"emotion loss is\", emotion_loss)\n",
        "        # print(\"trigger loss is\", trigger_loss)\n",
        "        # print(trigger_loss.requires_grad)\n",
        "\n",
        "        # Backpropagate losses and step optimizers\n",
        "        emotion_loss.backward(retain_graph=True)\n",
        "        optimizer_shared.step()\n",
        "\n",
        "        trigger_loss.backward()\n",
        "        optimizer_trigger.step()\n",
        "\n",
        "        # Update total and individual losses\n",
        "        total_loss += (emotion_loss.item() + trigger_loss.item())\n",
        "        loss_emotion += emotion_loss.item()\n",
        "        loss_trigger += trigger_loss.item()\n",
        "\n",
        "    # Compute average loss for the epoch\n",
        "    average_loss = total_loss / len(train_loader)\n",
        "    average_emotion_loss = loss_emotion / len(train_loader)\n",
        "    average_trigger_loss = loss_trigger / len(train_loader)\n",
        "    print(f\"----Evaluation scores on Validation set for Epoch {epoch+1}----\")\n",
        "    validation = test_bert('validation') # print out F1 scores using test_bert\n",
        "    print(\"------------------------------------------------------\")\n",
        "    # Adjust learning rate based on the average loss\n",
        "    scheduler.step(average_loss)\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}, Total Average Loss: {average_loss}\")\n",
        "    print(f\"Epoch {epoch + 1}, Average Emotion Loss: {average_emotion_loss}\")\n",
        "    print(f\"Epoch {epoch + 1}, Average Trigger Loss: {average_trigger_loss}\")"
      ],
      "metadata": {
        "id": "f9UfUaEmC79u",
        "execution": {
          "iopub.status.busy": "2024-02-09T18:09:41.540877Z",
          "iopub.status.idle": "2024-02-09T18:09:41.541336Z",
          "shell.execute_reply.started": "2024-02-09T18:09:41.541090Z",
          "shell.execute_reply": "2024-02-09T18:09:41.541108Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_bert('test')"
      ],
      "metadata": {
        "id": "ZZvrPME-Kqlm",
        "execution": {
          "iopub.status.busy": "2024-02-09T18:09:41.542535Z",
          "iopub.status.idle": "2024-02-09T18:09:41.542977Z",
          "shell.execute_reply.started": "2024-02-09T18:09:41.542750Z",
          "shell.execute_reply": "2024-02-09T18:09:41.542769Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Old Initialisation and Training code with One optimizer"
      ],
      "metadata": {
        "id": "YETzHhCyJnPK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "\n",
        "num_emotions = 7\n",
        "num_triggers = 2\n",
        "\n",
        "# Instantiate the model\n",
        "BERT_lstm = BERT_LSTM_5(num_emotions,num_triggers).to(device)\n",
        "#optimizer = AdamW(filter(lambda p: p.requires_grad, custom_Bert_Model.parameters()), lr=5e-5)\n",
        "# optimizer = torch.optim.SGD(BERT_lstm.parameters(), lr=1e-5)\n",
        "optimizer = torch.optim.AdamW(BERT_lstm.parameters(), lr=1e-5, weight_decay=1e-4)\n",
        "# optimizer = torch.optim.AdamW(BERT_lstm.parameters(), lr=1e-3,weight_decay = 5e-4)\n",
        "criterion_emotion = torch.nn.CrossEntropyLoss()\n",
        "criterion_trigger = torch.nn.BCEWithLogitsLoss()\n",
        "\n",
        "# Define the learning rate scheduler\n",
        "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=1, verbose=True)"
      ],
      "metadata": {
        "id": "RPrAMRrMXZt5",
        "execution": {
          "iopub.status.busy": "2024-02-09T18:09:41.544112Z",
          "iopub.status.idle": "2024-02-09T18:09:41.544558Z",
          "shell.execute_reply.started": "2024-02-09T18:09:41.544339Z",
          "shell.execute_reply": "2024-02-09T18:09:41.544357Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 8\n",
        "batch_size = 16\n",
        "for epoch in range(num_epochs):\n",
        "    BERT_lstm.train()\n",
        "    total_loss = 0.0\n",
        "    loss_emotion = 0.0\n",
        "    loss_trigger = 0.0\n",
        "    for batch in tqdm(train_loader, desc=f'Epoch {epoch + 1}', leave=False):\n",
        "        input_ids,attention_mask,emotion_labels,trigger_label = batch\n",
        "\n",
        "        # Zero the gradients on the optimizer\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        emotion_loss = 0.0\n",
        "        trigger_loss = 0.0\n",
        "        for el in range(batch_size):\n",
        "            input_ids_el = input_ids[el].squeeze().to(device)\n",
        "            attention_mask_el = attention_mask[el].squeeze().to(device)\n",
        "            emotion_labels_el = emotion_labels[el].squeeze().to(device)\n",
        "            trigger_label_el = trigger_label[el].squeeze().to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            emotion_logits, trigger_logits = BERT_lstm(input_ids_el, attention_mask_el)\n",
        "            # Compute the loss for both emotion and trigger\n",
        "\n",
        "            emotion_loss += criterion_emotion(emotion_logits, torch.argmax(emotion_labels_el, dim=1))\n",
        "            trigger_loss += criterion_trigger(torch.argmax(trigger_logits, dim=1).float(), trigger_label_el.float())\n",
        "\n",
        "        # Combine losses for backpropagation\n",
        "        loss = (emotion_loss + trigger_loss)/batch_size\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        loss_emotion += emotion_loss/batch_size\n",
        "        loss_trigger += trigger_loss/batch_size\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    # Compute the average loss\n",
        "    average_loss = total_loss / len(train_loader)\n",
        "    validation_loss = test_bert('validation')\n",
        "\n",
        "    scheduler.step(average_loss)\n",
        "\n",
        "    # Compute the average loss\n",
        "    print(f\"Epoch {epoch + 1}, Average Loss: {average_loss}\")\n",
        "    print(f\"Epoch {epoch + 1}, Emotion Loss: {loss_emotion/len(train_loader)}\")\n",
        "    print(f\"Epoch {epoch + 1}, Trigger Loss: {loss_trigger/len(train_loader)}\")"
      ],
      "metadata": {
        "id": "9937TpiLcD4I",
        "execution": {
          "iopub.status.busy": "2024-02-09T18:09:41.545880Z",
          "iopub.status.idle": "2024-02-09T18:09:41.546423Z",
          "shell.execute_reply.started": "2024-02-09T18:09:41.546114Z",
          "shell.execute_reply": "2024-02-09T18:09:41.546132Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_bert('test')"
      ],
      "metadata": {
        "id": "67fZFk4c8yKJ",
        "execution": {
          "iopub.status.busy": "2024-02-09T18:09:41.548049Z",
          "iopub.status.idle": "2024-02-09T18:09:41.548402Z",
          "shell.execute_reply.started": "2024-02-09T18:09:41.548235Z",
          "shell.execute_reply": "2024-02-09T18:09:41.548250Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluation loop"
      ],
      "metadata": {
        "id": "ToTApmgOJxb3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Usage in the eval loop\n",
        "sequence_f1_scores_emotion = []\n",
        "sequence_f1_scores_trigger = []\n",
        "unrolled_predictions_emotion = []\n",
        "unrolled_predictions_trigger = []\n",
        "unrolled_labels_emotion = []\n",
        "unrolled_labels_trigger = []\n",
        "sequence_f1_scores = []\n",
        "\n",
        "test_loader = # insert test loader code here, todo\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in tqdm(test_loader, desc='Evaluation', leave=False):\n",
        "        input_ids = batch['input_ids'].squeeze().to(device)\n",
        "        attention_mask = batch['attention_mask'].squeeze().to(device)\n",
        "        emotion_labels = batch['emotion_labels'].squeeze().to(device)\n",
        "        trigger_label = batch['trigger_label'].squeeze().to(device)\n",
        "\n",
        "        emotion_logits, trigger_logits = BERT_lstm(input_ids, attention_mask)\n",
        "\n",
        "        # Store predictions and labels for later unrolled F1 computation\n",
        "        unrolled_predictions_emotion.append(emotion_logits)\n",
        "        unrolled_labels_emotion.append(emotion_labels)\n",
        "        unrolled_predictions_trigger.append(trigger_logits)\n",
        "        unrolled_labels_trigger.append(trigger_label)\n",
        "\n",
        "        # Convert logits to probabilities and then to class predictions\n",
        "        predicted_classes = torch.argmax(emotion_logits, dim=1)\n",
        "        true_classes = torch.argmax(emotion_labels, dim=1)\n",
        "\n",
        "        # Compute F1 for the current sequence (dialogue)\n",
        "        sequence_f1 = f1_score(true_classes.cpu().numpy(), predicted_classes.cpu().numpy(), average='macro')\n",
        "        sequence_f1_scores.append(sequence_f1)\n",
        "\n",
        "# Compute the average Sequence F1 for emotions and triggers\n",
        "average_sequence_f1_emotion, average_sequence_f1_trigger = compute_sequence_f1(\n",
        "    [unrolled_predictions_emotion, unrolled_predictions_trigger],\n",
        "    [unrolled_labels_emotion, unrolled_labels_trigger]\n",
        ")\n",
        "\n",
        "# Compute the Unrolled Sequence F1 for emotions and triggers\n",
        "unrolled_sequence_f1_emotion, unrolled_sequence_f1_trigger = compute_unrolled_sequence_f1(\n",
        "    [unrolled_predictions_emotion, unrolled_predictions_trigger],\n",
        "    [unrolled_labels_emotion, unrolled_labels_trigger]\n",
        ")\n",
        "\n",
        "# Print the F1 scores for emotions and triggers\n",
        "print(f\"Average Sequence F1 (Emotion): {average_sequence_f1_emotion:.4f}\")\n",
        "print(f\"Average Sequence F1 (Trigger): {average_sequence_f1_trigger:.4f}\")\n",
        "print(f\"Unrolled Sequence F1 (Emotion): {unrolled_sequence_f1_emotion.item():.4f}\")\n",
        "print(f\"Unrolled Sequence F1 (Trigger): {unrolled_sequence_f1_trigger.item():.4f}\")"
      ],
      "metadata": {
        "id": "NRliJGnfeKmp",
        "execution": {
          "iopub.status.busy": "2024-02-09T18:09:41.549959Z",
          "iopub.status.idle": "2024-02-09T18:09:41.550403Z",
          "shell.execute_reply.started": "2024-02-09T18:09:41.550176Z",
          "shell.execute_reply": "2024-02-09T18:09:41.550195Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Roberta"
      ],
      "metadata": {
        "id": "DJLNVH-pXymq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"import torch\n",
        "from transformers import RobertaModel, RobertaForSequenceClassification\n",
        "import torch.nn as nn\n",
        "\n",
        "class RoBERTa_LSTM(nn.Module):\n",
        "    def __init__(self, num_emotions, num_triggers, freeze_embeddings=True):\n",
        "        super(RoBERTa_LSTM, self).__init__()\n",
        "        # Load the pretrained RoBERTa model\n",
        "        #self.roberta = RobertaModel.from_pretrained('roberta-base')\n",
        "        #self.roberta = RobertaModel.from_pretrained(\"j-hartmann/emotion-english-distilroberta-base\")\n",
        "        self.roberta = RobertaModel.from_pretrained('roberta-large')\n",
        "        #self.roberta = RobertaForSequenceClassification.from_pretrained('roberta-base')\n",
        "        # Optionally, freeze the embeddings layer to prevent fine-tuning\n",
        "        if freeze_embeddings:\n",
        "            for name, param in self.roberta.named_parameters():\n",
        "                if 'embeddings' in name:\n",
        "                    param.requires_grad = False\n",
        "        \"\"\"\n",
        "        # LSTM configuration remains the same\n",
        "        self.lstm_hidden_size = self.roberta.config.hidden_size\n",
        "        self.lstm = nn.LSTM(input_size=self.lstm_hidden_size,\n",
        "                            hidden_size=self.lstm_hidden_size,\n",
        "                            num_layers=1,\n",
        "                            batch_first=True,\n",
        "                            bidirectional=True)\n",
        "\n",
        "        self.dropout = nn.Dropout(p=0)  # Adjust dropout rate as needed\n",
        "\n",
        "        # Classification heads for emotions and triggers\n",
        "        \"\"\"\n",
        "        #self.emotion_head = nn.Linear(self.lstm_hidden_size * 2, num_emotions)  # *2 for bidirectional LSTM\n",
        "        #self.trigger_head = nn.Linear(self.lstm_hidden_size * 2, num_triggers)\n",
        "        self.emotion_head = nn.Linear(self.roberta.config.hidden_size, num_emotions)\n",
        "        self.trigger_head = nn.Linear(self.roberta.config.hidden_size, num_triggers)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        # Process input through RoBERTa\n",
        "        \"\"\"\n",
        "        roberta_outputs = self.roberta(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        roberta_sequence_output = roberta_outputs.last_hidden_state\n",
        "\n",
        "        # Process the output through LSTM\n",
        "        lstm_output, (h_n, c_n) = self.lstm(roberta_sequence_output)\n",
        "\n",
        "        # Use the final hidden states from LSTM for classification\n",
        "        h_n = torch.cat((h_n[-2,:,:], h_n[-1,:,:]), dim=1)\n",
        "        h_n = self.dropout(h_n)  # Apply dropout\n",
        "\n",
        "        # Generate logits for each head\n",
        "        emotion_logits = self.emotion_head(h_n)\n",
        "        trigger_logits = self.trigger_head(h_n)\"\"\"\n",
        "        outputs = self.roberta(input_ids=input_ids, attention_mask=attention_mask, return_dict=True)\n",
        "\n",
        "        pooled_output = outputs['pooler_output']\n",
        "\n",
        "\n",
        "        emotion_logits = self.emotion_head(pooled_output)\n",
        "        trigger_logits = self.trigger_head(pooled_output)\n",
        "\n",
        "        return emotion_logits, trigger_logits\n",
        "\n",
        "        return emotion_logits, trigger_logits\"\"\""
      ],
      "metadata": {
        "id": "WesAcAJOX0JJ",
        "execution": {
          "iopub.status.busy": "2024-02-09T18:09:41.551812Z",
          "iopub.status.idle": "2024-02-09T18:09:41.552285Z",
          "shell.execute_reply.started": "2024-02-09T18:09:41.552027Z",
          "shell.execute_reply": "2024-02-09T18:09:41.552046Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import RobertaModel\n",
        "import torch.nn as nn\n",
        "\n",
        "class RoBERTa_LSTM(nn.Module):\n",
        "    def __init__(self, num_emotions, num_triggers, freeze_embeddings=False):  # Fixed __init_ method\n",
        "        super(RoBERTa_LSTM, self).__init__()  # Fixed __init_ method\n",
        "        # Load the pretrained RoBERTa model\n",
        "        self.roberta = RobertaModel.from_pretrained('roberta-base')\n",
        "\n",
        "        # Optionally, freeze the embeddings layer to prevent fine-tuning\n",
        "        if freeze_embeddings:\n",
        "            for name, param in self.roberta.named_parameters():\n",
        "                if 'embeddings' in name:\n",
        "                    param.requires_grad = False\n",
        "\n",
        "        # LSTM configuration remains the same\n",
        "        self.lstm_hidden_size = self.roberta.config.hidden_size\n",
        "        self.lstm = nn.LSTM(input_size=self.lstm_hidden_size,\n",
        "                            hidden_size=self.lstm_hidden_size,\n",
        "                            num_layers=1,\n",
        "                            batch_first=True,\n",
        "                            bidirectional=True)\n",
        "\n",
        "        self.dropout = nn.Dropout(p=0.1)  # Adjust dropout rate as needed\n",
        "\n",
        "        # Add batch normalization layers\n",
        "        self.batchnorm_emotion = nn.BatchNorm1d(self.lstm_hidden_size * 2)\n",
        "        self.batchnorm_trigger = nn.BatchNorm1d(self.lstm_hidden_size * 2)\n",
        "\n",
        "        # Classification heads for emotions and triggers\n",
        "        self.emotion_head = nn.Linear(self.lstm_hidden_size * 2, num_emotions)  # *2 for bidirectional LSTM\n",
        "        self.trigger_head = nn.Linear(self.lstm_hidden_size * 2, num_triggers)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        # Process input through RoBERTa\n",
        "        roberta_outputs = self.roberta(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        roberta_sequence_output = roberta_outputs.last_hidden_state\n",
        "\n",
        "        # Process the output through LSTM\n",
        "        lstm_output, (h_n, c_n) = self.lstm(roberta_sequence_output)\n",
        "\n",
        "        # Concatenate the final forward and backward hidden states and apply dropout\n",
        "        h_n = torch.cat((h_n[-2,:,:], h_n[-1,:,:]), dim=1)\n",
        "        h_n = self.dropout(h_n)\n",
        "\n",
        "        # Apply batch normalization to the output of the LSTM\n",
        "        emotion_bn = self.batchnorm_emotion(h_n)\n",
        "        trigger_bn = self.batchnorm_trigger(h_n)\n",
        "\n",
        "        # Generate logits for each head\n",
        "        emotion_logits = self.emotion_head(emotion_bn)\n",
        "        trigger_logits = self.trigger_head(trigger_bn)\n",
        "\n",
        "        return emotion_logits, trigger_logits"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-09T18:09:41.553745Z",
          "iopub.status.idle": "2024-02-09T18:09:41.554193Z",
          "shell.execute_reply.started": "2024-02-09T18:09:41.553953Z",
          "shell.execute_reply": "2024-02-09T18:09:41.553971Z"
        },
        "trusted": true,
        "id": "S_nLbBdIlTIZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "from pytorch_ranger import Ranger\n",
        "\n",
        "\n",
        "num_emotions = 7\n",
        "num_triggers = 2\n",
        "\n",
        "# Instantiate the model\n",
        "BERT_lstm = RoBERTa_LSTM(num_emotions,num_triggers).to(device)\n",
        "model = RoBERTa_LSTM(num_emotions, num_triggers).to(device)\n",
        "#optimizer = Ranger(model.parameters(), lr=1e-3)\n",
        "#optimizer = Ranger(RoBERTa_LSTM.parameters(), lr=1e-3)\n",
        "#optimizer = AdamW(filter(lambda p: p.requires_grad, custom_Bert_Model.parameters()), lr=5e-5)\n",
        "# optimizer = torch.optim.SGD(BERT_lstm.parameters(), lr=1e-5)\n",
        "optimizer = torch.optim.AdamW(BERT_lstm.parameters(), lr=1e-5, weight_decay=1e-4)\n",
        "#optimizer = torch.optim.AdamW(BERT_lstm.parameters(), lr=1e-3,weight_decay = 5e-4)\n",
        "criterion_emotion = torch.nn.CrossEntropyLoss()\n",
        "criterion_trigger = torch.nn.BCEWithLogitsLoss()\n",
        "\n",
        "# Define the learning rate scheduler\n",
        "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=1, verbose=True)"
      ],
      "metadata": {
        "id": "Ogbyi7nnX9S5",
        "execution": {
          "iopub.status.busy": "2024-02-09T18:09:41.555653Z",
          "iopub.status.idle": "2024-02-09T18:09:41.556084Z",
          "shell.execute_reply.started": "2024-02-09T18:09:41.555864Z",
          "shell.execute_reply": "2024-02-09T18:09:41.555882Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Roberta baseline"
      ],
      "metadata": {
        "id": "NqM9-sfblTIZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSequenceClassification, RobertaModel, RobertaForSequenceClassification, RobertaForMultipleChoice\n",
        "from transformers import TFAutoModelForSequenceClassification\n",
        "from transformers import AutoTokenizer, AutoConfig\n",
        "\n",
        "\n",
        "#tokenizer = AutoTokenizer.from_pretrained(\"j-hartmann/emotion-english-distilroberta-base\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"roberta-base\")\n",
        "#tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
        "def tokenize_padding(speakers_list, utterances_list):\n",
        "    tokenized_dialogues = []\n",
        "    max_length = 128  # Adjust the maximum sequence length as needed\n",
        "    for speakers, utterances in zip(speakers_list, utterances_list):#, total=len(utterances_list):\n",
        "        dialogue_with_speakers = []\n",
        "        for speaker, utterance in zip(speakers, utterances):\n",
        "            dialogue_with_speakers.append(utterance)\n",
        "        tokenized_dialogues.append(dialogue_with_speakers)\n",
        "\n",
        "\n",
        "    tokenization = []\n",
        "    for dialogue in tqdm(tokenized_dialogues):\n",
        "      tokenized_dialogue = tokenizer(\n",
        "          dialogue,\n",
        "          #max_length=9,\n",
        "          padding=True,\n",
        "          truncation=False,\n",
        "          return_tensors='pt'\n",
        "      )\n",
        "      tokenization.append(tokenized_dialogue)\n",
        "\n",
        "    input_ids = [dialogue['input_ids'] for dialogue in tokenization]\n",
        "    attention_mask = [dialogue['attention_mask'] for dialogue in tokenization]\n",
        "    return input_ids,attention_mask\n",
        "\n",
        "# Example usage with your dataset:\n",
        "input_ids_train, attention_mask_train = tokenize_padding(train_data['speakers'], train_data['utterances'])\n",
        "#input_ids_val, attention_mask_val = tokenize_padding(val_data['speakers'], val_data['utterances'])\n",
        "input_ids_test, attention_mask_test = tokenize_padding(test_data['speakers'], test_data['utterances'])\n",
        "\n",
        "train_dataset = CustomDataset(input_ids_train, attention_mask_train, train_data['emotions'],\n",
        "                              train_data['triggers'])\n",
        "#validation_dataset = CustomDataset(input_ids_val, attention_mask_val, val_data['emotions'],\n",
        " #                            val_data['triggers'])\n",
        "test_dataset = CustomDataset(input_ids_test, attention_mask_test, test_data['emotions'],\n",
        "                             test_data['triggers'])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-09T18:10:30.659870Z",
          "iopub.execute_input": "2024-02-09T18:10:30.660561Z",
          "iopub.status.idle": "2024-02-09T18:10:34.699938Z",
          "shell.execute_reply.started": "2024-02-09T18:10:30.660528Z",
          "shell.execute_reply": "2024-02-09T18:10:34.698955Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QcJwzYVnlTIZ",
        "outputId": "0fae9fb2-6893-4883-8564-da1c25e266a3"
      },
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2000/2000 [00:01<00:00, 1252.18it/s]\n",
            "100%|██████████| 2000/2000 [00:01<00:00, 1317.88it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import BertModel\n",
        "\n",
        "\n",
        "class Roberta_baseline(torch.nn.Module):\n",
        "    def __init__(self, freeze_embeddings=True):\n",
        "        super(Roberta_baseline, self).__init__()\n",
        "        self.roberta = RobertaModel.from_pretrained('roberta-base')\n",
        "        #self.roberta = RobertaModel.from_pretrained('j-hartmann/emotion-english-distilroberta-base')\n",
        "\n",
        "        if freeze_embeddings:\n",
        "            for name, param in self.roberta.named_parameters():\n",
        "                if 'embeddings' in name:\n",
        "                    param.requires_grad = False\n",
        "        self.emotion_head = torch.nn.Linear(self.roberta.config.hidden_size, len(emotions))\n",
        "        self.trigger_head = torch.nn.Linear(self.roberta.config.hidden_size, len(triggers))\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        outputs = self.roberta(input_ids=input_ids, attention_mask=attention_mask, return_dict=True)\n",
        "        pooled_output = outputs['pooler_output']\n",
        "\n",
        "        emotion_logits = self.emotion_head(pooled_output)\n",
        "        trigger_logits = self.trigger_head(pooled_output)\n",
        "\n",
        "        return emotion_logits, trigger_logits\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-09T18:11:54.502050Z",
          "iopub.execute_input": "2024-02-09T18:11:54.502912Z",
          "iopub.status.idle": "2024-02-09T18:11:54.510342Z",
          "shell.execute_reply.started": "2024-02-09T18:11:54.502878Z",
          "shell.execute_reply": "2024-02-09T18:11:54.509330Z"
        },
        "trusted": true,
        "id": "vEg2SYlOlTIa"
      },
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = torch.nn.CrossEntropyLoss() # can tinker with the loss function, change to a different one\n",
        "#criterion_trigger = torch.nn.BCEWithLogitsLoss()\n",
        "\n",
        "\n",
        "num_epochs = 5\n",
        "batch_size = 32\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
        "freezed_embeddings = False\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "roberta_baseline = Roberta_baseline().to(device)\n",
        "optimizer = torch.optim.AdamW(roberta_baseline.parameters(), lr=1e-5)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-09T18:10:41.758075Z",
          "iopub.execute_input": "2024-02-09T18:10:41.758769Z",
          "iopub.status.idle": "2024-02-09T18:10:46.397175Z",
          "shell.execute_reply.started": "2024-02-09T18:10:41.758740Z",
          "shell.execute_reply": "2024-02-09T18:10:46.396169Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FGb2F6YYlTIa",
        "outputId": "734f21d5-63ba-4b48-fa3e-ac9266a60d48"
      },
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(num_epochs):\n",
        "    roberta_baseline.train()\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for batch in tqdm(train_loader, desc=f'Epoch {epoch + 1}', leave=False):\n",
        "        input_ids,attention_mask,emotion_labels,trigger_label = batch\n",
        "        optimizer.zero_grad()\n",
        "        emotion_loss = 0.0\n",
        "        trigger_loss = 0.0\n",
        "        for el in range(len(input_ids)):\n",
        "\n",
        "          input_ids_el = input_ids[el].squeeze().to(device)\n",
        "          attention_mask_el = attention_mask[el].squeeze().to(device)\n",
        "          emotion_labels_el = emotion_labels[el].squeeze().to(device)\n",
        "          trigger_label_el = trigger_label[el].squeeze().to(device)\n",
        "          # Forward pass\n",
        "          emotion_logits, trigger_logits = roberta_baseline(input_ids_el, attention_mask_el)\n",
        "\n",
        "          emotion_loss += criterion(emotion_logits, torch.argmax(emotion_labels_el, dim=1))\n",
        "          #trigger_loss += criterion(torch.argmax(trigger_logits, dim=1).float(), trigger_label_el.float())\n",
        "          trigger_loss += criterion(trigger_logits, trigger_label_el)\n",
        "\n",
        "        # Combine losses for backpropagation\n",
        "        loss = (emotion_loss + trigger_loss)/len(input_ids)#batch_size\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "    # Compute the average loss\n",
        "    average_loss = total_loss / len(train_loader)\n",
        "    print(f\"Epoch {epoch + 1}, Average Loss: {average_loss}\")\n",
        "    test_bert('test',roberta_baseline)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-09T18:09:41.569379Z",
          "iopub.status.idle": "2024-02-09T18:09:41.569730Z",
          "shell.execute_reply.started": "2024-02-09T18:09:41.569555Z",
          "shell.execute_reply": "2024-02-09T18:09:41.569569Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MDjTs6CYlTIa",
        "outputId": "d5dabaed-707e-4e8f-cbbf-dd0f7bbc6182"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Average Loss: 2.0428851010307434\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Sequence F1 (Emotion):  0.388563\n",
            "Average Sequence F1 (Trigger): 0.438173\n",
            "Unrolled Sequence F1 (Emotion): 0.292144\n",
            "Unrolled Sequence F1 (Trigger): 0.448390\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2, Average Loss: 1.5501572934408037\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Sequence F1 (Emotion):  0.440026\n",
            "Average Sequence F1 (Trigger): 0.438173\n",
            "Unrolled Sequence F1 (Emotion): 0.364738\n",
            "Unrolled Sequence F1 (Trigger): 0.448390\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3, Average Loss: 1.3078779076773024\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Sequence F1 (Emotion):  0.433626\n",
            "Average Sequence F1 (Trigger): 0.438173\n",
            "Unrolled Sequence F1 (Emotion): 0.387289\n",
            "Unrolled Sequence F1 (Trigger): 0.448390\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4, Average Loss: 1.104237905570439\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluation:  42%|████▏     | 835/2000 [00:13<00:16, 70.50it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_ = test_bert('test',roberta_baseline)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-09T18:09:41.571384Z",
          "iopub.status.idle": "2024-02-09T18:09:41.571705Z",
          "shell.execute_reply.started": "2024-02-09T18:09:41.571542Z",
          "shell.execute_reply": "2024-02-09T18:09:41.571555Z"
        },
        "trusted": true,
        "id": "lmpsTN59lTIa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
