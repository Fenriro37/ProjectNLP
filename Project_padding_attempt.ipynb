{
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 7435709,
          "sourceType": "datasetVersion",
          "datasetId": 4327472
        }
      ],
      "dockerImageVersionId": 30636,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#!pip install torch==1.13.0+cu116 --extra-index-url https://download.pytorch.org/whl/cu116\n",
        "!pip install transformers==4.30.0\n",
        "!pip install datasets==2.13.2\n",
        "!pip install accelerate -U\n",
        "!pip install evaluate"
      ],
      "metadata": {
        "id": "vc-YdlGVyh9_",
        "execution": {
          "iopub.status.busy": "2024-01-19T14:52:31.572284Z",
          "iopub.execute_input": "2024-01-19T14:52:31.572710Z",
          "iopub.status.idle": "2024-01-19T14:53:37.461936Z",
          "shell.execute_reply.started": "2024-01-19T14:52:31.572674Z",
          "shell.execute_reply": "2024-01-19T14:53:37.460952Z"
        },
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# system packages\n",
        "from pathlib import Path\n",
        "import shutil\n",
        "import urllib\n",
        "import tarfile\n",
        "import sys\n",
        "import os\n",
        "# data and numerical management packages\n",
        "import pandas as pd\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import BertTokenizer, BertModel, BertForSequenceClassification, AdamW, Trainer, TrainingArguments\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "# useful during debugging (progress bars)\n",
        "from tqdm import tqdm\n",
        "from transformers import set_seed\n",
        "\n",
        "seed = 852\n",
        "\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "set_seed(seed)"
      ],
      "metadata": {
        "id": "pD7fWLEPyh-B",
        "execution": {
          "iopub.status.busy": "2024-01-19T14:54:24.175501Z",
          "iopub.execute_input": "2024-01-19T14:54:24.175879Z",
          "iopub.status.idle": "2024-01-19T14:54:47.215342Z",
          "shell.execute_reply.started": "2024-01-19T14:54:24.175847Z",
          "shell.execute_reply": "2024-01-19T14:54:47.214536Z"
        },
        "trusted": true
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_folder = Path.cwd().joinpath(\"sample_data/MELD_train_efr.json\")\n",
        "#dataset_path = dataset_folder.joinpath('/MELD_train_efr.json')\n",
        "#dataset_folder = \"/kaggle/input/plaplapla/MELD_train_efr.json\"\n",
        "df = pd.read_json(dataset_folder)\n",
        "#df['triggers'] = df['triggers'].fillna(value=0, inplace=False)#.replace('None', 0.0)"
      ],
      "metadata": {
        "id": "6Vnl6q1Qyh-C",
        "execution": {
          "iopub.status.busy": "2024-01-19T14:54:52.271253Z",
          "iopub.execute_input": "2024-01-19T14:54:52.271898Z",
          "iopub.status.idle": "2024-01-19T14:54:52.422899Z",
          "shell.execute_reply.started": "2024-01-19T14:54:52.271866Z",
          "shell.execute_reply": "2024-01-19T14:54:52.421043Z"
        },
        "trusted": true
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "oq9_ohFH3yeX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 597
        },
        "outputId": "5c5872af-b363-4fc7-8ba6-084e994542e2",
        "execution": {
          "iopub.status.busy": "2024-01-19T14:54:53.822422Z",
          "iopub.execute_input": "2024-01-19T14:54:53.823318Z",
          "iopub.status.idle": "2024-01-19T14:54:53.861339Z",
          "shell.execute_reply.started": "2024-01-19T14:54:53.823286Z",
          "shell.execute_reply": "2024-01-19T14:54:53.860540Z"
        },
        "trusted": true
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             episode                                           speakers  \\\n",
              "0        utterance_0  [Chandler, The Interviewer, Chandler, The Inte...   \n",
              "1        utterance_1  [Chandler, The Interviewer, Chandler, The Inte...   \n",
              "2        utterance_2  [Chandler, The Interviewer, Chandler, The Inte...   \n",
              "3        utterance_3  [Chandler, The Interviewer, Chandler, The Inte...   \n",
              "4        utterance_4                       [Joey, Rachel, Joey, Rachel]   \n",
              "...              ...                                                ...   \n",
              "3995  utterance_3995  [Chandler, All, Monica, Chandler, Ross, Chandl...   \n",
              "3996  utterance_3996  [Chandler, All, Monica, Chandler, Ross, Chandl...   \n",
              "3997  utterance_3997  [Chandler, All, Monica, Chandler, Ross, Chandl...   \n",
              "3998  utterance_3998  [Chandler, All, Monica, Chandler, Ross, Chandl...   \n",
              "3999  utterance_3999  [Chandler, All, Monica, Chandler, Ross, Chandl...   \n",
              "\n",
              "                                               emotions  \\\n",
              "0        [neutral, neutral, neutral, neutral, surprise]   \n",
              "1     [neutral, neutral, neutral, neutral, surprise,...   \n",
              "2     [neutral, neutral, neutral, neutral, surprise,...   \n",
              "3     [neutral, neutral, neutral, neutral, surprise,...   \n",
              "4                   [surprise, sadness, surprise, fear]   \n",
              "...                                                 ...   \n",
              "3995  [neutral, joy, neutral, neutral, surprise, dis...   \n",
              "3996  [neutral, joy, neutral, neutral, surprise, dis...   \n",
              "3997  [neutral, joy, neutral, neutral, surprise, dis...   \n",
              "3998  [neutral, joy, neutral, neutral, surprise, dis...   \n",
              "3999  [neutral, joy, neutral, neutral, surprise, dis...   \n",
              "\n",
              "                                             utterances  \\\n",
              "0     [also I was the point person on my company's t...   \n",
              "1     [also I was the point person on my company's t...   \n",
              "2     [also I was the point person on my company's t...   \n",
              "3     [also I was the point person on my company's t...   \n",
              "4     [But then who? The waitress I went out with la...   \n",
              "...                                                 ...   \n",
              "3995  [Hey., Hey!, So how was Joan?, I broke up with...   \n",
              "3996  [Hey., Hey!, So how was Joan?, I broke up with...   \n",
              "3997  [Hey., Hey!, So how was Joan?, I broke up with...   \n",
              "3998  [Hey., Hey!, So how was Joan?, I broke up with...   \n",
              "3999  [Hey., Hey!, So how was Joan?, I broke up with...   \n",
              "\n",
              "                                               triggers  \n",
              "0                             [0.0, 0.0, 0.0, 1.0, 0.0]  \n",
              "1                   [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]  \n",
              "2     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...  \n",
              "3     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
              "4                                  [0.0, 0.0, 1.0, 0.0]  \n",
              "...                                                 ...  \n",
              "3995  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
              "3996  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
              "3997  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
              "3998  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
              "3999  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
              "\n",
              "[4000 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-835d50fb-9eec-424e-bdd7-51772004c00c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>episode</th>\n",
              "      <th>speakers</th>\n",
              "      <th>emotions</th>\n",
              "      <th>utterances</th>\n",
              "      <th>triggers</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>utterance_0</td>\n",
              "      <td>[Chandler, The Interviewer, Chandler, The Inte...</td>\n",
              "      <td>[neutral, neutral, neutral, neutral, surprise]</td>\n",
              "      <td>[also I was the point person on my company's t...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 1.0, 0.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>utterance_1</td>\n",
              "      <td>[Chandler, The Interviewer, Chandler, The Inte...</td>\n",
              "      <td>[neutral, neutral, neutral, neutral, surprise,...</td>\n",
              "      <td>[also I was the point person on my company's t...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>utterance_2</td>\n",
              "      <td>[Chandler, The Interviewer, Chandler, The Inte...</td>\n",
              "      <td>[neutral, neutral, neutral, neutral, surprise,...</td>\n",
              "      <td>[also I was the point person on my company's t...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>utterance_3</td>\n",
              "      <td>[Chandler, The Interviewer, Chandler, The Inte...</td>\n",
              "      <td>[neutral, neutral, neutral, neutral, surprise,...</td>\n",
              "      <td>[also I was the point person on my company's t...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>utterance_4</td>\n",
              "      <td>[Joey, Rachel, Joey, Rachel]</td>\n",
              "      <td>[surprise, sadness, surprise, fear]</td>\n",
              "      <td>[But then who? The waitress I went out with la...</td>\n",
              "      <td>[0.0, 0.0, 1.0, 0.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3995</th>\n",
              "      <td>utterance_3995</td>\n",
              "      <td>[Chandler, All, Monica, Chandler, Ross, Chandl...</td>\n",
              "      <td>[neutral, joy, neutral, neutral, surprise, dis...</td>\n",
              "      <td>[Hey., Hey!, So how was Joan?, I broke up with...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3996</th>\n",
              "      <td>utterance_3996</td>\n",
              "      <td>[Chandler, All, Monica, Chandler, Ross, Chandl...</td>\n",
              "      <td>[neutral, joy, neutral, neutral, surprise, dis...</td>\n",
              "      <td>[Hey., Hey!, So how was Joan?, I broke up with...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3997</th>\n",
              "      <td>utterance_3997</td>\n",
              "      <td>[Chandler, All, Monica, Chandler, Ross, Chandl...</td>\n",
              "      <td>[neutral, joy, neutral, neutral, surprise, dis...</td>\n",
              "      <td>[Hey., Hey!, So how was Joan?, I broke up with...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3998</th>\n",
              "      <td>utterance_3998</td>\n",
              "      <td>[Chandler, All, Monica, Chandler, Ross, Chandl...</td>\n",
              "      <td>[neutral, joy, neutral, neutral, surprise, dis...</td>\n",
              "      <td>[Hey., Hey!, So how was Joan?, I broke up with...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3999</th>\n",
              "      <td>utterance_3999</td>\n",
              "      <td>[Chandler, All, Monica, Chandler, Ross, Chandl...</td>\n",
              "      <td>[neutral, joy, neutral, neutral, surprise, dis...</td>\n",
              "      <td>[Hey., Hey!, So how was Joan?, I broke up with...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4000 rows × 5 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-835d50fb-9eec-424e-bdd7-51772004c00c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-835d50fb-9eec-424e-bdd7-51772004c00c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-835d50fb-9eec-424e-bdd7-51772004c00c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-29c549de-afd0-4341-91be-2497685a41de\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-29c549de-afd0-4341-91be-2497685a41de')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-29c549de-afd0-4341-91be-2497685a41de button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "triggers = df['triggers']\n",
        "for row in range(triggers.shape[0]):\n",
        "    for trigger in range(len(triggers[row])):\n",
        "        if triggers[row][trigger] == None:\n",
        "            triggers[row][trigger] = 0.0\n",
        "\n",
        "df['triggers'] = triggers"
      ],
      "metadata": {
        "id": "PK4MQkLvyh-C",
        "execution": {
          "iopub.status.busy": "2024-01-19T14:55:01.577721Z",
          "iopub.execute_input": "2024-01-19T14:55:01.578604Z",
          "iopub.status.idle": "2024-01-19T14:55:01.766066Z",
          "shell.execute_reply.started": "2024-01-19T14:55:01.578558Z",
          "shell.execute_reply": "2024-01-19T14:55:01.765107Z"
        },
        "trusted": true
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emotions = df['emotions'].explode().unique()\n",
        "emotions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QFfykazN2xDw",
        "outputId": "928b3081-a552-4b80-8fe8-c6ffa38ddc8a",
        "execution": {
          "iopub.status.busy": "2024-01-19T14:55:01.767909Z",
          "iopub.execute_input": "2024-01-19T14:55:01.768190Z",
          "iopub.status.idle": "2024-01-19T14:55:01.786308Z",
          "shell.execute_reply.started": "2024-01-19T14:55:01.768166Z",
          "shell.execute_reply": "2024-01-19T14:55:01.785534Z"
        },
        "trusted": true
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['neutral', 'surprise', 'fear', 'sadness', 'joy', 'disgust',\n",
              "       'anger'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "triggers = df['triggers'].explode().unique()\n",
        "triggers"
      ],
      "metadata": {
        "id": "p10v1luzDn1M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b16388e5-4b26-42a1-eef5-18a983d3ed36",
        "execution": {
          "iopub.status.busy": "2024-01-19T14:55:01.787508Z",
          "iopub.execute_input": "2024-01-19T14:55:01.787866Z",
          "iopub.status.idle": "2024-01-19T14:55:01.801047Z",
          "shell.execute_reply.started": "2024-01-19T14:55:01.787832Z",
          "shell.execute_reply": "2024-01-19T14:55:01.800146Z"
        },
        "trusted": true
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.0, 1.0], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dialogues = df['utterances'][:3200]\n",
        "#print(sentences)\n",
        "max_len_utterance = 0\n",
        "index = 0\n",
        "utterances_len = []\n",
        "for dialogue in dialogues:\n",
        "  for utterance in dialogue:\n",
        "    #print(utterance)\n",
        "    #if len(utterance.split()) > max_len_utterance:\n",
        "     # max_len_utterance = len(utterance.split())\n",
        "     utterances_len.append(len(utterance.split()))\n",
        "np.mean(np.array(utterances_len))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q39q6ZPh-tCy",
        "outputId": "0833fc08-beb9-40cb-c45a-a905ed2110d5",
        "execution": {
          "iopub.status.busy": "2024-01-19T14:55:01.802004Z",
          "iopub.execute_input": "2024-01-19T14:55:01.802575Z",
          "iopub.status.idle": "2024-01-19T14:55:01.815797Z",
          "shell.execute_reply.started": "2024-01-19T14:55:01.802544Z",
          "shell.execute_reply": "2024-01-19T14:55:01.814877Z"
        },
        "trusted": true
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8.077553661956639"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelBinarizer\n",
        "sorted_emotions = sorted(emotions)  #sort the array because Binarizer will automatically do that for one hot encoding\n",
        "label_binarizer = LabelBinarizer()\n",
        "label_binarizer.fit(sorted_emotions)\n",
        "\n",
        "dialogues = df['emotions']\n",
        "one_hot_emotions = []\n",
        "for dialogue_emotion in dialogues:\n",
        "  dialogue_emotions_list = []\n",
        "  for emotion in dialogue_emotion:\n",
        "    encoded_emotion=label_binarizer.transform([emotion])\n",
        "    dialogue_emotions_list.append(np.ravel(encoded_emotion).tolist())\n",
        "  one_hot_emotions.append(dialogue_emotions_list)"
      ],
      "metadata": {
        "id": "H6K5IJ0-NLlL",
        "execution": {
          "iopub.status.busy": "2024-01-19T14:55:01.818813Z",
          "iopub.execute_input": "2024-01-19T14:55:01.819198Z",
          "iopub.status.idle": "2024-01-19T14:55:15.447863Z",
          "shell.execute_reply.started": "2024-01-19T14:55:01.819174Z",
          "shell.execute_reply": "2024-01-19T14:55:15.447026Z"
        },
        "trusted": true
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['emotions'] = one_hot_emotions"
      ],
      "metadata": {
        "id": "fNaWF4KIgIys",
        "execution": {
          "iopub.status.busy": "2024-01-19T14:55:15.449068Z",
          "iopub.execute_input": "2024-01-19T14:55:15.449401Z",
          "iopub.status.idle": "2024-01-19T14:55:15.455432Z",
          "shell.execute_reply.started": "2024-01-19T14:55:15.449371Z",
          "shell.execute_reply": "2024-01-19T14:55:15.454554Z"
        },
        "trusted": true
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_data, temp_data = train_test_split(df, train_size=0.8, shuffle=False)\n",
        "val_data, test_data = train_test_split(temp_data, test_size=0.5, shuffle=False)\n",
        "val_data.reset_index(drop=True, inplace=True)\n",
        "test_data.reset_index(drop=True, inplace=True)"
      ],
      "metadata": {
        "id": "ALZyV8V-kk5k",
        "execution": {
          "iopub.status.busy": "2024-01-19T15:37:31.269362Z",
          "iopub.execute_input": "2024-01-19T15:37:31.269811Z",
          "iopub.status.idle": "2024-01-19T15:37:31.280717Z",
          "shell.execute_reply.started": "2024-01-19T15:37:31.269776Z",
          "shell.execute_reply": "2024-01-19T15:37:31.279818Z"
        },
        "trusted": true
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "def tokenize_padding(dialogues):\n",
        "  tokenized_dialogues = []\n",
        "  max_length = 10\n",
        "\n",
        "  for dialogue in tqdm(dialogues):\n",
        "      tokenized_dialogue = tokenizer(\n",
        "          dialogue,\n",
        "          max_length=9,\n",
        "          padding='max_length',\n",
        "          truncation=True,\n",
        "          return_tensors='pt'\n",
        "      )\n",
        "      tokenized_dialogues.append(tokenized_dialogue)\n",
        "\n",
        "  #padded_input_ids = pad_sequence([dialogue['input_ids'] for dialogue in tokenized_dialogues], batch_first=True)\n",
        "  input_ids = [dialogue['input_ids'] for dialogue in tokenized_dialogues]\n",
        "  attention_mask = [dialogue['attention_mask'] for dialogue in tokenized_dialogues]\n",
        "  return input_ids,attention_mask\n",
        "\n",
        "#padded_input_ids_train,padded_attention_mask_train = tokenize_padding(train_data['utterances'])\n",
        "input_ids_train,attention_mask_train = tokenize_padding(train_data['utterances'])\n",
        "input_ids_val,attention_mask_val = tokenize_padding(val_data['utterances'])\n",
        "input_ids_test,attention_mask_test = tokenize_padding(test_data['utterances'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RLe5H6fW5tMN",
        "outputId": "2f4900f8-22cb-405e-c6f0-b5308636bf7d"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3200/3200 [00:14<00:00, 220.19it/s]\n",
            "100%|██████████| 400/400 [00:01<00:00, 389.36it/s]\n",
            "100%|██████████| 400/400 [00:01<00:00, 396.44it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "def compute_sequence_f1(predictions, labels):\n",
        "    # predictions and labels should be lists of tensors for each dialogue\n",
        "    emotion_f1_scores = []\n",
        "    trigger_f1_scores = []\n",
        "    for emotion_pred, trigger_pred, emotion_lab, trigger_lab in zip(predictions[0], predictions[1], labels[0], labels[1]):\n",
        "        emotion_predicted_classes = torch.argmax(emotion_pred, dim=1)\n",
        "        trigger_predicted_classes = torch.argmax(trigger_pred, dim=1)\n",
        "        emotion_true_classes = torch.argmax(emotion_lab, dim=1)\n",
        "        trigger_true_classes = trigger_lab\n",
        "        emotion_f1 = f1_score(emotion_true_classes.cpu().numpy(), emotion_predicted_classes.cpu().numpy(), average='macro')\n",
        "        trigger_f1 = f1_score(trigger_true_classes.cpu().numpy(), trigger_predicted_classes.cpu().numpy(), average='binary')\n",
        "        emotion_f1_scores.append(emotion_f1)\n",
        "        trigger_f1_scores.append(trigger_f1)\n",
        "    average_emotion_f1 = torch.tensor(emotion_f1_scores, dtype=torch.float32).mean()\n",
        "    average_trigger_f1 = torch.tensor(trigger_f1_scores, dtype=torch.float32).mean()\n",
        "    return average_emotion_f1, average_trigger_f1\n",
        "\n",
        "def compute_unrolled_sequence_f1(predictions, labels):\n",
        "    # Flatten all utterances and compute the F1 score\n",
        "    all_emotion_predicted_classes = torch.argmax(torch.cat(predictions[0], dim=0), dim=1)\n",
        "    all_trigger_predicted_classes = torch.argmax(torch.cat(predictions[1], dim=0), dim=1)\n",
        "    all_emotion_true_classes = torch.argmax(torch.cat(labels[0], dim=0), dim=1)\n",
        "    all_trigger_true_classes = torch.cat(labels[1], dim=0)\n",
        "    unrolled_emotion_f1 = f1_score(all_emotion_true_classes.cpu().numpy(), all_emotion_predicted_classes.cpu().numpy(), average='macro')\n",
        "    unrolled_trigger_f1 = f1_score(all_trigger_true_classes.cpu().numpy(), all_trigger_predicted_classes.cpu().numpy(), average='binary')\n",
        "    unrolled_emotion_f1_tensor = torch.tensor(unrolled_emotion_f1, dtype=torch.float32)\n",
        "    unrolled_trigger_f1_tensor = torch.tensor(unrolled_trigger_f1, dtype=torch.float32)\n",
        "    return unrolled_emotion_f1_tensor, unrolled_trigger_f1_tensor"
      ],
      "metadata": {
        "id": "yx9yj1Kuq7qt"
      },
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, input_ids, attention_mask, emotions, triggers):\n",
        "        self.input_ids = input_ids\n",
        "        self.attention_mask = attention_mask\n",
        "        self.emotions = emotions\n",
        "        self.triggers = triggers\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.emotions)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        input_ids = self.input_ids[idx]\n",
        "        attention_mask = self.attention_mask[idx]\n",
        "        emotion = self.emotions[idx]\n",
        "        trigger = self.triggers[idx]\n",
        "\n",
        "        emotion_labels = torch.tensor(emotion, dtype=torch.float32)\n",
        "        trigger_label = torch.tensor(trigger, dtype=torch.long)\n",
        "        return {\n",
        "            'input_ids': input_ids,\n",
        "            'attention_mask': attention_mask,\n",
        "            'emotion_labels': emotion_labels,\n",
        "            'trigger_label': trigger_label\n",
        "        }"
      ],
      "metadata": {
        "id": "HiiN1Qs9k0DM",
        "execution": {
          "iopub.status.busy": "2024-01-19T14:55:16.624483Z",
          "iopub.execute_input": "2024-01-19T14:55:16.625040Z",
          "iopub.status.idle": "2024-01-19T14:55:16.647212Z",
          "shell.execute_reply.started": "2024-01-19T14:55:16.625013Z",
          "shell.execute_reply": "2024-01-19T14:55:16.646482Z"
        },
        "trusted": true
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomBERTModel(torch.nn.Module):\n",
        "    def __init__(self, freeze_embeddings=True,hidden_size=64, num_layers=1, bidirectional=False):\n",
        "        super(CustomBERTModel, self).__init__()\n",
        "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
        "        if freeze_embeddings:\n",
        "            for name,param in self.bert.named_parameters():\n",
        "                if 'embeddings' in name:\n",
        "                    param.requires_grad = False\n",
        "\n",
        "\n",
        "        #self.fc1 = torch.nn.Linear(self.bert.config.hidden_size, hidden_size)\n",
        "\n",
        "        input_size =  input_size = self.bert.config.hidden_size\n",
        "\n",
        "        self.lstm = torch.nn.LSTM(\n",
        "            input_size=input_size,\n",
        "            hidden_size=hidden_size,\n",
        "            num_layers=num_layers,\n",
        "            bidirectional=bidirectional,\n",
        "            batch_first=True\n",
        "        )\n",
        "\n",
        "        # Linear layer for emotion classification\n",
        "        self.emotion_head = torch.nn.Linear(hidden_size * 2 if bidirectional else hidden_size, len(emotions))\n",
        "\n",
        "        # Linear layer for trigger classification\n",
        "        self.trigger_head = torch.nn.Linear(hidden_size * 2 if bidirectional else hidden_size, len(triggers))\n",
        "\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        \"\"\"outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask, return_dict=True)\n",
        "        pooled_output = outputs['pooler_output']\n",
        "        # Emotion head\n",
        "        emotion_logits = self.emotion_head(pooled_output)\n",
        "\n",
        "        # Trigger head\n",
        "        trigger_logits = self.trigger_head(pooled_output)\n",
        "        return emotion_logits, trigger_logits\"\"\"\n",
        "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask, return_dict=True)\n",
        "        pooled_output = outputs['pooler_output']\n",
        "\n",
        "        #x = torch.nn.functional.relu(self.fc1(pooled_output))\n",
        "\n",
        "        lstm_input = pooled_output.unsqueeze(1).expand(-1, 9, -1)\n",
        "        lstm_output, _ = self.lstm(lstm_input)\n",
        "        # Extract the output from the last time step\n",
        "        lstm_output = lstm_output[:, -1, :]\n",
        "        # Emotion head\n",
        "        emotion_logits = self.emotion_head(lstm_output)\n",
        "\n",
        "        # Trigger head\n",
        "        trigger_logits = self.trigger_head(lstm_output)\n",
        "\n",
        "        return emotion_logits, trigger_logits"
      ],
      "metadata": {
        "id": "MfLGTU4Mkw3V",
        "execution": {
          "iopub.status.busy": "2024-01-19T16:59:48.636076Z",
          "iopub.execute_input": "2024-01-19T16:59:48.636728Z",
          "iopub.status.idle": "2024-01-19T16:59:48.644739Z",
          "shell.execute_reply.started": "2024-01-19T16:59:48.636695Z",
          "shell.execute_reply": "2024-01-19T16:59:48.643907Z"
        },
        "trusted": true
      },
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = CustomDataset(input_ids_train, attention_mask_train, train_data['emotions'],\n",
        "                              train_data['triggers'])\n",
        "validation_dataset = CustomDataset(input_ids_val, attention_mask_val, val_data['emotions'],\n",
        "                             val_data['triggers'])\n",
        "test_dataset = CustomDataset(input_ids_test, attention_mask_test, test_data['emotions'],\n",
        "                             test_data['triggers'])"
      ],
      "metadata": {
        "id": "bUR8qBNelMMl",
        "execution": {
          "iopub.status.busy": "2024-01-19T16:59:52.185789Z",
          "iopub.execute_input": "2024-01-19T16:59:52.186155Z",
          "iopub.status.idle": "2024-01-19T16:59:53.312702Z",
          "shell.execute_reply.started": "2024-01-19T16:59:52.186126Z",
          "shell.execute_reply": "2024-01-19T16:59:53.311901Z"
        },
        "trusted": true
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "def collate_fn(batch):\n",
        "    input_ids = [item['input_ids'] for item in batch]\n",
        "    attention_mask = [item['attention_mask'] for item in batch]\n",
        "    emotion_labels = [item['emotion_labels'] for item in batch]#torch.stack([item['emotion_labels'] for item in batch], dim=0)\n",
        "    trigger_label = [item['trigger_label'] for item in batch]#torch.stack([item['trigger_label'] for item in batch], dim=0)\n",
        "\n",
        "    #input_ids = pad_sequence([torch.stack(item['input_ids']) for item in batch], batch_first=True)\n",
        "    #attention_mask = pad_sequence([torch.stack(item['attention_mask']) for item in batch], batch_first=True)\n",
        "    return input_ids,attention_mask,emotion_labels,trigger_label\n",
        "    #return {'input_ids': input_ids, 'attention_mask': attention_mask, 'emotion_labels': emotion_labels, 'trigger_label': trigger_label"
      ],
      "metadata": {
        "id": "ybP2gK92AU7o"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bert"
      ],
      "metadata": {
        "id": "5-oF31k5JxDt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "criterion_emotion = torch.nn.CrossEntropyLoss() # can tinker with the loss function, change to a different one\n",
        "criterion_trigger = torch.nn.BCEWithLogitsLoss()\n",
        "\n",
        "num_epochs = 20\n",
        "batch_size = 16\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
        "val_loader = DataLoader(validation_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
        "freezed_embeddings = True\n",
        "custom_Bert_Model = CustomBERTModel()\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "custom_Bert_Model = custom_Bert_Model.to(device)\n",
        "optimizer = torch.optim.Adam(custom_Bert_Model.parameters(), lr=5e-5)"
      ],
      "metadata": {
        "id": "X9yT4HSYPXV1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26e044c0-4261-4937-8ef2-5a2f705c88da"
      },
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def test_bert(mode='validation'):\n",
        "# Usage in the eval loop\n",
        "  sequence_f1_scores_emotion = []\n",
        "  sequence_f1_scores_trigger = []\n",
        "  unrolled_predictions_emotion = []\n",
        "  unrolled_predictions_trigger = []\n",
        "  unrolled_labels_emotion = []\n",
        "  unrolled_labels_trigger = []\n",
        "  sequence_f1_scores = []\n",
        "\n",
        "  batch_size = 1\n",
        "  #test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "  if mode == 'validation':\n",
        "    loader = DataLoader(validation_dataset, batch_size=batch_size, shuffle=False)\n",
        "  elif mode == 'test':\n",
        "    loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "  with torch.no_grad():\n",
        "      for batch in tqdm(loader, desc='Evaluation', leave=False):\n",
        "          input_ids = batch['input_ids'].squeeze().to(device)\n",
        "          attention_mask = batch['attention_mask'].squeeze().to(device)\n",
        "          emotion_labels = batch['emotion_labels'].squeeze().to(device)\n",
        "          trigger_label = batch['trigger_label'].squeeze().to(device)\n",
        "\n",
        "          emotion_logits, trigger_logits = custom_Bert_Model(input_ids, attention_mask)\n",
        "\n",
        "          # Store predictions and labels for later unrolled F1 computation\n",
        "          unrolled_predictions_emotion.append(emotion_logits)\n",
        "          unrolled_labels_emotion.append(emotion_labels)\n",
        "          unrolled_predictions_trigger.append(trigger_logits)\n",
        "          unrolled_labels_trigger.append(trigger_label)\n",
        "\n",
        "          # Convert logits to probabilities and then to class predictions\n",
        "          predicted_classes = torch.argmax(emotion_logits, dim=1)\n",
        "          true_classes = torch.argmax(emotion_labels, dim=1)\n",
        "\n",
        "          # Compute F1 for the current sequence (dialogue)\n",
        "          sequence_f1 = f1_score(true_classes.cpu().numpy(), predicted_classes.cpu().numpy(), average='macro')\n",
        "          sequence_f1_scores.append(sequence_f1)\n",
        "\n",
        "  # Compute the average Sequence F1 for emotions and triggers\n",
        "  average_sequence_f1_emotion, average_sequence_f1_trigger = compute_sequence_f1(\n",
        "      [unrolled_predictions_emotion, unrolled_predictions_trigger],\n",
        "      [unrolled_labels_emotion, unrolled_labels_trigger]\n",
        "  )\n",
        "\n",
        "  # Compute the Unrolled Sequence F1 for emotions and triggers\n",
        "  unrolled_sequence_f1_emotion, unrolled_sequence_f1_trigger = compute_unrolled_sequence_f1(\n",
        "      [unrolled_predictions_emotion, unrolled_predictions_trigger],\n",
        "      [unrolled_labels_emotion, unrolled_labels_trigger]\n",
        "  )\n",
        "\n",
        "  # Print the F1 scores for emotions and triggers\n",
        "  print(f\"Average Sequence F1 (Emotion): {average_sequence_f1_emotion}\")\n",
        "  print(f\"Average Sequence F1 (Trigger): {average_sequence_f1_trigger}\")\n",
        "  print(f\"Unrolled Sequence F1 (Emotion): {unrolled_sequence_f1_emotion.item()}\")\n",
        "  print(f\"Unrolled Sequence F1 (Trigger): {unrolled_sequence_f1_trigger.item()}\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-19T17:06:23.721431Z",
          "iopub.execute_input": "2024-01-19T17:06:23.721829Z",
          "iopub.status.idle": "2024-01-19T17:06:32.580790Z",
          "shell.execute_reply.started": "2024-01-19T17:06:23.721805Z",
          "shell.execute_reply": "2024-01-19T17:06:32.579851Z"
        },
        "trusted": true,
        "id": "PhPnLK7ZAQxE"
      },
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(num_epochs):\n",
        "    custom_Bert_Model.train()\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for batch in tqdm(train_loader, desc=f'Epoch {epoch + 1}', leave=False):\n",
        "        input_ids,attention_mask,emotion_labels,trigger_label = batch\n",
        "\n",
        "        # Zero the gradients on the optimizer\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        for el in range(batch_size):\n",
        "          emotion_loss = 0.0\n",
        "          trigger_loss = 0.0\n",
        "\n",
        "          input_ids_el = input_ids[el].squeeze().to(device)\n",
        "          attention_mask_el = attention_mask[el].squeeze().to(device)\n",
        "          emotion_labels_el = emotion_labels[el].squeeze().to(device)\n",
        "          trigger_label_el = trigger_label[el].squeeze().to(device)\n",
        "\n",
        "          # Forward pass\n",
        "          emotion_logits, trigger_logits = custom_Bert_Model(input_ids_el, attention_mask_el)\n",
        "          # Compute the loss for both emotion and trigger\n",
        "\n",
        "          emotion_loss += criterion_emotion(emotion_logits, torch.argmax(emotion_labels_el, dim=1))\n",
        "          trigger_loss += criterion_trigger(torch.argmax(trigger_logits, dim=1).float(), trigger_label_el.float())\n",
        "\n",
        "        # Combine losses for backpropagation\n",
        "        loss = (emotion_loss + trigger_loss)/batch_size\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "    # Compute the average loss\n",
        "    average_loss = total_loss / len(train_loader)\n",
        "    print(f\"Epoch {epoch + 1}, Average Loss: {average_loss}\")\n",
        "    test_bert('validation')"
      ],
      "metadata": {
        "id": "RiM7PzNfsHBm",
        "execution": {
          "iopub.status.busy": "2024-01-19T16:59:59.152258Z",
          "iopub.execute_input": "2024-01-19T16:59:59.152636Z",
          "iopub.status.idle": "2024-01-19T17:06:14.724472Z",
          "shell.execute_reply.started": "2024-01-19T16:59:59.152604Z",
          "shell.execute_reply": "2024-01-19T17:06:14.723552Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 737
        },
        "outputId": "a4b4b60f-a737-40d4-bb56-17e0c8776d13"
      },
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Average Loss: 0.15407862298190594\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Sequence F1 (Emotion): 0.27070796489715576\n",
            "Average Sequence F1 (Trigger): 0.449733167886734\n",
            "Unrolled Sequence F1 (Emotion): 0.17098261415958405\n",
            "Unrolled Sequence F1 (Trigger): 0.49200451374053955\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2, Average Loss: 0.13999401323497296\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Sequence F1 (Emotion): 0.3039402663707733\n",
            "Average Sequence F1 (Trigger): 0.4729042947292328\n",
            "Unrolled Sequence F1 (Emotion): 0.21924729645252228\n",
            "Unrolled Sequence F1 (Trigger): 0.510274350643158\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3, Average Loss: 0.13262631554156543\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Sequence F1 (Emotion): 0.3030347526073456\n",
            "Average Sequence F1 (Trigger): 0.45957833528518677\n",
            "Unrolled Sequence F1 (Emotion): 0.22836025059223175\n",
            "Unrolled Sequence F1 (Trigger): 0.4881386160850525\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4, Average Loss: 0.12252616142854095\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Sequence F1 (Emotion): 0.3007153272628784\n",
            "Average Sequence F1 (Trigger): 0.45699068903923035\n",
            "Unrolled Sequence F1 (Emotion): 0.24919816851615906\n",
            "Unrolled Sequence F1 (Trigger): 0.4994644820690155\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-140-ff2c38747412>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m           \u001b[0;31m# Forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m           \u001b[0memotion_logits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrigger_logits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcustom_Bert_Model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids_el\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask_el\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m           \u001b[0;31m# Compute the loss for both emotion and trigger\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-133-d92c59b021a7>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask)\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mtrigger_logits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrigger_head\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpooled_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         return emotion_logits, trigger_logits\"\"\"\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m         \u001b[0mpooled_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pooler_output'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1018\u001b[0m             \u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1019\u001b[0m         )\n\u001b[0;32m-> 1020\u001b[0;31m         encoder_outputs = self.encoder(\n\u001b[0m\u001b[1;32m   1021\u001b[0m             \u001b[0membedding_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1022\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    608\u001b[0m                 )\n\u001b[1;32m    609\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m                 layer_outputs = layer_module(\n\u001b[0m\u001b[1;32m    611\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    493\u001b[0m         \u001b[0;31m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m         \u001b[0mself_attn_past_key_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpast_key_value\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpast_key_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 495\u001b[0;31m         self_attention_outputs = self.attention(\n\u001b[0m\u001b[1;32m    496\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    423\u001b[0m         \u001b[0moutput_attentions\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m     ) -> Tuple[torch.Tensor]:\n\u001b[0;32m--> 425\u001b[0;31m         self_outputs = self.self(\n\u001b[0m\u001b[1;32m    426\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0mvalue_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpast_key_value\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue_layer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m             \u001b[0mkey_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose_for_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    307\u001b[0m             \u001b[0mvalue_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose_for_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_bert('test')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dnFkphFUgo8R",
        "outputId": "c44eb323-0032-4161-e29b-580592147893"
      },
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Sequence F1 (Emotion): 0.3182724118232727\n",
            "Average Sequence F1 (Trigger): 0.1578434556722641\n",
            "Unrolled Sequence F1 (Emotion): 0.25376445055007935\n",
            "Unrolled Sequence F1 (Trigger): 0.17444218695163727\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Majority classifier"
      ],
      "metadata": {
        "id": "XcYo46z3J0jV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "def find_majority_class(train_loader):\n",
        "    # Initialize counters\n",
        "    emotion_counts = torch.zeros(7) # Assuming there are 7 unique emotions\n",
        "    trigger_counts = torch.zeros(2) # There are 2 classes for triggers: present or not\n",
        "    negative_trigger_counts = 0\n",
        "    positive_trigger_counts = 0\n",
        "    # Iterate over the training dataset to count the labels\n",
        "    for batch in train_loader:\n",
        "        emotion_labels = batch['emotion_labels'].squeeze()\n",
        "        trigger_labels = batch['trigger_label'].squeeze()\n",
        "        #print(trigger_labels,torch.sum(trigger_labels, dim=0),(trigger_labels == 0).sum())\n",
        "        # Sum up the counts for each class\n",
        "        positive_trigger_counts += torch.sum(trigger_labels, dim=0)\n",
        "        # Count the zeros for the negative class (absence of a trigger)\n",
        "        # Since one-hot encoding, the absence is just the inverse of the presence\n",
        "        negative_trigger_counts += torch.sum(1 - trigger_labels, dim=0)\n",
        "        emotion_counts += torch.sum(emotion_labels, dim=0)\n",
        "\n",
        "    trigger_counts[0] = negative_trigger_counts\n",
        "    trigger_counts[1] = positive_trigger_counts\n",
        "    print(trigger_counts)\n",
        "    print(emotion_counts)\n",
        "    # Find the index with the maximum count for emotions and triggers\n",
        "    majority_emotion = torch.zeros_like(emotion_counts)\n",
        "    majority_emotion[torch.argmax(emotion_counts)] = 1\n",
        "    majority_trigger = torch.zeros_like(trigger_counts)\n",
        "    majority_trigger[torch.argmax(trigger_counts)] = 1\n",
        "\n",
        "    return majority_emotion, majority_trigger\n",
        "\n",
        "# Let's assume that 'train_loader' is a DataLoader for your training dataset\n",
        "# You need to replace 'train_loader' with the actual DataLoader for your dataset\n",
        "majority_emotion, majority_trigger = find_majority_class(train_loader)\n",
        "majority_emotion, majority_trigger"
      ],
      "metadata": {
        "id": "EdfQ_Tkn0Hzj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "def majority_classifier(majority_emotion, majority_trigger, test_loader):\n",
        "    all_emotion_predictions = []\n",
        "    all_trigger_predictions = []\n",
        "    all_emotion_labels = []\n",
        "    all_trigger_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(test_loader, desc='Evaluation', leave=False):\n",
        "            emotion_labels = batch['emotion_labels']\n",
        "            trigger_labels = batch['trigger_label']\n",
        "\n",
        "            for emotion_lab, trigger_lab in zip(emotion_labels, trigger_labels):\n",
        "                # Ensure we have at least 1 dimension\n",
        "                if emotion_lab.ndim == 1 and emotion_lab.size(0) == 1:\n",
        "                    emotion_lab = emotion_lab.unsqueeze(0)\n",
        "                if trigger_lab.ndim == 1 and trigger_lab.size(0) == 1:\n",
        "                    trigger_lab = trigger_lab.unsqueeze(0)\n",
        "\n",
        "                # Store the labels\n",
        "                all_emotion_labels.append(emotion_lab)\n",
        "                all_trigger_labels.append(trigger_lab)\n",
        "\n",
        "                # Repeat the majority class prediction to match the number of utterances\n",
        "                emotion_predictions = majority_emotion.repeat(emotion_lab.size(0), 1)\n",
        "                #print(emotion_predictions)\n",
        "\n",
        "                trigger_predictions = majority_trigger.repeat(trigger_lab.size(0), 1)\n",
        "\n",
        "                # Store the predictions\n",
        "                all_emotion_predictions.append(emotion_predictions)\n",
        "                all_trigger_predictions.append(trigger_predictions)\n",
        "\n",
        "    # Use the stored predictions and labels to calculate sequence F1 and unrolled sequence F1\n",
        "    average_sequence_f1_emotion, average_sequence_f1_trigger = compute_sequence_f1(\n",
        "        [all_emotion_predictions, all_trigger_predictions],\n",
        "        [all_emotion_labels, all_trigger_labels]\n",
        "    )\n",
        "\n",
        "    unrolled_sequence_f1_emotion, unrolled_sequence_f1_trigger = compute_unrolled_sequence_f1(\n",
        "        [all_emotion_predictions, all_trigger_predictions],\n",
        "        [all_emotion_labels, all_trigger_labels]\n",
        "    )\n",
        "\n",
        "    return average_sequence_f1_emotion, average_sequence_f1_trigger, unrolled_sequence_f1_emotion, unrolled_sequence_f1_trigger\n",
        "\n",
        "# Assume majority_emotion and majority_trigger are tensors of the majority class (one-hot encoded)\n",
        "# and test_loader is your DataLoader instance for the test dataset.\n",
        "average_f1_emotion, average_f1_trigger, unrolled_f1_emotion, unrolled_f1_trigger = majority_classifier(majority_emotion, majority_trigger, test_loader)\n",
        "\n",
        "print(f\"Average Sequence F1 (Emotion): {average_f1_emotion}\")\n",
        "print(f\"Average Sequence F1 (Trigger): {average_f1_trigger}\")\n",
        "print(f\"Unrolled Sequence F1 (Emotion): {unrolled_f1_emotion}\")\n",
        "print(f\"Unrolled Sequence F1 (Trigger): {unrolled_f1_trigger}\")"
      ],
      "metadata": {
        "id": "J6KeegKyC0d9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Random"
      ],
      "metadata": {
        "id": "iA_NcO9QTaXW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "def random_classifier(test_loader, emotion_distribution, trigger_distribution):\n",
        "    all_emotion_predictions = []\n",
        "    all_trigger_predictions = []\n",
        "    all_emotion_labels = []\n",
        "    all_trigger_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(test_loader, desc='Evaluation', leave=False):\n",
        "            emotion_labels = batch['emotion_labels']\n",
        "            trigger_labels = batch['trigger_label']\n",
        "\n",
        "            for emotion_lab, trigger_lab in zip(emotion_labels, trigger_labels):\n",
        "                # Ensure we have at least 1 dimension\n",
        "                if emotion_lab.ndim == 1 and emotion_lab.size(0) == 1:\n",
        "                    emotion_lab = emotion_lab.unsqueeze(0)\n",
        "                if trigger_lab.ndim == 1 and trigger_lab.size(0) == 1:\n",
        "                    trigger_lab = trigger_lab.unsqueeze(0)\n",
        "\n",
        "                # Store the labels\n",
        "                all_emotion_labels.append(emotion_lab)\n",
        "                all_trigger_labels.append(trigger_lab)\n",
        "\n",
        "                # Generate random predictions for emotions\n",
        "                random_emotion_predictions = torch.randint(0, 2, (emotion_lab.size(0), 7))  # Randomly 0 or 1 for each emotion\n",
        "                all_emotion_predictions.append(random_emotion_predictions.float())\n",
        "\n",
        "                # Generate random predictions for triggers based on the training distribution\n",
        "                random_trigger_probs = torch.rand((trigger_lab.size(0), 1))\n",
        "                random_trigger_predictions = (random_trigger_probs < trigger_distribution).long()  # Binary prediction based on distribution\n",
        "                random_trigger_predictions = torch.cat((random_trigger_predictions, 1 - random_trigger_predictions), dim=1)  # Make it one-hot\n",
        "                all_trigger_predictions.append(random_trigger_predictions.float())\n",
        "\n",
        "    # Calculate the F1 scores using your metric functions\n",
        "    average_sequence_f1_emotion, average_sequence_f1_trigger = compute_sequence_f1(\n",
        "        [all_emotion_predictions, all_trigger_predictions],\n",
        "        [all_emotion_labels, all_trigger_labels]\n",
        "    )\n",
        "\n",
        "    unrolled_sequence_f1_emotion, unrolled_sequence_f1_trigger = compute_unrolled_sequence_f1(\n",
        "        [all_emotion_predictions, all_trigger_predictions],\n",
        "        [all_emotion_labels, all_trigger_labels]\n",
        "    )\n",
        "\n",
        "    return average_sequence_f1_emotion, average_sequence_f1_trigger, unrolled_sequence_f1_emotion, unrolled_sequence_f1_trigger\n",
        "\n",
        "# You need to provide the distribution for the trigger class from your training data\n",
        "# For example, if 30% of your training samples have a trigger, trigger_distribution should be 0.3\n",
        "trigger_distribution = 0.5  # Replace with your actual distribution\n",
        "\n",
        "# Now call your random classifier function\n",
        "average_f1_emotion, average_f1_trigger, unrolled_f1_emotion, unrolled_f1_trigger = random_classifier(\n",
        "    test_loader,\n",
        "    emotion_distribution=None,  # Not used currently as we're assuming a uniform distribution\n",
        "    trigger_distribution=trigger_distribution\n",
        ")\n",
        "\n",
        "print(f\"Random Classifier Average Sequence F1 (Emotion): {average_f1_emotion}\")\n",
        "print(f\"Random Classifier Average Sequence F1 (Trigger): {average_f1_trigger}\")\n",
        "print(f\"Random Classifier Unrolled Sequence F1 (Emotion): {unrolled_f1_emotion}\")\n",
        "print(f\"Random Classifier Unrolled Sequence F1 (Trigger): {unrolled_f1_trigger}\")"
      ],
      "metadata": {
        "id": "PyrbLyM5QezV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bert with context?!?"
      ],
      "metadata": {
        "id": "mX3i2xOzVri2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import BertModel\n",
        "import torch.nn as nn\n",
        "class Attention(nn.Module):\n",
        "    def __init__(self, hidden_size):\n",
        "        super(Attention, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.attention_weights = nn.Parameter(torch.Tensor(hidden_size, 1))\n",
        "        nn.init.xavier_uniform_(self.attention_weights.data)\n",
        "\n",
        "    def forward(self, lstm_output):\n",
        "        # Apply attention weights\n",
        "        attention_scores = torch.matmul(lstm_output, self.attention_weights).squeeze(-1)\n",
        "        attention_scores = torch.softmax(attention_scores, dim=1).unsqueeze(2)\n",
        "\n",
        "        # Apply the attention scores to the lstm_output\n",
        "        weighted_sequence = lstm_output * attention_scores\n",
        "        attended_output = weighted_sequence.sum(dim=1)\n",
        "        return attended_output\n",
        "\n",
        "class BERT(torch.nn.Module):\n",
        "    def __init__(self, num_emotions, num_triggers, freeze_embeddings=True):\n",
        "        super(BERT, self).__init__()\n",
        "        self.bert = BertModel.from_pretrained('bert-base-uncased')#BertForSequenceClassification.from_pretrained\n",
        "        #LSTM\n",
        "        if freeze_embeddings:\n",
        "            for name,param in self.bert.named_parameters():\n",
        "                if 'embeddings' in name:\n",
        "                    param.requires_grad = False\n",
        "        # The size of the hidden layer in the LSTM, which will be the same as the BERT hidden size\n",
        "        self.lstm_hidden_size = self.bert.config.hidden_size\n",
        "\n",
        "        # Define a bidirectional LSTM layer that processes the full sequence of BERT outputs\n",
        "        self.lstm = nn.LSTM(input_size=self.lstm_hidden_size,\n",
        "                            hidden_size=self.lstm_hidden_size,\n",
        "                            num_layers=1,\n",
        "                            batch_first=True,\n",
        "                            bidirectional=True)\n",
        "\n",
        "        # Define the emotion and trigger heads with an input size that is twice the BERT hidden size\n",
        "        # because the LSTM is bidirectional\n",
        "        self.attention = Attention(self.lstm_hidden_size * 2)  # Because LSTM is bidirectional\n",
        "\n",
        "        self.emotion_head = nn.Linear(self.lstm_hidden_size * 2, num_emotions)\n",
        "        self.trigger_head = nn.Linear(self.lstm_hidden_size * 2, num_triggers)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        bert_outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask, return_dict=True)\n",
        "        bert_sequence_output = bert_outputs.last_hidden_state\n",
        "\n",
        "        lstm_output, (h_n, c_n) = self.lstm(bert_sequence_output)\n",
        "\n",
        "        # Apply attention to the LSTM output\n",
        "        attended_output = self.attention(lstm_output)\n",
        "\n",
        "        emotion_logits = self.emotion_head(attended_output)\n",
        "        trigger_logits = self.trigger_head(attended_output)\n",
        "\n",
        "        return emotion_logits, trigger_logits"
      ],
      "metadata": {
        "id": "mBTnJPl1Z3Y_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_emotions = 7\n",
        "num_triggers = 2\n",
        "\n",
        "# Instantiate the model\n",
        "BERT_lstm = BERT(num_emotions,num_triggers).to(device)\n",
        "#optimizer = AdamW(filter(lambda p: p.requires_grad, custom_Bert_Model.parameters()), lr=5e-5)\n",
        "optimizer = torch.optim.Adam(BERT_lstm.parameters(), lr=5e-5)"
      ],
      "metadata": {
        "id": "RPrAMRrMXZt5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 2\n",
        "batch_size = 1\n",
        "for epoch in range(num_epochs):\n",
        "    BERT_lstm.train()\n",
        "    total_loss = 0.0\n",
        "    loss_emotion = 0.0\n",
        "    loss_trigger = 0.0\n",
        "    for batch in tqdm(train_loader, desc=f'Epoch {epoch + 1}', leave=False):\n",
        "        input_ids = batch['input_ids'].squeeze().to(device)\n",
        "        attention_mask = batch['attention_mask'].squeeze().to(device)\n",
        "        emotion_labels = batch['emotion_labels'].squeeze().to(device)\n",
        "        trigger_label = batch['trigger_label'].squeeze().to(device)\n",
        "\n",
        "        # Zero the gradients on the optimizer\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        emotion_logits, trigger_logits = BERT_lstm(input_ids, attention_mask)\n",
        "\n",
        "        # Compute the loss for both emotion and trigger\n",
        "        emotion_loss = criterion(emotion_logits, torch.argmax(emotion_labels, dim=1))\n",
        "        trigger_loss = criterion(trigger_logits, trigger_label)\n",
        "\n",
        "        # Combine losses for backpropagation\n",
        "        loss = emotion_loss + trigger_loss\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        loss_emotion += emotion_loss\n",
        "        loss_trigger += trigger_loss\n",
        "\n",
        "    # Compute the average loss\n",
        "    average_loss = total_loss / len(train_loader)\n",
        "    print(f\"Epoch {epoch + 1}, Average Loss: {average_loss}\")\n",
        "    print(f\"Epoch {epoch + 1}, Emotion Loss: {loss_emotion/len(train_loader)}\")\n",
        "    print(f\"Epoch {epoch + 1}, Trigger Loss: {loss_trigger/len(train_loader)}\")"
      ],
      "metadata": {
        "id": "9937TpiLcD4I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Usage in the eval loop\n",
        "sequence_f1_scores_emotion = []\n",
        "sequence_f1_scores_trigger = []\n",
        "unrolled_predictions_emotion = []\n",
        "unrolled_predictions_trigger = []\n",
        "unrolled_labels_emotion = []\n",
        "unrolled_labels_trigger = []\n",
        "sequence_f1_scores = []\n",
        "\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in tqdm(test_loader, desc='Evaluation', leave=False):\n",
        "        input_ids = batch['input_ids'].squeeze().to(device)\n",
        "        attention_mask = batch['attention_mask'].squeeze().to(device)\n",
        "        emotion_labels = batch['emotion_labels'].squeeze().to(device)\n",
        "        trigger_label = batch['trigger_label'].squeeze().to(device)\n",
        "\n",
        "        emotion_logits, trigger_logits = BERT_lstm(input_ids, attention_mask)\n",
        "\n",
        "        # Store predictions and labels for later unrolled F1 computation\n",
        "        unrolled_predictions_emotion.append(emotion_logits)\n",
        "        unrolled_labels_emotion.append(emotion_labels)\n",
        "        unrolled_predictions_trigger.append(trigger_logits)\n",
        "        unrolled_labels_trigger.append(trigger_label)\n",
        "\n",
        "        # Convert logits to probabilities and then to class predictions\n",
        "        predicted_classes = torch.argmax(emotion_logits, dim=1)\n",
        "        true_classes = torch.argmax(emotion_labels, dim=1)\n",
        "\n",
        "        # Compute F1 for the current sequence (dialogue)\n",
        "        sequence_f1 = f1_score(true_classes.cpu().numpy(), predicted_classes.cpu().numpy(), average='macro')\n",
        "        sequence_f1_scores.append(sequence_f1)\n",
        "\n",
        "# Compute the average Sequence F1 for emotions and triggers\n",
        "average_sequence_f1_emotion, average_sequence_f1_trigger = compute_sequence_f1(\n",
        "    [unrolled_predictions_emotion, unrolled_predictions_trigger],\n",
        "    [unrolled_labels_emotion, unrolled_labels_trigger]\n",
        ")\n",
        "\n",
        "# Compute the Unrolled Sequence F1 for emotions and triggers\n",
        "unrolled_sequence_f1_emotion, unrolled_sequence_f1_trigger = compute_unrolled_sequence_f1(\n",
        "    [unrolled_predictions_emotion, unrolled_predictions_trigger],\n",
        "    [unrolled_labels_emotion, unrolled_labels_trigger]\n",
        ")\n",
        "\n",
        "# Print the F1 scores for emotions and triggers\n",
        "print(f\"Average Sequence F1 (Emotion): {average_sequence_f1_emotion}\")\n",
        "print(f\"Average Sequence F1 (Trigger): {average_sequence_f1_trigger}\")\n",
        "print(f\"Unrolled Sequence F1 (Emotion): {unrolled_sequence_f1_emotion.item()}\")\n",
        "print(f\"Unrolled Sequence F1 (Trigger): {unrolled_sequence_f1_trigger.item()}\")"
      ],
      "metadata": {
        "id": "NRliJGnfeKmp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}