{
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 7435709,
          "sourceType": "datasetVersion",
          "datasetId": 4327472
        }
      ],
      "dockerImageVersionId": 30636,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ff52c6d48f2e46b8836024f9702021c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dcb25a44229048c7aede8c1b3be1957b",
              "IPY_MODEL_10766895ac3c43ce9fe5a07ff769793e",
              "IPY_MODEL_0f020cffac704d23bc85150c124c948a"
            ],
            "layout": "IPY_MODEL_df23edce392f46e8b8e96a49cc76c2a7"
          }
        },
        "dcb25a44229048c7aede8c1b3be1957b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c80ee61459ed41fdafc24bb2dd363bd4",
            "placeholder": "​",
            "style": "IPY_MODEL_99c5a2f3661b4ec79be0fc6806d3451b",
            "value": "Evaluation:  98%"
          }
        },
        "10766895ac3c43ce9fe5a07ff769793e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fe5536e595694015b5e5452048f1d4f9",
            "max": 400,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3a8dab2fdd8e47358126ee30730a18a8",
            "value": 400
          }
        },
        "0f020cffac704d23bc85150c124c948a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_de9ee7bc51844a91938f579a2c2d14cb",
            "placeholder": "​",
            "style": "IPY_MODEL_e9d4ca079cb34c428a7111181bc21d23",
            "value": " 390/400 [00:04&lt;00:00, 126.46it/s]"
          }
        },
        "df23edce392f46e8b8e96a49cc76c2a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "c80ee61459ed41fdafc24bb2dd363bd4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "99c5a2f3661b4ec79be0fc6806d3451b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fe5536e595694015b5e5452048f1d4f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a8dab2fdd8e47358126ee30730a18a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "de9ee7bc51844a91938f579a2c2d14cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e9d4ca079cb34c428a7111181bc21d23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f8960bcf6cd746548648ee8df3cc6c65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_564791db471941c8a35dfdec947c4bd0",
              "IPY_MODEL_b80b232ad5ce473fbe3738b68bd7ba1a",
              "IPY_MODEL_eb1a9f01dc0346cba7457db346ccc38d"
            ],
            "layout": "IPY_MODEL_12983111e8644952ba71586dd440ab5e"
          }
        },
        "564791db471941c8a35dfdec947c4bd0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_03212a0e355540ffa628f396d0e15e53",
            "placeholder": "​",
            "style": "IPY_MODEL_d9177f45f2724968b50384377cf7a9d3",
            "value": "Evaluation:  99%"
          }
        },
        "b80b232ad5ce473fbe3738b68bd7ba1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f5c137cad3ed4022909b16717e714955",
            "max": 400,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d47c944fedb4456d872559e12717f7de",
            "value": 400
          }
        },
        "eb1a9f01dc0346cba7457db346ccc38d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_17a02ecdec3049668a8f9b6e57eed9f6",
            "placeholder": "​",
            "style": "IPY_MODEL_7eaa2fd9c84048eb9167ff83edf73734",
            "value": " 395/400 [00:03&lt;00:00, 137.53it/s]"
          }
        },
        "12983111e8644952ba71586dd440ab5e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "03212a0e355540ffa628f396d0e15e53": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d9177f45f2724968b50384377cf7a9d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f5c137cad3ed4022909b16717e714955": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d47c944fedb4456d872559e12717f7de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "17a02ecdec3049668a8f9b6e57eed9f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7eaa2fd9c84048eb9167ff83edf73734": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "720b22ca40d149b5b58e34a11cc3b984": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_600a0af640814babb3e97ee6c1a389f0",
              "IPY_MODEL_aee3e6d6aa254789a0d6015f5056bc41",
              "IPY_MODEL_3d010c30d90a422aaa9d0ff49a8a580a"
            ],
            "layout": "IPY_MODEL_c163528f1b2d477d910dc96e7be50aa3"
          }
        },
        "600a0af640814babb3e97ee6c1a389f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_370e3091d2504c9cae3470cadfa682e7",
            "placeholder": "​",
            "style": "IPY_MODEL_c4b3188d527949419d61e80ba92ad008",
            "value": "spiece.model: 100%"
          }
        },
        "aee3e6d6aa254789a0d6015f5056bc41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4e94dbf4b7db45308dd5f08b8b63a248",
            "max": 798011,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8630fc0f4f1d40df81008c782ff3c6d6",
            "value": 798011
          }
        },
        "3d010c30d90a422aaa9d0ff49a8a580a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6467c2d272da4aa6aa663f19517ec56d",
            "placeholder": "​",
            "style": "IPY_MODEL_74bf0a5fc68042e7be4ba2bd65b372a4",
            "value": " 798k/798k [00:00&lt;00:00, 4.38MB/s]"
          }
        },
        "c163528f1b2d477d910dc96e7be50aa3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "370e3091d2504c9cae3470cadfa682e7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c4b3188d527949419d61e80ba92ad008": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4e94dbf4b7db45308dd5f08b8b63a248": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8630fc0f4f1d40df81008c782ff3c6d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6467c2d272da4aa6aa663f19517ec56d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "74bf0a5fc68042e7be4ba2bd65b372a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3eb9cdca194b4e669e25eec47d25a0b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7425abc3069948d281fc7980d1108489",
              "IPY_MODEL_87ca886ca6414f2aa9fd4372ba696b77",
              "IPY_MODEL_5ef9c894b407485f949b375bdc7368ba"
            ],
            "layout": "IPY_MODEL_739d7ff07f484951bade8b9643a80bee"
          }
        },
        "7425abc3069948d281fc7980d1108489": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e69171725dae4808a891c008e803281d",
            "placeholder": "​",
            "style": "IPY_MODEL_63bd6d9236d74f40835f45cbef407710",
            "value": "config.json: 100%"
          }
        },
        "87ca886ca6414f2aa9fd4372ba696b77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_624fb418b8d5479f9c647385208ad6c7",
            "max": 760,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4554b11dbcce4339b71d286d77ced1de",
            "value": 760
          }
        },
        "5ef9c894b407485f949b375bdc7368ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0cd38756e096483583b3e2e2403c4202",
            "placeholder": "​",
            "style": "IPY_MODEL_f594d291d33c427490f0813f69133962",
            "value": " 760/760 [00:00&lt;00:00, 27.4kB/s]"
          }
        },
        "739d7ff07f484951bade8b9643a80bee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e69171725dae4808a891c008e803281d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "63bd6d9236d74f40835f45cbef407710": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "624fb418b8d5479f9c647385208ad6c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4554b11dbcce4339b71d286d77ced1de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0cd38756e096483583b3e2e2403c4202": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f594d291d33c427490f0813f69133962": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#!pip install torch==1.13.0+cu116 --extra-index-url https://download.pytorch.org/whl/cu116\n",
        "!pip install transformers==4.30.0\n",
        "!pip install datasets==2.13.2\n",
        "!pip install accelerate -U\n",
        "!pip install evaluate\n",
        "!pip install sentencepiece"
      ],
      "metadata": {
        "id": "vc-YdlGVyh9_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff7cbec2-62a0-4ca5-a25e-e78547290ab4",
        "execution": {
          "iopub.status.busy": "2024-01-19T14:52:31.572284Z",
          "iopub.execute_input": "2024-01-19T14:52:31.572710Z",
          "iopub.status.idle": "2024-01-19T14:53:37.461936Z",
          "shell.execute_reply.started": "2024-01-19T14:52:31.572674Z",
          "shell.execute_reply": "2024-01-19T14:53:37.460952Z"
        },
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "trusted": true
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers==4.30.0\n",
            "  Downloading transformers-4.30.0-py3-none-any.whl (7.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.30.0) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.30.0) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.30.0) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.30.0) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.30.0) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.30.0) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.30.0) (2.31.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers==4.30.0)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m48.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.30.0) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.30.0) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers==4.30.0) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers==4.30.0) (4.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.30.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.30.0) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.30.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.30.0) (2024.2.2)\n",
            "Installing collected packages: tokenizers, transformers\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.15.1\n",
            "    Uninstalling tokenizers-0.15.1:\n",
            "      Successfully uninstalled tokenizers-0.15.1\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.35.2\n",
            "    Uninstalling transformers-4.35.2:\n",
            "      Successfully uninstalled transformers-4.35.2\n",
            "Successfully installed tokenizers-0.13.3 transformers-4.30.0\n",
            "Collecting datasets==2.13.2\n",
            "  Downloading datasets-2.13.2-py3-none-any.whl (512 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m512.7/512.7 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets==2.13.2) (1.23.5)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets==2.13.2) (10.0.1)\n",
            "Collecting dill<0.3.7,>=0.3.0 (from datasets==2.13.2)\n",
            "  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets==2.13.2) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets==2.13.2) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets==2.13.2) (4.66.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets==2.13.2) (3.4.1)\n",
            "Collecting multiprocess (from datasets==2.13.2)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets==2.13.2) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets==2.13.2) (3.9.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from datasets==2.13.2) (0.20.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets==2.13.2) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets==2.13.2) (6.0.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.13.2) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.13.2) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.13.2) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.13.2) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.13.2) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.13.2) (4.0.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets==2.13.2) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets==2.13.2) (4.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets==2.13.2) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets==2.13.2) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets==2.13.2) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets==2.13.2) (2024.2.2)\n",
            "INFO: pip is looking at multiple versions of multiprocess to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading multiprocess-0.70.14-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.3/134.3 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets==2.13.2) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets==2.13.2) (2023.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets==2.13.2) (1.16.0)\n",
            "Installing collected packages: dill, multiprocess, datasets\n",
            "Successfully installed datasets-2.13.2 dill-0.3.6 multiprocess-0.70.14\n",
            "Collecting accelerate\n",
            "  Downloading accelerate-0.27.0-py3-none-any.whl (279 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m279.7/279.7 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.1.0+cu121)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.20.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.9.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Installing collected packages: accelerate\n",
            "Successfully installed accelerate-0.27.0\n",
            "Collecting evaluate\n",
            "  Downloading evaluate-0.4.1-py3-none-any.whl (84 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.13.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.23.5)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.3.6)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.66.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.70.14)\n",
            "Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2023.6.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.20.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (23.2)\n",
            "Collecting responses<0.19 (from evaluate)\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (10.0.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.9.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2023.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->evaluate) (1.16.0)\n",
            "Installing collected packages: responses, evaluate\n",
            "Successfully installed evaluate-0.4.1 responses-0.18.0\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.1.99)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# system packages\n",
        "from pathlib import Path\n",
        "import shutil\n",
        "import urllib\n",
        "import tarfile\n",
        "import sys\n",
        "import os\n",
        "# data and numerical management packages\n",
        "import pandas as pd\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "# useful during debugging (progress bars)\n",
        "from tqdm import tqdm\n",
        "from transformers import set_seed\n",
        "\n",
        "seed = 852\n",
        "\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "set_seed(seed)"
      ],
      "metadata": {
        "id": "pD7fWLEPyh-B",
        "execution": {
          "iopub.status.busy": "2024-01-19T14:54:24.175501Z",
          "iopub.execute_input": "2024-01-19T14:54:24.175879Z",
          "iopub.status.idle": "2024-01-19T14:54:47.215342Z",
          "shell.execute_reply.started": "2024-01-19T14:54:24.175847Z",
          "shell.execute_reply": "2024-01-19T14:54:47.214536Z"
        },
        "trusted": true
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "nqfoRhffA2u_",
        "outputId": "6ea223b5-7875-4770-ba30-60dc0a6539ad"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_folder = Path.cwd().joinpath(\"MELD_train_efr.json\")\n",
        "#dataset_path = dataset_folder.joinpath('/MELD_train_efr.json')\n",
        "#dataset_folder = \"/kaggle/input/plaplapla/MELD_train_efr.json\"\n",
        "df = pd.read_json(dataset_folder)\n",
        "#df['triggers'] = df['triggers'].fillna(value=0, inplace=False)#.replace('None', 0.0)"
      ],
      "metadata": {
        "id": "6Vnl6q1Qyh-C",
        "execution": {
          "iopub.status.busy": "2024-01-19T14:54:52.271253Z",
          "iopub.execute_input": "2024-01-19T14:54:52.271898Z",
          "iopub.status.idle": "2024-01-19T14:54:52.422899Z",
          "shell.execute_reply.started": "2024-01-19T14:54:52.271866Z",
          "shell.execute_reply": "2024-01-19T14:54:52.421043Z"
        },
        "trusted": true
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "oq9_ohFH3yeX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 770
        },
        "outputId": "daedbd01-c502-4d6e-e805-8043ef43f80a",
        "execution": {
          "iopub.status.busy": "2024-01-19T14:54:53.822422Z",
          "iopub.execute_input": "2024-01-19T14:54:53.823318Z",
          "iopub.status.idle": "2024-01-19T14:54:53.861339Z",
          "shell.execute_reply.started": "2024-01-19T14:54:53.823286Z",
          "shell.execute_reply": "2024-01-19T14:54:53.860540Z"
        },
        "trusted": true
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             episode                                           speakers  \\\n",
              "0        utterance_0  [Chandler, The Interviewer, Chandler, The Inte...   \n",
              "1        utterance_1  [Chandler, The Interviewer, Chandler, The Inte...   \n",
              "2        utterance_2  [Chandler, The Interviewer, Chandler, The Inte...   \n",
              "3        utterance_3  [Chandler, The Interviewer, Chandler, The Inte...   \n",
              "4        utterance_4                       [Joey, Rachel, Joey, Rachel]   \n",
              "...              ...                                                ...   \n",
              "3995  utterance_3995  [Chandler, All, Monica, Chandler, Ross, Chandl...   \n",
              "3996  utterance_3996  [Chandler, All, Monica, Chandler, Ross, Chandl...   \n",
              "3997  utterance_3997  [Chandler, All, Monica, Chandler, Ross, Chandl...   \n",
              "3998  utterance_3998  [Chandler, All, Monica, Chandler, Ross, Chandl...   \n",
              "3999  utterance_3999  [Chandler, All, Monica, Chandler, Ross, Chandl...   \n",
              "\n",
              "                                               emotions  \\\n",
              "0        [neutral, neutral, neutral, neutral, surprise]   \n",
              "1     [neutral, neutral, neutral, neutral, surprise,...   \n",
              "2     [neutral, neutral, neutral, neutral, surprise,...   \n",
              "3     [neutral, neutral, neutral, neutral, surprise,...   \n",
              "4                   [surprise, sadness, surprise, fear]   \n",
              "...                                                 ...   \n",
              "3995  [neutral, joy, neutral, neutral, surprise, dis...   \n",
              "3996  [neutral, joy, neutral, neutral, surprise, dis...   \n",
              "3997  [neutral, joy, neutral, neutral, surprise, dis...   \n",
              "3998  [neutral, joy, neutral, neutral, surprise, dis...   \n",
              "3999  [neutral, joy, neutral, neutral, surprise, dis...   \n",
              "\n",
              "                                             utterances  \\\n",
              "0     [also I was the point person on my company's t...   \n",
              "1     [also I was the point person on my company's t...   \n",
              "2     [also I was the point person on my company's t...   \n",
              "3     [also I was the point person on my company's t...   \n",
              "4     [But then who? The waitress I went out with la...   \n",
              "...                                                 ...   \n",
              "3995  [Hey., Hey!, So how was Joan?, I broke up with...   \n",
              "3996  [Hey., Hey!, So how was Joan?, I broke up with...   \n",
              "3997  [Hey., Hey!, So how was Joan?, I broke up with...   \n",
              "3998  [Hey., Hey!, So how was Joan?, I broke up with...   \n",
              "3999  [Hey., Hey!, So how was Joan?, I broke up with...   \n",
              "\n",
              "                                               triggers  \n",
              "0                             [0.0, 0.0, 0.0, 1.0, 0.0]  \n",
              "1                   [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]  \n",
              "2     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...  \n",
              "3     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
              "4                                  [0.0, 0.0, 1.0, 0.0]  \n",
              "...                                                 ...  \n",
              "3995  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
              "3996  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
              "3997  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
              "3998  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
              "3999  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
              "\n",
              "[4000 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d1ac3f3a-02d4-43d6-8839-87665b5f7af1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>episode</th>\n",
              "      <th>speakers</th>\n",
              "      <th>emotions</th>\n",
              "      <th>utterances</th>\n",
              "      <th>triggers</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>utterance_0</td>\n",
              "      <td>[Chandler, The Interviewer, Chandler, The Inte...</td>\n",
              "      <td>[neutral, neutral, neutral, neutral, surprise]</td>\n",
              "      <td>[also I was the point person on my company's t...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 1.0, 0.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>utterance_1</td>\n",
              "      <td>[Chandler, The Interviewer, Chandler, The Inte...</td>\n",
              "      <td>[neutral, neutral, neutral, neutral, surprise,...</td>\n",
              "      <td>[also I was the point person on my company's t...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>utterance_2</td>\n",
              "      <td>[Chandler, The Interviewer, Chandler, The Inte...</td>\n",
              "      <td>[neutral, neutral, neutral, neutral, surprise,...</td>\n",
              "      <td>[also I was the point person on my company's t...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>utterance_3</td>\n",
              "      <td>[Chandler, The Interviewer, Chandler, The Inte...</td>\n",
              "      <td>[neutral, neutral, neutral, neutral, surprise,...</td>\n",
              "      <td>[also I was the point person on my company's t...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>utterance_4</td>\n",
              "      <td>[Joey, Rachel, Joey, Rachel]</td>\n",
              "      <td>[surprise, sadness, surprise, fear]</td>\n",
              "      <td>[But then who? The waitress I went out with la...</td>\n",
              "      <td>[0.0, 0.0, 1.0, 0.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3995</th>\n",
              "      <td>utterance_3995</td>\n",
              "      <td>[Chandler, All, Monica, Chandler, Ross, Chandl...</td>\n",
              "      <td>[neutral, joy, neutral, neutral, surprise, dis...</td>\n",
              "      <td>[Hey., Hey!, So how was Joan?, I broke up with...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3996</th>\n",
              "      <td>utterance_3996</td>\n",
              "      <td>[Chandler, All, Monica, Chandler, Ross, Chandl...</td>\n",
              "      <td>[neutral, joy, neutral, neutral, surprise, dis...</td>\n",
              "      <td>[Hey., Hey!, So how was Joan?, I broke up with...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3997</th>\n",
              "      <td>utterance_3997</td>\n",
              "      <td>[Chandler, All, Monica, Chandler, Ross, Chandl...</td>\n",
              "      <td>[neutral, joy, neutral, neutral, surprise, dis...</td>\n",
              "      <td>[Hey., Hey!, So how was Joan?, I broke up with...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3998</th>\n",
              "      <td>utterance_3998</td>\n",
              "      <td>[Chandler, All, Monica, Chandler, Ross, Chandl...</td>\n",
              "      <td>[neutral, joy, neutral, neutral, surprise, dis...</td>\n",
              "      <td>[Hey., Hey!, So how was Joan?, I broke up with...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3999</th>\n",
              "      <td>utterance_3999</td>\n",
              "      <td>[Chandler, All, Monica, Chandler, Ross, Chandl...</td>\n",
              "      <td>[neutral, joy, neutral, neutral, surprise, dis...</td>\n",
              "      <td>[Hey., Hey!, So how was Joan?, I broke up with...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4000 rows × 5 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d1ac3f3a-02d4-43d6-8839-87665b5f7af1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d1ac3f3a-02d4-43d6-8839-87665b5f7af1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d1ac3f3a-02d4-43d6-8839-87665b5f7af1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-cc36629c-1829-434b-a473-8d22bcee9c2e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-cc36629c-1829-434b-a473-8d22bcee9c2e')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-cc36629c-1829-434b-a473-8d22bcee9c2e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_5d03d010-3793-4f19-8d0d-c223ed3fd069\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_5d03d010-3793-4f19-8d0d-c223ed3fd069 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "triggers = df['triggers']\n",
        "for row in range(triggers.shape[0]):\n",
        "    for trigger in range(len(triggers[row])):\n",
        "        if triggers[row][trigger] == None:\n",
        "            triggers[row][trigger] = 0.0\n",
        "\n",
        "df['triggers'] = triggers"
      ],
      "metadata": {
        "id": "PK4MQkLvyh-C",
        "execution": {
          "iopub.status.busy": "2024-01-19T14:55:01.577721Z",
          "iopub.execute_input": "2024-01-19T14:55:01.578604Z",
          "iopub.status.idle": "2024-01-19T14:55:01.766066Z",
          "shell.execute_reply.started": "2024-01-19T14:55:01.578558Z",
          "shell.execute_reply": "2024-01-19T14:55:01.765107Z"
        },
        "trusted": true
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emotions = df['emotions'].explode().unique()\n",
        "emotions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QFfykazN2xDw",
        "outputId": "b90cb297-b167-4aa2-e4fd-709d4d680832",
        "execution": {
          "iopub.status.busy": "2024-01-19T14:55:01.767909Z",
          "iopub.execute_input": "2024-01-19T14:55:01.768190Z",
          "iopub.status.idle": "2024-01-19T14:55:01.786308Z",
          "shell.execute_reply.started": "2024-01-19T14:55:01.768166Z",
          "shell.execute_reply": "2024-01-19T14:55:01.785534Z"
        },
        "trusted": true
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['neutral', 'surprise', 'fear', 'sadness', 'joy', 'disgust',\n",
              "       'anger'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "triggers = df['triggers'].explode().unique()\n",
        "triggers"
      ],
      "metadata": {
        "id": "p10v1luzDn1M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6093b08e-b870-4738-9efd-e3fa224b74a5",
        "execution": {
          "iopub.status.busy": "2024-01-19T14:55:01.787508Z",
          "iopub.execute_input": "2024-01-19T14:55:01.787866Z",
          "iopub.status.idle": "2024-01-19T14:55:01.801047Z",
          "shell.execute_reply.started": "2024-01-19T14:55:01.787832Z",
          "shell.execute_reply": "2024-01-19T14:55:01.800146Z"
        },
        "trusted": true
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.0, 1.0], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dialogues = df['utterances']\n",
        "#print(sentences)\n",
        "max_len_dialogue = 0\n",
        "index = 0\n",
        "for idx, dialogue in enumerate(dialogues):\n",
        "  if len(dialogue) > max_len_dialogue:\n",
        "    max_len_dialogue = len(dialogue)\n",
        "    index = idx\n",
        "max_len_dialogue,index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q39q6ZPh-tCy",
        "outputId": "d0ec9a16-803e-46db-df34-56be49ff8fb0",
        "execution": {
          "iopub.status.busy": "2024-01-19T14:55:01.802004Z",
          "iopub.execute_input": "2024-01-19T14:55:01.802575Z",
          "iopub.status.idle": "2024-01-19T14:55:01.815797Z",
          "shell.execute_reply.started": "2024-01-19T14:55:01.802544Z",
          "shell.execute_reply": "2024-01-19T14:55:01.814877Z"
        },
        "trusted": true
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(24, 219)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelBinarizer\n",
        "sorted_emotions = sorted(emotions)  #sort the array because Binarizer will automatically do that for one hot encoding\n",
        "label_binarizer = LabelBinarizer()\n",
        "label_binarizer.fit(sorted_emotions)\n",
        "\n",
        "dialogues = df['emotions']\n",
        "one_hot_emotions = []\n",
        "for dialogue_emotion in dialogues:\n",
        "  dialogue_emotions_list = []\n",
        "  for emotion in dialogue_emotion:\n",
        "    encoded_emotion=label_binarizer.transform([emotion])\n",
        "    dialogue_emotions_list.append(np.ravel(encoded_emotion).tolist())\n",
        "  one_hot_emotions.append(dialogue_emotions_list)"
      ],
      "metadata": {
        "id": "H6K5IJ0-NLlL",
        "execution": {
          "iopub.status.busy": "2024-01-19T14:55:01.818813Z",
          "iopub.execute_input": "2024-01-19T14:55:01.819198Z",
          "iopub.status.idle": "2024-01-19T14:55:15.447863Z",
          "shell.execute_reply.started": "2024-01-19T14:55:01.819174Z",
          "shell.execute_reply": "2024-01-19T14:55:15.447026Z"
        },
        "trusted": true
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['emotions'] = one_hot_emotions"
      ],
      "metadata": {
        "id": "fNaWF4KIgIys",
        "execution": {
          "iopub.status.busy": "2024-01-19T14:55:15.449068Z",
          "iopub.execute_input": "2024-01-19T14:55:15.449401Z",
          "iopub.status.idle": "2024-01-19T14:55:15.455432Z",
          "shell.execute_reply.started": "2024-01-19T14:55:15.449371Z",
          "shell.execute_reply": "2024-01-19T14:55:15.454554Z"
        },
        "trusted": true
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_data, temp_data = train_test_split(df, train_size=0.8, shuffle=False)\n",
        "val_data, test_data = train_test_split(temp_data, test_size=0.5, shuffle=False)\n",
        "val_data.reset_index(drop=True, inplace=True)\n",
        "test_data.reset_index(drop=True, inplace=True)"
      ],
      "metadata": {
        "id": "ALZyV8V-kk5k",
        "execution": {
          "iopub.status.busy": "2024-01-19T15:37:31.269362Z",
          "iopub.execute_input": "2024-01-19T15:37:31.269811Z",
          "iopub.status.idle": "2024-01-19T15:37:31.280717Z",
          "shell.execute_reply.started": "2024-01-19T15:37:31.269776Z",
          "shell.execute_reply": "2024-01-19T15:37:31.279818Z"
        },
        "trusted": true
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import BertTokenizer, BertModel, BertForSequenceClassification, AdamW, Trainer, TrainingArguments\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, dialogues, emotions, triggers, tokenizer, max_length=10):\n",
        "        self.dialogues = dialogues\n",
        "        self.emotions = emotions\n",
        "        self.triggers = triggers\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dialogues)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        dialogue = self.dialogues[idx]\n",
        "        emotion = self.emotions[idx]\n",
        "        trigger = self.triggers[idx]\n",
        "\n",
        "        input_ids_list = []\n",
        "        attention_mask_list = []\n",
        "\n",
        "        for utterance in dialogue:\n",
        "          tokenized_utterance = self.tokenizer(utterance, max_length=self.max_length, padding='max_length', truncation=True, return_tensors='pt')\n",
        "          # Extract relevant information\n",
        "          #input_ids = torch.stack([inputs['input_ids'].squeeze() for inputs in tokenized_dialogue])\n",
        "          input_ids_list.extend(tokenized_utterance['input_ids'])\n",
        "          attention_mask_list.extend(tokenized_utterance['attention_mask'])\n",
        "\n",
        "        emotion_labels = torch.tensor(emotion, dtype=torch.float32)\n",
        "        trigger_label = torch.tensor(trigger, dtype=torch.long)\n",
        "        #print('input',torch.stack(input_ids_list).shape)\n",
        "        #print('attention',torch.stack(attention_mask_list).shape)\n",
        "        #print('emotion',emotion_labels.shape)\n",
        "        #print('trigeeer',trigger_label.shape)\n",
        "        return {\n",
        "            'input_ids': torch.stack(input_ids_list),\n",
        "            'attention_mask': torch.stack(attention_mask_list),\n",
        "            'emotion_labels': emotion_labels,\n",
        "            'trigger_label': trigger_label\n",
        "        }"
      ],
      "metadata": {
        "id": "HiiN1Qs9k0DM",
        "execution": {
          "iopub.status.busy": "2024-01-19T14:55:16.624483Z",
          "iopub.execute_input": "2024-01-19T14:55:16.625040Z",
          "iopub.status.idle": "2024-01-19T14:55:16.647212Z",
          "shell.execute_reply.started": "2024-01-19T14:55:16.625013Z",
          "shell.execute_reply": "2024-01-19T14:55:16.646482Z"
        },
        "trusted": true
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Baseline, no LSTM or Attention\n",
        "import torch\n",
        "from torch import nn\n",
        "from transformers import XLNetModel\n",
        "\n",
        "class CustomXLNetModel(nn.Module):\n",
        "    def __init__(self, num_emotions, num_triggers):\n",
        "        super(CustomXLNetModel, self).__init__()\n",
        "        self.xlnet = XLNetModel.from_pretrained('xlnet-base-cased')\n",
        "\n",
        "        # Assuming we use the pooled output of XLNet for classification\n",
        "        self.emotion_head = nn.Linear(self.xlnet.config.hidden_size, num_emotions)\n",
        "        self.trigger_head = nn.Linear(self.xlnet.config.hidden_size, num_triggers)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        xlnet_outputs = self.xlnet(input_ids=input_ids, attention_mask=attention_mask, return_dict=True)\n",
        "\n",
        "        # Get the last hidden state\n",
        "        sequence_output = xlnet_outputs.last_hidden_state\n",
        "\n",
        "        # Optionally, use the pooled output (representation of [CLS] token) as features for classification\n",
        "        # However, note that XLNet does not provide a pooled output like BERT's `pooler_output`.\n",
        "        # You might need to explicitly pool the last_hidden_state, for example, by taking the first token's representation or applying mean pooling.\n",
        "        # Here, we take the representation of the first token as an example.\n",
        "        pooled_output = sequence_output[:, 0]\n",
        "\n",
        "        emotion_logits = self.emotion_head(pooled_output)\n",
        "        trigger_logits = self.trigger_head(pooled_output)\n",
        "\n",
        "        return emotion_logits, trigger_logits\n"
      ],
      "metadata": {
        "id": "76Tc4FC071mK"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# With Attention\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from transformers import XLNetModel\n",
        "\n",
        "class Attention(nn.Module):\n",
        "    def __init__(self, hidden_size):\n",
        "        super(Attention, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.attention_weights = nn.Parameter(torch.Tensor(hidden_size, 1))\n",
        "        nn.init.xavier_uniform_(self.attention_weights.data)\n",
        "\n",
        "    def forward(self, outputs):\n",
        "        # Apply attention weights\n",
        "        attention_scores = torch.matmul(outputs, self.attention_weights).squeeze(-1)\n",
        "        attention_scores = torch.softmax(attention_scores, dim=1).unsqueeze(2)\n",
        "\n",
        "        # Apply the attention scores to the outputs\n",
        "        weighted_sequence = outputs * attention_scores\n",
        "        attended_output = weighted_sequence.sum(dim=1)\n",
        "        return attended_output\n",
        "\n",
        "class CustomXLNetModel(nn.Module):\n",
        "    def __init__(self, num_emotions, num_triggers):\n",
        "        super(CustomXLNetModel, self).__init__()\n",
        "        self.xlnet = XLNetModel.from_pretrained('xlnet-base-cased')\n",
        "\n",
        "        self.attention = Attention(self.xlnet.config.hidden_size)\n",
        "\n",
        "        self.emotion_head = nn.Linear(self.xlnet.config.hidden_size, num_emotions)\n",
        "        self.trigger_head = nn.Linear(self.xlnet.config.hidden_size, num_triggers)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        xlnet_outputs = self.xlnet(input_ids=input_ids, attention_mask=attention_mask, return_dict=True)\n",
        "        sequence_output = xlnet_outputs.last_hidden_state\n",
        "\n",
        "        attended_output = self.attention(sequence_output)\n",
        "\n",
        "        emotion_logits = self.emotion_head(attended_output)\n",
        "        trigger_logits = self.trigger_head(attended_output)\n",
        "\n",
        "        return emotion_logits, trigger_logits\n"
      ],
      "metadata": {
        "id": "zzS0X5Fu5NO1"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# With LSTM + Attention\n",
        "import torch\n",
        "from torch import nn\n",
        "from transformers import XLNetModel\n",
        "\n",
        "class Attention(nn.Module):\n",
        "    def __init__(self, hidden_size):\n",
        "        super(Attention, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.attention_weights = nn.Parameter(torch.Tensor(hidden_size, 1))\n",
        "        nn.init.xavier_uniform_(self.attention_weights.data)\n",
        "\n",
        "    def forward(self, lstm_output):\n",
        "        # Apply attention weights\n",
        "        attention_scores = torch.matmul(lstm_output, self.attention_weights).squeeze(-1)\n",
        "        attention_scores = torch.softmax(attention_scores, dim=1).unsqueeze(2)\n",
        "\n",
        "        # Apply the attention scores to the lstm_output\n",
        "        weighted_sequence = lstm_output * attention_scores\n",
        "        attended_output = weighted_sequence.sum(dim=1)\n",
        "        return attended_output\n",
        "\n",
        "class CustomXLNetModel(nn.Module):\n",
        "    def __init__(self, num_emotions, num_triggers):\n",
        "        super(CustomXLNetModel, self).__init__()\n",
        "        self.xlnet = XLNetModel.from_pretrained('xlnet-base-cased')\n",
        "\n",
        "        self.lstm_hidden_size = self.xlnet.config.hidden_size\n",
        "        self.lstm = nn.LSTM(input_size=self.lstm_hidden_size,\n",
        "                            hidden_size=self.lstm_hidden_size,\n",
        "                            num_layers=1,\n",
        "                            batch_first=True,\n",
        "                            bidirectional=True)\n",
        "\n",
        "        self.attention = Attention(self.lstm_hidden_size * 2)\n",
        "\n",
        "        self.emotion_head = nn.Linear(self.lstm_hidden_size * 2, num_emotions)\n",
        "        self.trigger_head = nn.Linear(self.lstm_hidden_size * 2, num_triggers)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        xlnet_outputs = self.xlnet(input_ids=input_ids, attention_mask=attention_mask, return_dict=True)\n",
        "        sequence_output = xlnet_outputs.last_hidden_state\n",
        "\n",
        "        lstm_output, (h_n, c_n) = self.lstm(sequence_output)\n",
        "        attended_output = self.attention(lstm_output)\n",
        "\n",
        "        emotion_logits = self.emotion_head(attended_output)\n",
        "        trigger_logits = self.trigger_head(attended_output)\n",
        "\n",
        "        return emotion_logits, trigger_logits"
      ],
      "metadata": {
        "id": "xqtvD_b1tIVx"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import XLNetTokenizer\n",
        "\n",
        "tokenizer = XLNetTokenizer.from_pretrained('xlnet-base-cased')\n",
        "\n",
        "train_dataset = CustomDataset(train_data['utterances'], train_data['emotions'],\n",
        "                              train_data['triggers'], tokenizer)\n",
        "validation_dataset = CustomDataset(val_data['utterances'], val_data['emotions'],\n",
        "                             val_data['triggers'], tokenizer)\n",
        "test_dataset = CustomDataset(test_data['utterances'], test_data['emotions'],\n",
        "                             test_data['triggers'], tokenizer)\n",
        "\n",
        "# freezed_embeddings = False\n",
        "\n",
        "custom_xlnet_model = CustomXLNetModel(num_emotions = 7, num_triggers = 2)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "custom_xlnet_model = custom_xlnet_model.to(device)\n",
        "optimizer = AdamW(custom_xlnet_model.parameters(), lr=1e-5, weight_decay = 0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F61etxljy5w0",
        "outputId": "f7db6ca3-6349-47cf-afdb-a08efb455ec1"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetModel: ['lm_loss.bias', 'lm_loss.weight']\n",
            "- This IS expected if you are initializing XLNetModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing XLNetModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "def collate_fn(batch):\n",
        "    input_ids = [item['input_ids'] for item in batch]\n",
        "    attention_mask = [item['attention_mask'] for item in batch]\n",
        "    emotion_labels = [item['emotion_labels'] for item in batch]#torch.stack([item['emotion_labels'] for item in batch], dim=0)\n",
        "    trigger_label = [item['trigger_label'] for item in batch]#torch.stack([item['trigger_label'] for item in batch], dim=0)\n",
        "\n",
        "    #input_ids = pad_sequence([torch.stack(item['input_ids']) for item in batch], batch_first=True)\n",
        "    #attention_mask = pad_sequence([torch.stack(item['attention_mask']) for item in batch], batch_first=True)\n",
        "    return input_ids,attention_mask,emotion_labels,trigger_label\n",
        "    #return {'input_ids': input_ids, 'attention_mask': attention_mask, 'emotion_labels': emotion_labels, 'trigger_label': trigger_label"
      ],
      "metadata": {
        "id": "sBB_kLVy1A_L"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_bert(mode,model_instance):\n",
        "\n",
        "# Usage in the eval loop\n",
        "  sequence_f1_scores_emotion = []\n",
        "  sequence_f1_scores_trigger = []\n",
        "  unrolled_predictions_emotion = []\n",
        "  unrolled_predictions_trigger = []\n",
        "  unrolled_labels_emotion = []\n",
        "  unrolled_labels_trigger = []\n",
        "  sequence_f1_scores = []\n",
        "\n",
        "  batch_size = 1\n",
        "  #test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "  if mode == 'validation':\n",
        "    loader = DataLoader(validation_dataset, batch_size=batch_size, shuffle=False)\n",
        "  elif mode == 'test':\n",
        "    loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "  # if model == 'baseline':\n",
        "  #   BERT_baseline.eval()\n",
        "  # elif model == 'custom':\n",
        "  #   BERT_lstm.eval()\n",
        "  model_instance.eval()\n",
        "  with torch.no_grad():\n",
        "      for batch in tqdm(loader, desc='Evaluation', leave=False):\n",
        "          input_ids = batch['input_ids'].squeeze().to(device)\n",
        "          attention_mask = batch['attention_mask'].squeeze().to(device)\n",
        "          emotion_labels = batch['emotion_labels'].squeeze().to(device)\n",
        "          trigger_label = batch['trigger_label'].squeeze().to(device)\n",
        "\n",
        "          # if model == 'baseline':\n",
        "          #   emotion_logits, trigger_logits = BERT_baseline(input_ids, attention_mask)\n",
        "          # elif model == 'custom':\n",
        "          #   emotion_logits, trigger_logits = BERT_lstm(input_ids, attention_mask)\n",
        "          emotion_logits, trigger_logits = model_instance(input_ids, attention_mask)\n",
        "\n",
        "          # Store predictions and labels for later unrolled F1 computation\n",
        "          unrolled_predictions_emotion.append(emotion_logits)\n",
        "          unrolled_labels_emotion.append(emotion_labels)\n",
        "          unrolled_predictions_trigger.append(trigger_logits)\n",
        "          unrolled_labels_trigger.append(trigger_label)\n",
        "\n",
        "          # Convert logits to probabilities and then to class predictions\n",
        "          #predicted_classes = torch.argmax(emotion_logits, dim=1)\n",
        "          #true_classes = torch.argmax(emotion_labels, dim=1)\n",
        "\n",
        "          # Compute F1 for the current sequence (dialogue)\n",
        "          #sequence_f1 = f1_score(true_classes.cpu().numpy(), predicted_classes.cpu().numpy(), average='macro')\n",
        "          #sequence_f1_scores.append(sequence_f1)\n",
        "\n",
        "  # Compute the average Sequence F1 for emotions and triggers\n",
        "  average_sequence_f1_emotion, average_sequence_f1_trigger = compute_sequence_f1(\n",
        "      [unrolled_predictions_emotion, unrolled_predictions_trigger],\n",
        "      [unrolled_labels_emotion, unrolled_labels_trigger]\n",
        "  )\n",
        "\n",
        "  # Compute the Unrolled Sequence F1 for emotions and triggers\n",
        "  unrolled_sequence_f1_emotion, unrolled_sequence_f1_trigger = compute_unrolled_sequence_f1(\n",
        "      [unrolled_predictions_emotion, unrolled_predictions_trigger],\n",
        "      [unrolled_labels_emotion, unrolled_labels_trigger]\n",
        "  )\n",
        "  # if model == 'baseline':\n",
        "  #   BERT_baseline.train()\n",
        "  # elif model == 'custom':\n",
        "  #   BERT_lstm.train()\n",
        "  model_instance.train()\n",
        "  # Print the F1 scores for emotions and triggers\n",
        "  print(f\"Average Sequence F1 (Emotion):  {average_sequence_f1_emotion:03f}\")\n",
        "  print(f\"Average Sequence F1 (Trigger): {average_sequence_f1_trigger:03f}\")\n",
        "  print(f\"Unrolled Sequence F1 (Emotion): {unrolled_sequence_f1_emotion.item():03f}\")\n",
        "  print(f\"Unrolled Sequence F1 (Trigger): {unrolled_sequence_f1_trigger.item():03f}\")\n",
        "  return average_sequence_f1_emotion, average_sequence_f1_trigger, unrolled_sequence_f1_emotion, unrolled_sequence_f1_trigger"
      ],
      "metadata": {
        "id": "mMc7w-Pk1GvT"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion_emotion = torch.nn.CrossEntropyLoss()\n",
        "criterion_trigger = torch.nn.BCEWithLogitsLoss()\n",
        "num_epochs = 5\n",
        "batch_size = 32\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn = collate_fn)"
      ],
      "metadata": {
        "id": "p_QeMoOAztBN"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(num_epochs):\n",
        "    custom_xlnet_model.train()\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for batch in tqdm(train_loader, desc=f'Epoch {epoch + 1}', leave=False):\n",
        "        input_ids,attention_mask,emotion_labels,trigger_label = batch\n",
        "\n",
        "        # Zero the gradients on the optimizer\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        for el in range(batch_size):\n",
        "          emotion_loss = 0.0\n",
        "          trigger_loss = 0.0\n",
        "\n",
        "          input_ids_el = input_ids[el].squeeze().to(device)\n",
        "          attention_mask_el = attention_mask[el].squeeze().to(device)\n",
        "          emotion_labels_el = emotion_labels[el].squeeze().to(device)\n",
        "          trigger_label_el = trigger_label[el].squeeze().to(device)\n",
        "\n",
        "          # Forward pass\n",
        "          emotion_logits, trigger_logits = custom_xlnet_model(input_ids_el, attention_mask_el)\n",
        "          # Compute the loss for both emotion and trigger\n",
        "\n",
        "          emotion_loss += criterion_emotion(emotion_logits, torch.argmax(emotion_labels_el, dim=1))\n",
        "          trigger_loss += criterion_trigger(torch.argmax(trigger_logits, dim=1).float(), trigger_label_el.float())\n",
        "\n",
        "        # Combine losses for backpropagation\n",
        "        loss = (emotion_loss + trigger_loss)/batch_size\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "    # Compute the average loss\n",
        "    average_loss = total_loss / len(train_loader)\n",
        "    print(f\"Epoch {epoch + 1}, Average Loss: {average_loss}\")\n",
        "    test_bert('validation', custom_xlnet_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xi3wv-fPzuMF",
        "outputId": "5b0b6ca4-1af4-427e-934f-256687bcb577"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Average Loss: 0.08647044502198696\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Sequence F1 (Emotion):  0.183634\n",
            "Average Sequence F1 (Trigger): 0.330511\n",
            "Unrolled Sequence F1 (Emotion): 0.085029\n",
            "Unrolled Sequence F1 (Trigger): 0.334355\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2, Average Loss: 0.0829169850051403\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Sequence F1 (Emotion):  0.183634\n",
            "Average Sequence F1 (Trigger): 0.450336\n",
            "Unrolled Sequence F1 (Emotion): 0.085029\n",
            "Unrolled Sequence F1 (Trigger): 0.474217\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3, Average Loss: 0.08258714564144612\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Sequence F1 (Emotion):  0.231562\n",
            "Average Sequence F1 (Trigger): 0.462759\n",
            "Unrolled Sequence F1 (Emotion): 0.137631\n",
            "Unrolled Sequence F1 (Trigger): 0.509116\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4, Average Loss: 0.08187616527080536\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Sequence F1 (Emotion):  0.280429\n",
            "Average Sequence F1 (Trigger): 0.285186\n",
            "Unrolled Sequence F1 (Emotion): 0.196562\n",
            "Unrolled Sequence F1 (Trigger): 0.276280\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5, Average Loss: 0.08054202452301978\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Sequence F1 (Emotion):  0.265491\n",
            "Average Sequence F1 (Trigger): 0.307654\n",
            "Unrolled Sequence F1 (Emotion): 0.178324\n",
            "Unrolled Sequence F1 (Trigger): 0.306485\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_bert('test', custom_xlnet_model) # Baseline"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fcvATE4k27Qb",
        "outputId": "2ee98cb9-8f02-4b63-9869-6bd6b3944d3e"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Sequence F1 (Emotion):  0.300681\n",
            "Average Sequence F1 (Trigger): 0.263727\n",
            "Unrolled Sequence F1 (Emotion): 0.188067\n",
            "Unrolled Sequence F1 (Trigger): 0.262602\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.3007), tensor(0.2637), tensor(0.1881), tensor(0.2626))"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Baseline BERT below\n"
      ],
      "metadata": {
        "id": "5AryfGpxBcaQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomBERTModel(torch.nn.Module):\n",
        "    def __init__(self, freeze_embeddings=True):\n",
        "        super(CustomBERTModel, self).__init__()\n",
        "        # Replace this with your custom BERT model architecture for multihead classification\n",
        "        self.bert = BertModel.from_pretrained('bert-base-uncased')#BertForSequenceClassification.from_pretrained\n",
        "        #LSTM\n",
        "        if freeze_embeddings:\n",
        "            for name,param in self.bert.named_parameters():\n",
        "                if 'embeddings' in name:\n",
        "                    param.requires_grad = False\n",
        "\n",
        "        self.emotion_head = torch.nn.Linear(self.bert.config.hidden_size, len(emotions))\n",
        "        self.trigger_head = torch.nn.Linear(self.bert.config.hidden_size, len(triggers))\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask, return_dict=True)\n",
        "        pooled_output = outputs['pooler_output']\n",
        "\n",
        "        # Emotion head\n",
        "        emotion_logits = self.emotion_head(pooled_output)\n",
        "\n",
        "        # Trigger head\n",
        "        trigger_logits = self.trigger_head(pooled_output)\n",
        "        return emotion_logits, trigger_logits\n",
        "        #return emotion_outputs, trigger_outputs\n",
        "        #return torch.stack(emotion_outputs), torch.stack(trigger_outputs)"
      ],
      "metadata": {
        "id": "MfLGTU4Mkw3V",
        "execution": {
          "iopub.status.busy": "2024-01-19T16:59:48.636076Z",
          "iopub.execute_input": "2024-01-19T16:59:48.636728Z",
          "iopub.status.idle": "2024-01-19T16:59:48.644739Z",
          "shell.execute_reply.started": "2024-01-19T16:59:48.636695Z",
          "shell.execute_reply": "2024-01-19T16:59:48.643907Z"
        },
        "trusted": true
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# BERT baseline\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "\n",
        "trairn_dataset = CustomDataset(train_data['utterances'], train_data['emotions'],\n",
        "                              train_data['triggers'], tokenizer)\n",
        "validation_dataset = CustomDataset(val_data['utterances'], val_data['emotions'],\n",
        "                             val_data['triggers'], tokenizer)\n",
        "test_dataset = CustomDataset(test_data['utterances'], test_data['emotions'],\n",
        "                             test_data['triggers'], tokenizer)\n",
        "\n",
        "\n",
        "freezed_embeddings = False\n",
        "custom_Bert_Model = CustomBERTModel(freezed_embeddings)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "custom_Bert_Model = custom_Bert_Model.to(device)\n",
        "optimizer = AdamW(filter(lambda p: p.requires_grad, custom_Bert_Model.parameters()), lr=5e-5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156,
          "referenced_widgets": [
            "720b22ca40d149b5b58e34a11cc3b984",
            "600a0af640814babb3e97ee6c1a389f0",
            "aee3e6d6aa254789a0d6015f5056bc41",
            "3d010c30d90a422aaa9d0ff49a8a580a",
            "c163528f1b2d477d910dc96e7be50aa3",
            "370e3091d2504c9cae3470cadfa682e7",
            "c4b3188d527949419d61e80ba92ad008",
            "4e94dbf4b7db45308dd5f08b8b63a248",
            "8630fc0f4f1d40df81008c782ff3c6d6",
            "6467c2d272da4aa6aa663f19517ec56d",
            "74bf0a5fc68042e7be4ba2bd65b372a4",
            "3eb9cdca194b4e669e25eec47d25a0b4",
            "7425abc3069948d281fc7980d1108489",
            "87ca886ca6414f2aa9fd4372ba696b77",
            "5ef9c894b407485f949b375bdc7368ba",
            "739d7ff07f484951bade8b9643a80bee",
            "e69171725dae4808a891c008e803281d",
            "63bd6d9236d74f40835f45cbef407710",
            "624fb418b8d5479f9c647385208ad6c7",
            "4554b11dbcce4339b71d286d77ced1de",
            "0cd38756e096483583b3e2e2403c4202",
            "f594d291d33c427490f0813f69133962"
          ]
        },
        "id": "bUR8qBNelMMl",
        "outputId": "ebeba4fe-8f56-42e4-a73a-8bd613ecc2a0",
        "execution": {
          "iopub.status.busy": "2024-01-19T16:59:52.185789Z",
          "iopub.execute_input": "2024-01-19T16:59:52.186155Z",
          "iopub.status.idle": "2024-01-19T16:59:53.312702Z",
          "shell.execute_reply.started": "2024-01-19T16:59:52.186126Z",
          "shell.execute_reply": "2024-01-19T16:59:53.311901Z"
        },
        "trusted": true
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "spiece.model:   0%|          | 0.00/798k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "720b22ca40d149b5b58e34a11cc3b984"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/760 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3eb9cdca194b4e669e25eec47d25a0b4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "def compute_sequence_f1(predictions, labels):\n",
        "    # predictions and labels should be lists of tensors for each dialogue\n",
        "    emotion_f1_scores = []\n",
        "    trigger_f1_scores = []\n",
        "    for emotion_pred, trigger_pred, emotion_lab, trigger_lab in zip(predictions[0], predictions[1], labels[0], labels[1]):\n",
        "        emotion_predicted_classes = torch.argmax(emotion_pred, dim=1)\n",
        "        trigger_predicted_classes = torch.argmax(trigger_pred, dim=1)\n",
        "        emotion_true_classes = torch.argmax(emotion_lab, dim=1)\n",
        "        trigger_true_classes = trigger_lab\n",
        "        emotion_f1 = f1_score(emotion_true_classes.cpu().numpy(), emotion_predicted_classes.cpu().numpy(), average='macro')\n",
        "        trigger_f1 = f1_score(trigger_true_classes.cpu().numpy(), trigger_predicted_classes.cpu().numpy(), average='macro')\n",
        "        emotion_f1_scores.append(emotion_f1)\n",
        "        trigger_f1_scores.append(trigger_f1)\n",
        "    average_emotion_f1 = torch.tensor(emotion_f1_scores, dtype=torch.float32).mean()\n",
        "    average_trigger_f1 = torch.tensor(trigger_f1_scores, dtype=torch.float32).mean()\n",
        "    return average_emotion_f1, average_trigger_f1\n",
        "\n",
        "def compute_unrolled_sequence_f1(predictions, labels):\n",
        "    # Flatten all utterances and compute the F1 score\n",
        "    all_emotion_predicted_classes = torch.argmax(torch.cat(predictions[0], dim=0), dim=1)\n",
        "    all_trigger_predicted_classes = torch.argmax(torch.cat(predictions[1], dim=0), dim=1)\n",
        "    all_emotion_true_classes = torch.argmax(torch.cat(labels[0], dim=0), dim=1)\n",
        "    all_trigger_true_classes = torch.cat(labels[1], dim=0)\n",
        "    unrolled_emotion_f1 = f1_score(all_emotion_true_classes.cpu().numpy(), all_emotion_predicted_classes.cpu().numpy(), average='macro')\n",
        "    unrolled_trigger_f1 = f1_score(all_trigger_true_classes.cpu().numpy(), all_trigger_predicted_classes.cpu().numpy(), average='macro')\n",
        "    unrolled_emotion_f1_tensor = torch.tensor(unrolled_emotion_f1, dtype=torch.float32)\n",
        "    unrolled_trigger_f1_tensor = torch.tensor(unrolled_trigger_f1, dtype=torch.float32)\n",
        "    return unrolled_emotion_f1_tensor, unrolled_trigger_f1_tensor"
      ],
      "metadata": {
        "id": "yx9yj1Kuq7qt"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bert"
      ],
      "metadata": {
        "id": "5-oF31k5JxDt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "num_epochs = 3\n",
        "batch_size = 1\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(validation_dataset, batch_size=batch_size, shuffle=True)"
      ],
      "metadata": {
        "id": "X9yT4HSYPXV1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(num_epochs):\n",
        "    custom_Bert_Model.train()\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for batch in tqdm(train_loader, desc=f'Epoch {epoch + 1}', leave=False):\n",
        "        input_ids = batch['input_ids'].squeeze().to(device)\n",
        "        attention_mask = batch['attention_mask'].squeeze().to(device)\n",
        "        emotion_labels = batch['emotion_labels'].squeeze().to(device)\n",
        "        trigger_label = batch['trigger_label'].squeeze().to(device)\n",
        "\n",
        "        # Zero the gradients on the optimizer\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        emotion_logits, trigger_logits = custom_Bert_Model(input_ids, attention_mask)\n",
        "\n",
        "        # Compute the loss for both emotion and trigger\n",
        "        emotion_loss = criterion(emotion_logits, torch.argmax(emotion_labels, dim=1))\n",
        "        trigger_loss = criterion(trigger_logits, trigger_label)\n",
        "\n",
        "        # Combine losses for backpropagation\n",
        "        loss = emotion_loss + trigger_loss\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    print(f\"Emotion loss:\", emotion_loss)\n",
        "    print(f\"Trigger loss:\", trigger_loss)\n",
        "     # Compute the average loss\n",
        "    average_loss = total_loss / len(train_loader)\n",
        "    print(f\"Epoch {epoch + 1}, Average Loss: {average_loss}\")\n"
      ],
      "metadata": {
        "id": "RiM7PzNfsHBm",
        "execution": {
          "iopub.status.busy": "2024-01-19T16:59:59.152258Z",
          "iopub.execute_input": "2024-01-19T16:59:59.152636Z",
          "iopub.status.idle": "2024-01-19T17:06:14.724472Z",
          "shell.execute_reply.started": "2024-01-19T16:59:59.152604Z",
          "shell.execute_reply": "2024-01-19T17:06:14.723552Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3bc33851-6f71-4dd1-a1a2-771f66b49f16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Emotion loss: tensor(0.3195, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Trigger loss: tensor(0.3524, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Epoch 1, Average Loss: 1.473908871631138\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Emotion loss: tensor(1.6035, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Trigger loss: tensor(0.5599, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Epoch 2, Average Loss: 0.9099623631429858\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                            "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Emotion loss: tensor(0.6053, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Trigger loss: tensor(0.2888, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Epoch 3, Average Loss: 0.748000873948913\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Usage in the eval loop\n",
        "sequence_f1_scores_emotion = []\n",
        "sequence_f1_scores_trigger = []\n",
        "unrolled_predictions_emotion = []\n",
        "unrolled_predictions_trigger = []\n",
        "unrolled_labels_emotion = []\n",
        "unrolled_labels_trigger = []\n",
        "sequence_f1_scores = []\n",
        "\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in tqdm(test_loader, desc='Evaluation', leave=False):\n",
        "        input_ids = batch['input_ids'].squeeze().to(device)\n",
        "        attention_mask = batch['attention_mask'].squeeze().to(device)\n",
        "        emotion_labels = batch['emotion_labels'].squeeze().to(device)\n",
        "        trigger_label = batch['trigger_label'].squeeze().to(device)\n",
        "\n",
        "        emotion_logits, trigger_logits = custom_Bert_Model(input_ids, attention_mask)\n",
        "\n",
        "        # Store predictions and labels for later unrolled F1 computation\n",
        "        unrolled_predictions_emotion.append(emotion_logits)\n",
        "        unrolled_labels_emotion.append(emotion_labels)\n",
        "        unrolled_predictions_trigger.append(trigger_logits)\n",
        "        unrolled_labels_trigger.append(trigger_label)\n",
        "\n",
        "        # Convert logits to probabilities and then to class predictions\n",
        "        predicted_classes = torch.argmax(emotion_logits, dim=1)\n",
        "        true_classes = torch.argmax(emotion_labels, dim=1)\n",
        "\n",
        "        # Compute F1 for the current sequence (dialogue)\n",
        "        sequence_f1 = f1_score(true_classes.cpu().numpy(), predicted_classes.cpu().numpy(), average='macro')\n",
        "        sequence_f1_scores.append(sequence_f1)\n",
        "\n",
        "# Compute the average Sequence F1 for emotions and triggers\n",
        "average_sequence_f1_emotion, average_sequence_f1_trigger = compute_sequence_f1(\n",
        "    [unrolled_predictions_emotion, unrolled_predictions_trigger],\n",
        "    [unrolled_labels_emotion, unrolled_labels_trigger]\n",
        ")\n",
        "\n",
        "# Compute the Unrolled Sequence F1 for emotions and triggers\n",
        "unrolled_sequence_f1_emotion, unrolled_sequence_f1_trigger = compute_unrolled_sequence_f1(\n",
        "    [unrolled_predictions_emotion, unrolled_predictions_trigger],\n",
        "    [unrolled_labels_emotion, unrolled_labels_trigger]\n",
        ")\n",
        "\n",
        "# Print the F1 scores for emotions and triggers\n",
        "print(f\"Average Sequence F1 (Emotion): {average_sequence_f1_emotion}\")\n",
        "print(f\"Average Sequence F1 (Trigger): {average_sequence_f1_trigger}\")\n",
        "print(f\"Unrolled Sequence F1 (Emotion): {unrolled_sequence_f1_emotion.item()}\")\n",
        "print(f\"Unrolled Sequence F1 (Trigger): {unrolled_sequence_f1_trigger.item()}\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-19T17:06:23.721431Z",
          "iopub.execute_input": "2024-01-19T17:06:23.721829Z",
          "iopub.status.idle": "2024-01-19T17:06:32.580790Z",
          "shell.execute_reply.started": "2024-01-19T17:06:23.721805Z",
          "shell.execute_reply": "2024-01-19T17:06:32.579851Z"
        },
        "trusted": true,
        "id": "PhPnLK7ZAQxE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c183a13-d595-4969-ebcc-1066f688d856"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Sequence F1 (Emotion): 0.2413686364889145\n",
            "Average Sequence F1 (Trigger): 0.45175039768218994\n",
            "Unrolled Sequence F1 (Emotion): 0.1467110812664032\n",
            "Unrolled Sequence F1 (Trigger): 0.4606205224990845\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Majority classifier"
      ],
      "metadata": {
        "id": "XcYo46z3J0jV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "def find_majority_class(train_loader):\n",
        "    # Initialize counters\n",
        "    emotion_counts = torch.zeros(7) # Assuming there are 7 unique emotions\n",
        "    trigger_counts = torch.zeros(2) # There are 2 classes for triggers: present or not\n",
        "    negative_trigger_counts = 0\n",
        "    positive_trigger_counts = 0\n",
        "    # Iterate over the training dataset to count the labels\n",
        "    for batch in train_loader:\n",
        "        emotion_labels = batch['emotion_labels'].squeeze()\n",
        "        trigger_labels = batch['trigger_label'].squeeze()\n",
        "        #print(trigger_labels,torch.sum(trigger_labels, dim=0),(trigger_labels == 0).sum())\n",
        "        # Sum up the counts for each class\n",
        "        positive_trigger_counts += torch.sum(trigger_labels, dim=0)\n",
        "        # Count the zeros for the negative class (absence of a trigger)\n",
        "        # Since one-hot encoding, the absence is just the inverse of the presence\n",
        "        negative_trigger_counts += torch.sum(1 - trigger_labels, dim=0)\n",
        "        emotion_counts += torch.sum(emotion_labels, dim=0)\n",
        "\n",
        "    trigger_counts[0] = negative_trigger_counts\n",
        "    trigger_counts[1] = positive_trigger_counts\n",
        "    print(trigger_counts)\n",
        "    print(emotion_counts)\n",
        "    # Find the index with the maximum count for emotions and triggers\n",
        "    majority_emotion = torch.zeros_like(emotion_counts)\n",
        "    majority_emotion[torch.argmax(emotion_counts)] = 1\n",
        "    majority_trigger = torch.zeros_like(trigger_counts)\n",
        "    majority_trigger[torch.argmax(trigger_counts)] = 1\n",
        "\n",
        "    return majority_emotion, majority_trigger\n",
        "\n",
        "# Let's assume that 'train_loader' is a DataLoader for your training dataset\n",
        "# You need to replace 'train_loader' with the actual DataLoader for your dataset\n",
        "majority_emotion, majority_trigger = find_majority_class(train_loader)\n",
        "majority_emotion, majority_trigger"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EdfQ_Tkn0Hzj",
        "outputId": "2f9ce1f5-3f32-49a1-f755-c86c52d02ef5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([23524.,  4289.])\n",
            "tensor([ 3025.,   816.,   917.,  5123., 12228.,  1929.,  3775.])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([0., 0., 0., 0., 1., 0., 0.]), tensor([1., 0.]))"
            ]
          },
          "metadata": {},
          "execution_count": 150
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "def majority_classifier(majority_emotion, majority_trigger, test_loader):\n",
        "    all_emotion_predictions = []\n",
        "    all_trigger_predictions = []\n",
        "    all_emotion_labels = []\n",
        "    all_trigger_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(test_loader, desc='Evaluation', leave=False):\n",
        "            emotion_labels = batch['emotion_labels']\n",
        "            trigger_labels = batch['trigger_label']\n",
        "\n",
        "            for emotion_lab, trigger_lab in zip(emotion_labels, trigger_labels):\n",
        "                # Ensure we have at least 1 dimension\n",
        "                if emotion_lab.ndim == 1 and emotion_lab.size(0) == 1:\n",
        "                    emotion_lab = emotion_lab.unsqueeze(0)\n",
        "                if trigger_lab.ndim == 1 and trigger_lab.size(0) == 1:\n",
        "                    trigger_lab = trigger_lab.unsqueeze(0)\n",
        "\n",
        "                # Store the labels\n",
        "                all_emotion_labels.append(emotion_lab)\n",
        "                all_trigger_labels.append(trigger_lab)\n",
        "\n",
        "                # Repeat the majority class prediction to match the number of utterances\n",
        "                emotion_predictions = majority_emotion.repeat(emotion_lab.size(0), 1)\n",
        "                #print(emotion_predictions)\n",
        "\n",
        "                trigger_predictions = majority_trigger.repeat(trigger_lab.size(0), 1)\n",
        "\n",
        "                # Store the predictions\n",
        "                all_emotion_predictions.append(emotion_predictions)\n",
        "                all_trigger_predictions.append(trigger_predictions)\n",
        "\n",
        "    # Use the stored predictions and labels to calculate sequence F1 and unrolled sequence F1\n",
        "    average_sequence_f1_emotion, average_sequence_f1_trigger = compute_sequence_f1(\n",
        "        [all_emotion_predictions, all_trigger_predictions],\n",
        "        [all_emotion_labels, all_trigger_labels]\n",
        "    )\n",
        "\n",
        "    unrolled_sequence_f1_emotion, unrolled_sequence_f1_trigger = compute_unrolled_sequence_f1(\n",
        "        [all_emotion_predictions, all_trigger_predictions],\n",
        "        [all_emotion_labels, all_trigger_labels]\n",
        "    )\n",
        "\n",
        "    return average_sequence_f1_emotion, average_sequence_f1_trigger, unrolled_sequence_f1_emotion, unrolled_sequence_f1_trigger\n",
        "\n",
        "# Assume majority_emotion and majority_trigger are tensors of the majority class (one-hot encoded)\n",
        "# and test_loader is your DataLoader instance for the test dataset.\n",
        "average_f1_emotion, average_f1_trigger, unrolled_f1_emotion, unrolled_f1_trigger = majority_classifier(majority_emotion, majority_trigger, test_loader)\n",
        "\n",
        "print(f\"Average Sequence F1 (Emotion): {average_f1_emotion}\")\n",
        "print(f\"Average Sequence F1 (Trigger): {average_f1_trigger}\")\n",
        "print(f\"Unrolled Sequence F1 (Emotion): {unrolled_f1_emotion}\")\n",
        "print(f\"Unrolled Sequence F1 (Trigger): {unrolled_f1_trigger}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86,
          "referenced_widgets": [
            "ff52c6d48f2e46b8836024f9702021c9",
            "dcb25a44229048c7aede8c1b3be1957b",
            "10766895ac3c43ce9fe5a07ff769793e",
            "0f020cffac704d23bc85150c124c948a",
            "df23edce392f46e8b8e96a49cc76c2a7",
            "c80ee61459ed41fdafc24bb2dd363bd4",
            "99c5a2f3661b4ec79be0fc6806d3451b",
            "fe5536e595694015b5e5452048f1d4f9",
            "3a8dab2fdd8e47358126ee30730a18a8",
            "de9ee7bc51844a91938f579a2c2d14cb",
            "e9d4ca079cb34c428a7111181bc21d23"
          ]
        },
        "id": "J6KeegKyC0d9",
        "outputId": "ebc998b4-a6cf-48e3-fd42-a52f14b5e29f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluation:   0%|          | 0/400 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ff52c6d48f2e46b8836024f9702021c9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Sequence F1 (Emotion): 0.1836344599723816\n",
            "Average Sequence F1 (Trigger): 0.0\n",
            "Unrolled Sequence F1 (Emotion): 0.08502866327762604\n",
            "Unrolled Sequence F1 (Trigger): 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Random"
      ],
      "metadata": {
        "id": "iA_NcO9QTaXW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "def random_classifier(test_loader, emotion_distribution, trigger_distribution):\n",
        "    all_emotion_predictions = []\n",
        "    all_trigger_predictions = []\n",
        "    all_emotion_labels = []\n",
        "    all_trigger_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(test_loader, desc='Evaluation', leave=False):\n",
        "            emotion_labels = batch['emotion_labels']\n",
        "            trigger_labels = batch['trigger_label']\n",
        "\n",
        "            for emotion_lab, trigger_lab in zip(emotion_labels, trigger_labels):\n",
        "                # Ensure we have at least 1 dimension\n",
        "                if emotion_lab.ndim == 1 and emotion_lab.size(0) == 1:\n",
        "                    emotion_lab = emotion_lab.unsqueeze(0)\n",
        "                if trigger_lab.ndim == 1 and trigger_lab.size(0) == 1:\n",
        "                    trigger_lab = trigger_lab.unsqueeze(0)\n",
        "\n",
        "                # Store the labels\n",
        "                all_emotion_labels.append(emotion_lab)\n",
        "                all_trigger_labels.append(trigger_lab)\n",
        "\n",
        "                # Generate random predictions for emotions\n",
        "                random_emotion_predictions = torch.randint(0, 2, (emotion_lab.size(0), 7))  # Randomly 0 or 1 for each emotion\n",
        "                all_emotion_predictions.append(random_emotion_predictions.float())\n",
        "\n",
        "                # Generate random predictions for triggers based on the training distribution\n",
        "                random_trigger_probs = torch.rand((trigger_lab.size(0), 1))\n",
        "                random_trigger_predictions = (random_trigger_probs < trigger_distribution).long()  # Binary prediction based on distribution\n",
        "                random_trigger_predictions = torch.cat((random_trigger_predictions, 1 - random_trigger_predictions), dim=1)  # Make it one-hot\n",
        "                all_trigger_predictions.append(random_trigger_predictions.float())\n",
        "\n",
        "    # Calculate the F1 scores using your metric functions\n",
        "    average_sequence_f1_emotion, average_sequence_f1_trigger = compute_sequence_f1(\n",
        "        [all_emotion_predictions, all_trigger_predictions],\n",
        "        [all_emotion_labels, all_trigger_labels]\n",
        "    )\n",
        "\n",
        "    unrolled_sequence_f1_emotion, unrolled_sequence_f1_trigger = compute_unrolled_sequence_f1(\n",
        "        [all_emotion_predictions, all_trigger_predictions],\n",
        "        [all_emotion_labels, all_trigger_labels]\n",
        "    )\n",
        "\n",
        "    return average_sequence_f1_emotion, average_sequence_f1_trigger, unrolled_sequence_f1_emotion, unrolled_sequence_f1_trigger\n",
        "\n",
        "# You need to provide the distribution for the trigger class from your training data\n",
        "# For example, if 30% of your training samples have a trigger, trigger_distribution should be 0.3\n",
        "trigger_distribution = 0.5  # Replace with your actual distribution\n",
        "\n",
        "# Now call your random classifier function\n",
        "average_f1_emotion, average_f1_trigger, unrolled_f1_emotion, unrolled_f1_trigger = random_classifier(\n",
        "    test_loader,\n",
        "    emotion_distribution=None,  # Not used currently as we're assuming a uniform distribution\n",
        "    trigger_distribution=trigger_distribution\n",
        ")\n",
        "\n",
        "print(f\"Random Classifier Average Sequence F1 (Emotion): {average_f1_emotion}\")\n",
        "print(f\"Random Classifier Average Sequence F1 (Trigger): {average_f1_trigger}\")\n",
        "print(f\"Random Classifier Unrolled Sequence F1 (Emotion): {unrolled_f1_emotion}\")\n",
        "print(f\"Random Classifier Unrolled Sequence F1 (Trigger): {unrolled_f1_trigger}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86,
          "referenced_widgets": [
            "f8960bcf6cd746548648ee8df3cc6c65",
            "564791db471941c8a35dfdec947c4bd0",
            "b80b232ad5ce473fbe3738b68bd7ba1a",
            "eb1a9f01dc0346cba7457db346ccc38d",
            "12983111e8644952ba71586dd440ab5e",
            "03212a0e355540ffa628f396d0e15e53",
            "d9177f45f2724968b50384377cf7a9d3",
            "f5c137cad3ed4022909b16717e714955",
            "d47c944fedb4456d872559e12717f7de",
            "17a02ecdec3049668a8f9b6e57eed9f6",
            "7eaa2fd9c84048eb9167ff83edf73734"
          ]
        },
        "id": "PyrbLyM5QezV",
        "outputId": "b1656be4-882d-4282-f19e-ed2c8228f9dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluation:   0%|          | 0/400 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f8960bcf6cd746548648ee8df3cc6c65"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Classifier Average Sequence F1 (Emotion): 0.06286460161209106\n",
            "Random Classifier Average Sequence F1 (Trigger): 0.29223355650901794\n",
            "Random Classifier Unrolled Sequence F1 (Emotion): 0.07199179381132126\n",
            "Random Classifier Unrolled Sequence F1 (Trigger): 0.29306313395500183\n"
          ]
        }
      ]
    }
  ]
}