{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RgHMqcneDn1J"
      },
      "source": [
        "- We loose structure of dialogue using the tokenizer in preprocess_data\n",
        "\n",
        "- Emotions encoded using MultiLabelBinarizer doesn't tell us\n",
        "  anymore how many times a single emotion is present in the dialogue\n",
        "  and where it is"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2024-01-12T18:25:52.423261Z",
          "iopub.status.busy": "2024-01-12T18:25:52.422488Z",
          "iopub.status.idle": "2024-01-12T18:29:06.936875Z",
          "shell.execute_reply": "2024-01-12T18:29:06.935874Z",
          "shell.execute_reply.started": "2024-01-12T18:25:52.423224Z"
        },
        "id": "vc-YdlGVyh9_",
        "jupyter": {
          "outputs_hidden": true
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0eba030-f547-4028-8c1c-e2337df3cde4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu116\n",
            "Collecting torch==1.13.0+cu116\n",
            "  Downloading https://download.pytorch.org/whl/cu116/torch-1.13.0%2Bcu116-cp310-cp310-linux_x86_64.whl (1983.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 GB\u001b[0m \u001b[31m380.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==1.13.0+cu116) (4.5.0)\n",
            "Installing collected packages: torch\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.1.0+cu121\n",
            "    Uninstalling torch-2.1.0+cu121:\n",
            "      Successfully uninstalled torch-2.1.0+cu121\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.1.0+cu121 requires torch==2.1.0, but you have torch 1.13.0+cu116 which is incompatible.\n",
            "torchdata 0.7.0 requires torch==2.1.0, but you have torch 1.13.0+cu116 which is incompatible.\n",
            "torchtext 0.16.0 requires torch==2.1.0, but you have torch 1.13.0+cu116 which is incompatible.\n",
            "torchvision 0.16.0+cu121 requires torch==2.1.0, but you have torch 1.13.0+cu116 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed torch-1.13.0+cu116\n",
            "Collecting transformers==4.30.0\n",
            "  Downloading transformers-4.30.0-py3-none-any.whl (7.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m47.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.30.0) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.30.0) (0.20.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.30.0) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.30.0) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.30.0) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.30.0) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.30.0) (2.31.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers==4.30.0)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m77.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.30.0) (0.4.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.30.0) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers==4.30.0) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers==4.30.0) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.30.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.30.0) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.30.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.30.0) (2023.11.17)\n",
            "Installing collected packages: tokenizers, transformers\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.15.0\n",
            "    Uninstalling tokenizers-0.15.0:\n",
            "      Successfully uninstalled tokenizers-0.15.0\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.35.2\n",
            "    Uninstalling transformers-4.35.2:\n",
            "      Successfully uninstalled transformers-4.35.2\n",
            "Successfully installed tokenizers-0.13.3 transformers-4.30.0\n",
            "Collecting datasets==2.13.2\n",
            "  Downloading datasets-2.13.2-py3-none-any.whl (512 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m512.7/512.7 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets==2.13.2) (1.23.5)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets==2.13.2) (10.0.1)\n",
            "Collecting dill<0.3.7,>=0.3.0 (from datasets==2.13.2)\n",
            "  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets==2.13.2) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets==2.13.2) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets==2.13.2) (4.66.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets==2.13.2) (3.4.1)\n",
            "Collecting multiprocess (from datasets==2.13.2)\n",
            "  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets==2.13.2) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets==2.13.2) (3.9.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from datasets==2.13.2) (0.20.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets==2.13.2) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets==2.13.2) (6.0.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.13.2) (23.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.13.2) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.13.2) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.13.2) (1.4.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.13.2) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.13.2) (4.0.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets==2.13.2) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets==2.13.2) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets==2.13.2) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets==2.13.2) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets==2.13.2) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets==2.13.2) (2023.11.17)\n",
            "INFO: pip is looking at multiple versions of multiprocess to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading multiprocess-0.70.14-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.3/134.3 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets==2.13.2) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets==2.13.2) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets==2.13.2) (1.16.0)\n",
            "Installing collected packages: dill, multiprocess, datasets\n",
            "Successfully installed datasets-2.13.2 dill-0.3.6 multiprocess-0.70.14\n",
            "Collecting accelerate\n",
            "  Downloading accelerate-0.26.1-py3-none-any.whl (270 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m270.9/270.9 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.13.0+cu116)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.20.2)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2023.11.17)\n",
            "Installing collected packages: accelerate\n",
            "Successfully installed accelerate-0.26.1\n",
            "Collecting evaluate\n",
            "  Downloading evaluate-0.4.1-py3-none-any.whl (84 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.13.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.23.5)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.3.6)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.66.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.70.14)\n",
            "Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2023.6.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.20.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (23.2)\n",
            "Collecting responses<0.19 (from evaluate)\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (10.0.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.9.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2023.11.17)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2023.3.post1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->evaluate) (1.16.0)\n",
            "Installing collected packages: responses, evaluate\n",
            "Successfully installed evaluate-0.4.1 responses-0.18.0\n"
          ]
        }
      ],
      "source": [
        "!pip install torch==1.13.0+cu116 --extra-index-url https://download.pytorch.org/whl/cu116\n",
        "!pip install transformers==4.30.0\n",
        "!pip install datasets==2.13.2\n",
        "!pip install accelerate -U\n",
        "!pip install evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-01-12T18:29:06.939068Z",
          "iopub.status.busy": "2024-01-12T18:29:06.938752Z",
          "iopub.status.idle": "2024-01-12T18:29:27.003689Z",
          "shell.execute_reply": "2024-01-12T18:29:27.002668Z",
          "shell.execute_reply.started": "2024-01-12T18:29:06.939042Z"
        },
        "id": "pD7fWLEPyh-B",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# system packages\n",
        "from pathlib import Path\n",
        "import shutil\n",
        "import urllib\n",
        "import tarfile\n",
        "import sys\n",
        "import os\n",
        "# data and numerical management packages\n",
        "import pandas as pd\n",
        "import random\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "# useful during debugging (progress bars)\n",
        "from tqdm import tqdm\n",
        "from transformers import set_seed\n",
        "\n",
        "seed = 852\n",
        "\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "set_seed(seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-01-12T18:29:27.005734Z",
          "iopub.status.busy": "2024-01-12T18:29:27.004994Z",
          "iopub.status.idle": "2024-01-12T18:29:27.161176Z",
          "shell.execute_reply": "2024-01-12T18:29:27.160394Z",
          "shell.execute_reply.started": "2024-01-12T18:29:27.005698Z"
        },
        "id": "6Vnl6q1Qyh-C",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "dataset_folder = Path.cwd().joinpath(\"MELD_train_efr.json\")\n",
        "#dataset_path = dataset_folder.joinpath('/MELD_train_efr.json')\n",
        "df = pd.read_json(dataset_folder)\n",
        "#df['triggers'] = df['triggers'].fillna(value=0, inplace=False)#.replace('None', 0.0)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "oq9_ohFH3yeX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 597
        },
        "outputId": "a2361045-facc-40f3-bad0-c5398630fc23"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             episode                                           speakers  \\\n",
              "0        utterance_0  [Chandler, The Interviewer, Chandler, The Inte...   \n",
              "1        utterance_1  [Chandler, The Interviewer, Chandler, The Inte...   \n",
              "2        utterance_2  [Chandler, The Interviewer, Chandler, The Inte...   \n",
              "3        utterance_3  [Chandler, The Interviewer, Chandler, The Inte...   \n",
              "4        utterance_4                       [Joey, Rachel, Joey, Rachel]   \n",
              "...              ...                                                ...   \n",
              "3995  utterance_3995  [Chandler, All, Monica, Chandler, Ross, Chandl...   \n",
              "3996  utterance_3996  [Chandler, All, Monica, Chandler, Ross, Chandl...   \n",
              "3997  utterance_3997  [Chandler, All, Monica, Chandler, Ross, Chandl...   \n",
              "3998  utterance_3998  [Chandler, All, Monica, Chandler, Ross, Chandl...   \n",
              "3999  utterance_3999  [Chandler, All, Monica, Chandler, Ross, Chandl...   \n",
              "\n",
              "                                               emotions  \\\n",
              "0        [neutral, neutral, neutral, neutral, surprise]   \n",
              "1     [neutral, neutral, neutral, neutral, surprise,...   \n",
              "2     [neutral, neutral, neutral, neutral, surprise,...   \n",
              "3     [neutral, neutral, neutral, neutral, surprise,...   \n",
              "4                   [surprise, sadness, surprise, fear]   \n",
              "...                                                 ...   \n",
              "3995  [neutral, joy, neutral, neutral, surprise, dis...   \n",
              "3996  [neutral, joy, neutral, neutral, surprise, dis...   \n",
              "3997  [neutral, joy, neutral, neutral, surprise, dis...   \n",
              "3998  [neutral, joy, neutral, neutral, surprise, dis...   \n",
              "3999  [neutral, joy, neutral, neutral, surprise, dis...   \n",
              "\n",
              "                                             utterances  \\\n",
              "0     [also I was the point person on my company's t...   \n",
              "1     [also I was the point person on my company's t...   \n",
              "2     [also I was the point person on my company's t...   \n",
              "3     [also I was the point person on my company's t...   \n",
              "4     [But then who? The waitress I went out with la...   \n",
              "...                                                 ...   \n",
              "3995  [Hey., Hey!, So how was Joan?, I broke up with...   \n",
              "3996  [Hey., Hey!, So how was Joan?, I broke up with...   \n",
              "3997  [Hey., Hey!, So how was Joan?, I broke up with...   \n",
              "3998  [Hey., Hey!, So how was Joan?, I broke up with...   \n",
              "3999  [Hey., Hey!, So how was Joan?, I broke up with...   \n",
              "\n",
              "                                               triggers  \n",
              "0                             [0.0, 0.0, 0.0, 1.0, 0.0]  \n",
              "1                   [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]  \n",
              "2     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...  \n",
              "3     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
              "4                                  [0.0, 0.0, 1.0, 0.0]  \n",
              "...                                                 ...  \n",
              "3995  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
              "3996  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
              "3997  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
              "3998  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
              "3999  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
              "\n",
              "[4000 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-58458e07-fd71-4753-9a4e-3816939a0c63\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>episode</th>\n",
              "      <th>speakers</th>\n",
              "      <th>emotions</th>\n",
              "      <th>utterances</th>\n",
              "      <th>triggers</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>utterance_0</td>\n",
              "      <td>[Chandler, The Interviewer, Chandler, The Inte...</td>\n",
              "      <td>[neutral, neutral, neutral, neutral, surprise]</td>\n",
              "      <td>[also I was the point person on my company's t...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 1.0, 0.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>utterance_1</td>\n",
              "      <td>[Chandler, The Interviewer, Chandler, The Inte...</td>\n",
              "      <td>[neutral, neutral, neutral, neutral, surprise,...</td>\n",
              "      <td>[also I was the point person on my company's t...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>utterance_2</td>\n",
              "      <td>[Chandler, The Interviewer, Chandler, The Inte...</td>\n",
              "      <td>[neutral, neutral, neutral, neutral, surprise,...</td>\n",
              "      <td>[also I was the point person on my company's t...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>utterance_3</td>\n",
              "      <td>[Chandler, The Interviewer, Chandler, The Inte...</td>\n",
              "      <td>[neutral, neutral, neutral, neutral, surprise,...</td>\n",
              "      <td>[also I was the point person on my company's t...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>utterance_4</td>\n",
              "      <td>[Joey, Rachel, Joey, Rachel]</td>\n",
              "      <td>[surprise, sadness, surprise, fear]</td>\n",
              "      <td>[But then who? The waitress I went out with la...</td>\n",
              "      <td>[0.0, 0.0, 1.0, 0.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3995</th>\n",
              "      <td>utterance_3995</td>\n",
              "      <td>[Chandler, All, Monica, Chandler, Ross, Chandl...</td>\n",
              "      <td>[neutral, joy, neutral, neutral, surprise, dis...</td>\n",
              "      <td>[Hey., Hey!, So how was Joan?, I broke up with...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3996</th>\n",
              "      <td>utterance_3996</td>\n",
              "      <td>[Chandler, All, Monica, Chandler, Ross, Chandl...</td>\n",
              "      <td>[neutral, joy, neutral, neutral, surprise, dis...</td>\n",
              "      <td>[Hey., Hey!, So how was Joan?, I broke up with...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3997</th>\n",
              "      <td>utterance_3997</td>\n",
              "      <td>[Chandler, All, Monica, Chandler, Ross, Chandl...</td>\n",
              "      <td>[neutral, joy, neutral, neutral, surprise, dis...</td>\n",
              "      <td>[Hey., Hey!, So how was Joan?, I broke up with...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3998</th>\n",
              "      <td>utterance_3998</td>\n",
              "      <td>[Chandler, All, Monica, Chandler, Ross, Chandl...</td>\n",
              "      <td>[neutral, joy, neutral, neutral, surprise, dis...</td>\n",
              "      <td>[Hey., Hey!, So how was Joan?, I broke up with...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3999</th>\n",
              "      <td>utterance_3999</td>\n",
              "      <td>[Chandler, All, Monica, Chandler, Ross, Chandl...</td>\n",
              "      <td>[neutral, joy, neutral, neutral, surprise, dis...</td>\n",
              "      <td>[Hey., Hey!, So how was Joan?, I broke up with...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4000 rows × 5 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-58458e07-fd71-4753-9a4e-3816939a0c63')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-58458e07-fd71-4753-9a4e-3816939a0c63 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-58458e07-fd71-4753-9a4e-3816939a0c63');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-f593f09e-b421-48b1-9001-bed4cb4c6a06\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f593f09e-b421-48b1-9001-bed4cb4c6a06')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-f593f09e-b421-48b1-9001-bed4cb4c6a06 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-01-12T18:29:27.164488Z",
          "iopub.status.busy": "2024-01-12T18:29:27.164068Z",
          "iopub.status.idle": "2024-01-12T18:29:27.353387Z",
          "shell.execute_reply": "2024-01-12T18:29:27.352697Z",
          "shell.execute_reply.started": "2024-01-12T18:29:27.164451Z"
        },
        "id": "PK4MQkLvyh-C",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "triggers = df['triggers']\n",
        "for row in range(triggers.shape[0]):\n",
        "    for trigger in range(len(triggers[row])):\n",
        "        if triggers[row][trigger] == None:\n",
        "            triggers[row][trigger] = 0.0\n",
        "\n",
        "df['triggers'] = triggers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-01-12T18:29:27.354645Z",
          "iopub.status.busy": "2024-01-12T18:29:27.354368Z",
          "iopub.status.idle": "2024-01-12T18:29:27.374027Z",
          "shell.execute_reply": "2024-01-12T18:29:27.373203Z",
          "shell.execute_reply.started": "2024-01-12T18:29:27.354621Z"
        },
        "id": "QFfykazN2xDw",
        "outputId": "a8f1cf64-38de-4fcb-8018-e2692ced9f4a",
        "trusted": true
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['neutral', 'surprise', 'fear', 'sadness', 'joy', 'disgust',\n",
              "       'anger'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "emotions = df['emotions'].explode().unique()\n",
        "emotions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-01-12T18:29:27.375319Z",
          "iopub.status.busy": "2024-01-12T18:29:27.375078Z",
          "iopub.status.idle": "2024-01-12T18:29:27.390235Z",
          "shell.execute_reply": "2024-01-12T18:29:27.389245Z",
          "shell.execute_reply.started": "2024-01-12T18:29:27.375298Z"
        },
        "trusted": true,
        "id": "p10v1luzDn1M"
      },
      "outputs": [],
      "source": [
        "triggers = df['triggers'].explode().unique()\n",
        "triggers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-01-12T18:29:27.392361Z",
          "iopub.status.busy": "2024-01-12T18:29:27.391490Z",
          "iopub.status.idle": "2024-01-12T18:29:27.412862Z",
          "shell.execute_reply": "2024-01-12T18:29:27.411917Z",
          "shell.execute_reply.started": "2024-01-12T18:29:27.392329Z"
        },
        "id": "q39q6ZPh-tCy",
        "outputId": "8185e848-d808-4c01-cf42-3abde137cc6f",
        "trusted": true
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(24, 219)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "dialogues = df['utterances']\n",
        "#print(sentences)\n",
        "max_len_dialogue = 0\n",
        "index = 0\n",
        "for idx, dialogue in enumerate(dialogues):\n",
        "  if len(dialogue) > max_len_dialogue:\n",
        "    max_len_dialogue = len(dialogue)\n",
        "    index = idx\n",
        "max_len_dialogue,index"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dialogues = df['utterances']\n",
        "#print(sentences)\n",
        "max_len_sentence = 0\n",
        "index = 0\n",
        "for idx, dialogue in enumerate(dialogues):\n",
        "  for idx_sentence, utterance in enumerate(dialogue):\n",
        "    if len(utterance.split()) > max_len_sentence:\n",
        "      max_len_sentence = len(utterance.split())\n",
        "      index = idx,idx_sentence\n",
        "max_len_sentence,index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CwdTYBlTMvli",
        "outputId": "fc6d5b14-3550-4aba-ad2d-71551b233700"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(69, (1675, 11))"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2bP0X_ZEvFSp"
      },
      "source": [
        "### Be careful for the token used during padding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-01-12T18:30:39.880460Z",
          "iopub.status.busy": "2024-01-12T18:30:39.879732Z",
          "iopub.status.idle": "2024-01-12T18:30:39.889776Z",
          "shell.execute_reply": "2024-01-12T18:30:39.888865Z",
          "shell.execute_reply.started": "2024-01-12T18:30:39.880426Z"
        },
        "trusted": true,
        "id": "HHLo6FwYDn1M"
      },
      "outputs": [],
      "source": [
        "padded_dialogues = [seq + ['[PAD]'] * (max_len_dialogue - len(seq)) for seq in dialogues]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-01-12T18:30:45.278400Z",
          "iopub.status.busy": "2024-01-12T18:30:45.278059Z",
          "iopub.status.idle": "2024-01-12T18:30:45.517596Z",
          "shell.execute_reply": "2024-01-12T18:30:45.516517Z",
          "shell.execute_reply.started": "2024-01-12T18:30:45.278375Z"
        },
        "trusted": true,
        "id": "FsgpSVdgDn1M"
      },
      "outputs": [],
      "source": [
        "padded_emotions = [seq + ['[PAD]'] * (max_len_dialogue - len(seq)) for seq in df['emotions']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-01-12T18:31:01.496584Z",
          "iopub.status.busy": "2024-01-12T18:31:01.496212Z",
          "iopub.status.idle": "2024-01-12T18:31:01.506197Z",
          "shell.execute_reply": "2024-01-12T18:31:01.505122Z",
          "shell.execute_reply.started": "2024-01-12T18:31:01.496553Z"
        },
        "id": "-PH9rccxqc6g",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "triggers = df['triggers']\n",
        "padded_triggers = [seq + [0] * (max_len_dialogue - len(seq)) for seq in triggers]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-01-12T18:31:04.443590Z",
          "iopub.status.busy": "2024-01-12T18:31:04.443208Z",
          "iopub.status.idle": "2024-01-12T18:31:04.493733Z",
          "shell.execute_reply": "2024-01-12T18:31:04.492236Z",
          "shell.execute_reply.started": "2024-01-12T18:31:04.443561Z"
        },
        "id": "Cg7CppRVvg0-",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "\"\"\"tokenized_input_ids = []\n",
        "tokenized_attention_mask = []\n",
        "tokenized_token_type_ids = []\n",
        "\n",
        "for utterance_list in padded_dialogues:\n",
        "  utterance_input_ids = []\n",
        "  utterance_attention_mask = []\n",
        "  utterance_token_type_ids = []\n",
        "  for utterance in utterance_list:\n",
        "    tokenized_texts = tokenizer(utterance,return_tensors='pt')# padding='max_length', max_length=max_len, )\n",
        "    utterance_input_ids.extend(tokenized_texts.input_ids)\n",
        "    utterance_attention_mask.extend(tokenized_texts.attention_mask)\n",
        "    utterance_token_type_ids.extend(tokenized_texts.token_type_ids)\n",
        "\n",
        "  tokenized_input_ids.append(utterance_input_ids)\n",
        "  tokenized_attention_mask.append(utterance_attention_mask)\n",
        "  tokenized_token_type_ids.append(utterance_token_type_ids)\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-12T18:29:29.077108Z",
          "iopub.status.idle": "2024-01-12T18:29:29.077562Z",
          "shell.execute_reply": "2024-01-12T18:29:29.077331Z",
          "shell.execute_reply.started": "2024-01-12T18:29:29.077311Z"
        },
        "id": "va6wzu7gx9nw",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "\"\"\"emotions_input_ids = []\n",
        "emotions_attention_mask = []\n",
        "emotions_token_type_ids = []\n",
        "\n",
        "for utterance_list in padded_emotions:\n",
        "  emotion_input_ids = []\n",
        "  emotion_attention_mask = []\n",
        "  emotion_token_type_ids = []\n",
        "  for utterance in utterance_list:\n",
        "    tokenized_texts = tokenizer(utterance,return_tensors='pt')# padding='max_length', max_length=max_len, )\n",
        "    emotion_input_ids.append(tokenized_texts.input_ids)\n",
        "    emotion_attention_mask.append(tokenized_texts.attention_mask)\n",
        "    emotion_token_type_ids.append(tokenized_texts.token_type_ids)\n",
        "\n",
        "  emotions_input_ids.append(emotion_input_ids)\n",
        "  emotions_attention_mask.append(emotion_attention_mask)\n",
        "  emotions_token_type_ids.append(emotion_token_type_ids)\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-12T18:29:29.078716Z",
          "iopub.status.idle": "2024-01-12T18:29:29.079188Z",
          "shell.execute_reply": "2024-01-12T18:29:29.078961Z",
          "shell.execute_reply.started": "2024-01-12T18:29:29.078938Z"
        },
        "trusted": true,
        "id": "nDNbg7j_Dn1N"
      },
      "outputs": [],
      "source": [
        "df['emotions'][:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-12T18:29:29.083480Z",
          "iopub.status.idle": "2024-01-12T18:29:29.083825Z",
          "shell.execute_reply": "2024-01-12T18:29:29.083646Z",
          "shell.execute_reply.started": "2024-01-12T18:29:29.083631Z"
        },
        "id": "xgporu7myOr3",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "pad = torch.from_numpy(np.array([0]))\n",
        "padded_utterances_input_ids = [seq + [pad] * (max_len - len(seq)) for seq in tokenized_input_ids]\n",
        "padded_utterances_attention_mask = [seq + [torch.from_numpy(np.array([1]))] * (max_len - len(seq)) for seq in tokenized_attention_mask]\n",
        "padded_utterances_token_type_ids = [seq + [pad] * (max_len - len(seq)) for seq in tokenized_token_type_ids]\n",
        "pad_as_1 = torch.from_numpy(np.array([1]))\n",
        "padded_emotions_input_ids = [seq + [pad] * (max_len - len(seq)) for seq in emotions_input_ids]\n",
        "padded_emotions_attention_mask = [seq + [pad_as_1] * (max_len - len(seq)) for seq in emotions_attention_mask]\n",
        "padded_emotions_token_type_ids = [seq + [pad] * (max_len - len(seq)) for seq in emotions_token_type_ids]\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-12T18:29:29.084890Z",
          "iopub.status.idle": "2024-01-12T18:29:29.085217Z",
          "shell.execute_reply": "2024-01-12T18:29:29.085070Z",
          "shell.execute_reply.started": "2024-01-12T18:29:29.085054Z"
        },
        "trusted": true,
        "id": "EZDF8laGDn1N"
      },
      "outputs": [],
      "source": [
        "#emotion_mapping = {emotion: idx+1 for idx, emotion in enumerate(emotions)}\n",
        "#emotions_numerical_format = [[emotion_mapping[emotion] for emotion in dialogue] for dialogue in df['emotions']]\n",
        "#padded_emotions = [seq + [0] * (max_len_dialogue - len(seq)) for seq in emotions_numerical_format]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if np.isin('[PAD]', emotions).any() == False:\n",
        "  emotions = np.append(emotions,np.array(['[PAD]']))"
      ],
      "metadata": {
        "id": "Ie-PzRN9jfFA"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-01-12T18:32:51.180932Z",
          "iopub.status.busy": "2024-01-12T18:32:51.180195Z",
          "iopub.status.idle": "2024-01-12T18:32:57.227091Z",
          "shell.execute_reply": "2024-01-12T18:32:57.226294Z",
          "shell.execute_reply.started": "2024-01-12T18:32:51.180896Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_R-6uNvEDn1O",
        "outputId": "e3f9c2b1-e2e4-4d49-8acc-680f1fe2f9c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer\n",
        "from transformers import AutoModelForSequenceClassification\n",
        "from transformers import DataCollatorWithPadding\n",
        "model_card = 'bert-base-uncased'\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_card)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_card,\n",
        "                                                           num_labels= len(emotions),#max_len_dialogue +1 padding\n",
        "                                                           id2label=id_to_emotion,\n",
        "                                                           label2id=emotion_to_id,\n",
        "                                                           problem_type=\"multi_label_classification\")\n",
        "\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelBinarizer\n",
        "sorted_emotions = sorted(emotions)  #sort the array because Binarizer will automatically do that for one hot encoding\n",
        "label_binarizer = LabelBinarizer()\n",
        "label_binarizer.fit(sorted_emotions)\n",
        "numerical_representation = [label_binarizer.transform(sublist) for sublist in padded_emotions]"
      ],
      "metadata": {
        "id": "p-lg0CiZaqUQ"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a dictionary from ID to emotions\n",
        "id_to_emotion = {idx: emotion for idx, emotion in enumerate(emotions)}\n",
        "\n",
        "# Create a dictionary from emotion to ID\n",
        "emotion_to_id = {emotion: idx for idx, emotion in enumerate(emotions)}\n",
        "\n",
        "# Print the dictionaries\n",
        "print(\"ID to Emotion:\", id_to_emotion)\n",
        "print(\"Emotion to ID:\", emotion_to_id)\n",
        "\n",
        "exitmotions_numerical_format = [[emotion_to_id[emotion] for emotion in dialogue] for dialogue in padded_emotions]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K1oXDNhV59LJ",
        "outputId": "c614b679-2d53-4cc4-a942-1880bea7e818"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ID to Emotion: {0: 'neutral', 1: 'surprise', 2: 'fear', 3: 'sadness', 4: 'joy', 5: 'disgust', 6: 'anger'}\n",
            "Emotion to ID: {'neutral': 0, 'surprise': 1, 'fear': 2, 'sadness': 3, 'joy': 4, 'disgust': 5, 'anger': 6}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "exitmotions_numerical_format[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OYyyBteC6h8a",
        "outputId": "c734adaa-3289-4a53-be4b-0d670755c24d"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 0, 0, 0, 1, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7]"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-01-12T18:31:29.907488Z",
          "iopub.status.busy": "2024-01-12T18:31:29.907098Z",
          "iopub.status.idle": "2024-01-12T18:31:30.467067Z",
          "shell.execute_reply": "2024-01-12T18:31:30.466119Z",
          "shell.execute_reply.started": "2024-01-12T18:31:29.907457Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "4IalqGDZDn1N",
        "outputId": "e4dc5db0-1779-4e7d-fe13-58f4b240b211"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'exitmotions_numerical_format' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-db75e2c9c48f>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m data = {\n\u001b[1;32m      2\u001b[0m     \u001b[0;34m'episode'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'episode'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;34m'labels'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mexitmotions_numerical_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m#emotions_input_ids, #tokenized emotions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;34m'emotions'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mpadded_emotions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m#emotions_input_ids, #tokenized emotions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;34m'utterances'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpadded_dialogues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'exitmotions_numerical_format' is not defined"
          ]
        }
      ],
      "source": [
        "data = {\n",
        "    'episode' : df['episode'],\n",
        "    'labels' : exitmotions_numerical_format,#emotions_input_ids, #tokenized emotions\n",
        "    'emotions' : padded_emotions,#emotions_input_ids, #tokenized emotions\n",
        "    'utterances': padded_dialogues,\n",
        "}\n",
        "df_tokenized = pd.DataFrame(data)\n",
        "from sklearn.model_selection import train_test_split\n",
        "train_data, temp_data = train_test_split(df_tokenized, train_size=0.8, shuffle=False)\n",
        "val_data, test_data = train_test_split(temp_data, test_size=0.5, shuffle=False)\n",
        "train_data.shape, val_data.shape,test_data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-01-12T18:31:32.620514Z",
          "iopub.status.busy": "2024-01-12T18:31:32.620181Z",
          "iopub.status.idle": "2024-01-12T18:31:33.260777Z",
          "shell.execute_reply": "2024-01-12T18:31:33.259836Z",
          "shell.execute_reply.started": "2024-01-12T18:31:32.620488Z"
        },
        "trusted": true,
        "id": "0t3b7RYBDn1O"
      },
      "outputs": [],
      "source": [
        "from datasets import Dataset\n",
        "training_hf = Dataset.from_pandas(train_data)\n",
        "validation_hf = Dataset.from_pandas(val_data)\n",
        "test_hf = Dataset.from_pandas(test_data)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels_np = np.array(exitmotions_numerical_format)\n",
        "print((labels_np[3600]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NEUjEtzsUkk3",
        "outputId": "6154c49a-241c-4391-a278-e0b552e5a10c"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0 1 0 0 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_emotions = df['emotions']\n",
        "test_utterances = df['utterances']\n",
        "flattened_list_emotion = [[item] for sublist in test_emotions for item in sublist]\n",
        "flattened_list_utterances = [item for sublist in test_utterances for item in sublist]"
      ],
      "metadata": {
        "id": "VEj3dMGMEyma"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelBinarizer\n",
        "sorted_emotions = sorted(emotions)  #sort the array because Binarizer will automatically do that for one hot encoding\n",
        "label_binarizer = LabelBinarizer()\n",
        "label_binarizer.fit(sorted_emotions)\n",
        "#emotion_numerical_format_test = [emotion_to_id[emotion] for emotion in flattened_list_emotion]\n",
        "#Binarizer_test = [label_binarizer.transform(emotion) for emotion in flattened_list_emotion]\n",
        "binarizer_test = []\n",
        "for emotion in flattened_list_emotion:\n",
        "    binarized_emotion = label_binarizer.transform(emotion)\n",
        "    binarizer_test.extend(binarized_emotion.tolist())"
      ],
      "metadata": {
        "id": "H6K5IJ0-NLlL"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "binarizer_test[0]\n",
        "binarizer_test_np = np.array(binarizer_test,dtype=float)"
      ],
      "metadata": {
        "id": "9XLTwb8eN98z"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "binarizer_test_np"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5QR1D9CCPsRt",
        "outputId": "d169d2d0-ebe0-4687-816b-2b452ac6152d"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 1., 0., 0.],\n",
              "       [0., 0., 0., ..., 1., 0., 0.],\n",
              "       [0., 0., 0., ..., 1., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 1., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 1.],\n",
              "       [0., 0., 0., ..., 1., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#emotion_numerical_format_test = [emotion_to_id[emotion] for emotion in flattened_list_emotion]"
      ],
      "metadata": {
        "id": "VNnB51_NGYZk"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "binarizer_test_np = binarizer_test_np.astype(np.float32).tolist()\n",
        "binarizer_test_np"
      ],
      "metadata": {
        "id": "1ZMzF60fQJwE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "data_test = {\n",
        "    'labels' : binarizer_test,#emotions_input_ids, #tokenized emotions\n",
        "    'utterances': flattened_list_utterances,\n",
        "}\n",
        "df_test = pd.DataFrame(data_test)\n",
        "train_data_test, temp_data_test = train_test_split(df_test, train_size=0.8, shuffle=False)\n",
        "val_data_test, test_data_test = train_test_split(temp_data_test, test_size=0.5, shuffle=False)"
      ],
      "metadata": {
        "id": "-rMn2hE6GC1T"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_data_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "wvfwTvnyHooa",
        "outputId": "a6ec3d70-299f-408b-cbcd-a6d1c1d50283"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                      labels  \\\n",
              "28000  [0, 0, 0, 0, 1, 0, 0]   \n",
              "28001  [0, 0, 0, 1, 0, 0, 0]   \n",
              "28002  [0, 0, 0, 1, 0, 0, 0]   \n",
              "28003  [0, 0, 0, 1, 0, 0, 0]   \n",
              "28004  [0, 1, 0, 0, 0, 0, 0]   \n",
              "...                      ...   \n",
              "31495  [0, 0, 0, 0, 1, 0, 0]   \n",
              "31496  [0, 0, 0, 0, 0, 0, 1]   \n",
              "31497  [0, 0, 0, 0, 1, 0, 0]   \n",
              "31498  [0, 0, 0, 0, 1, 0, 0]   \n",
              "31499  [0, 0, 0, 1, 0, 0, 0]   \n",
              "\n",
              "                                              utterances  \n",
              "28000        (noticing a kid who has picked up a copy of  \n",
              "28001  Oh yeah, yeah! He's done tons of commercials. ...  \n",
              "28002            Yeah well, he's not gonna get this one.  \n",
              "28003                    Ben is way cuter than that kid.  \n",
              "28004                   I mean look at him, look at you,  \n",
              "...                                                  ...  \n",
              "31495  Just wanna check my horoscope, see if it was r...  \n",
              "31496                                         Oh my God.  \n",
              "31497                                            Phoebe.  \n",
              "31498  Don't look now, but behind us is a guy who has...  \n",
              "31499                        Where?  Ooh, come to Momma.  \n",
              "\n",
              "[3500 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8c46c19a-a2bf-4de5-81d5-d80b9147b8df\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>labels</th>\n",
              "      <th>utterances</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>28000</th>\n",
              "      <td>[0, 0, 0, 0, 1, 0, 0]</td>\n",
              "      <td>(noticing a kid who has picked up a copy of</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28001</th>\n",
              "      <td>[0, 0, 0, 1, 0, 0, 0]</td>\n",
              "      <td>Oh yeah, yeah! He's done tons of commercials. ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28002</th>\n",
              "      <td>[0, 0, 0, 1, 0, 0, 0]</td>\n",
              "      <td>Yeah well, he's not gonna get this one.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28003</th>\n",
              "      <td>[0, 0, 0, 1, 0, 0, 0]</td>\n",
              "      <td>Ben is way cuter than that kid.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28004</th>\n",
              "      <td>[0, 1, 0, 0, 0, 0, 0]</td>\n",
              "      <td>I mean look at him, look at you,</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31495</th>\n",
              "      <td>[0, 0, 0, 0, 1, 0, 0]</td>\n",
              "      <td>Just wanna check my horoscope, see if it was r...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31496</th>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 1]</td>\n",
              "      <td>Oh my God.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31497</th>\n",
              "      <td>[0, 0, 0, 0, 1, 0, 0]</td>\n",
              "      <td>Phoebe.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31498</th>\n",
              "      <td>[0, 0, 0, 0, 1, 0, 0]</td>\n",
              "      <td>Don't look now, but behind us is a guy who has...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31499</th>\n",
              "      <td>[0, 0, 0, 1, 0, 0, 0]</td>\n",
              "      <td>Where?  Ooh, come to Momma.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3500 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8c46c19a-a2bf-4de5-81d5-d80b9147b8df')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8c46c19a-a2bf-4de5-81d5-d80b9147b8df button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8c46c19a-a2bf-4de5-81d5-d80b9147b8df');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-1ee852da-5c32-4fdf-8030-e2f494f3afeb\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1ee852da-5c32-4fdf-8030-e2f494f3afeb')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-1ee852da-5c32-4fdf-8030-e2f494f3afeb button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_data_test['labels'].tolist()"
      ],
      "metadata": {
        "id": "vyUUe-r_WHIN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Dataset\n",
        "def preprocess_function(examples):\n",
        "    tokenized_inputs = tokenizer(examples['utterances'].tolist(), padding=True, truncation=True)\n",
        "    # Convert labels to a PyTorch tensor of type long\n",
        "    labels = examples['labels'].tolist()\n",
        "    #labels_np = np.array(labels)\n",
        "    #labels_tensor = torch.tensor(labels_np, dtype=torch.long)\n",
        "\n",
        "    # Create a PyTorch Dataset\n",
        "    return Dataset.from_dict({\n",
        "        'input_ids': tokenized_inputs['input_ids'],\n",
        "        'attention_mask': tokenized_inputs['attention_mask'],\n",
        "        'labels': np.array(labels).astype(np.float32).tolist()#torch.tensor(np.array(labels), dtype=torch.float)\n",
        "    })\n",
        "val_dataset_test = preprocess_function(val_data_test)\n",
        "\n",
        "\n",
        "#validation_hf = Dataset.from_pandas(val_data_test)\n",
        "#val_dataset_test = validation_hf.map(preprocess_function, batched=True)"
      ],
      "metadata": {
        "id": "j87WsquPHNca"
      },
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-01-12T18:33:25.558075Z",
          "iopub.status.busy": "2024-01-12T18:33:25.557724Z",
          "iopub.status.idle": "2024-01-12T18:33:47.730246Z",
          "shell.execute_reply": "2024-01-12T18:33:47.729333Z",
          "shell.execute_reply.started": "2024-01-12T18:33:25.558047Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "4NXHHI1fDn1O",
        "outputId": "e30a8baa-0b75-43ef-977b-17f450a51594"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'val_data' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-63-2d70f406554a>\u001b[0m in \u001b[0;36m<cell line: 64>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;31m# Now call preprocess_data to process your train and validation data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;31m#train_dataset = preprocess_text(train_data)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m \u001b[0mval_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \"\"\"training = training_hf.map(preprocess_text, batched=True)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'val_data' is not defined"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from datasets import Dataset\n",
        "def preprocess_text(texts):\n",
        "    tokenized_inputs = tokenizer([\" \".join(utterance) for utterance in texts['utterances']],padding='max_length', truncation=True, max_length=max_len_dialogue, return_tensors='pt')\n",
        "\n",
        "    tokenized_input_ids = []\n",
        "    tokenized_attention_mask = []\n",
        "    tokenized_token_type_ids = []\n",
        "\n",
        "    for utterance_list in texts['utterances']:\n",
        "      utterance_input_ids = []\n",
        "      utterance_attention_mask = []\n",
        "      utterance_token_type_ids = []\n",
        "      for utterance in utterance_list:\n",
        "        tokenized_texts = tokenizer(utterance,padding=True,truncation=True,return_tensors='pt')# padding='max_length', max_length=max_len, )\n",
        "        utterance_input_ids.extend(tokenized_texts.input_ids)\n",
        "        utterance_attention_mask.extend(tokenized_texts.attention_mask)\n",
        "        utterance_token_type_ids.extend(tokenized_texts.token_type_ids)\n",
        "\n",
        "      tokenized_input_ids.append(utterance_input_ids)\n",
        "      tokenized_attention_mask.append(utterance_attention_mask)\n",
        "      tokenized_token_type_ids.append(utterance_token_type_ids)\n",
        "    #labels_tensor = torch.tensor(labels_np[3200:3600,:], dtype=torch.float)\n",
        "    labels_tensor = torch.tensor(labels_np[3200:3600, :], dtype=torch.float)\n",
        "\n",
        "    print(labels_tensor.shape)\n",
        "    print(torch.tensor(tokenized_inputs['input_ids'],dtype=torch.float).shape)\n",
        "    print(torch.tensor(tokenized_inputs['attention_mask'],dtype=torch.float).shape)\n",
        "    print(tokenized_inputs['input_ids'][0])\n",
        "    print(type(tokenized_inputs['input_ids']))\n",
        "\n",
        "    return Dataset.from_dict({\n",
        "        'input_ids': tokenized_input_ids,#tokenized_inputs['input_ids'],\n",
        "        'attention_mask': tokenized_attention_mask,#tokenized_inputs['attention_mask'],\n",
        "        'labels': labels_tensor\n",
        "    })\n",
        "\n",
        "\"\"\"def preprocess_data(data, tokenizer, mlb):\n",
        "    # Tokenize the utterances\n",
        "    tokenized_inputs = tokenizer(\n",
        "        [\" \".join(utterance) for utterance in data['utterances']],\n",
        "        padding='max_length',\n",
        "        truncation=True,\n",
        "        max_length=128, # we might wanna change this to max_len !\n",
        "        return_tensors='pt'\n",
        "    )\n",
        "\n",
        "    # Encode the emotions\n",
        "    encoded_labels = mlb.transform(data['emotions'])\n",
        "    # Convert labels to tensors\n",
        "    labels_tensor = torch.tensor(encoded_labels, dtype=torch.float)\n",
        "    # Ensure the encoded labels are the correct shape (this step is crucial to avoid the batch size mismatch)\n",
        "    if labels_tensor.shape[0] != tokenized_inputs['input_ids'].shape[0]:\n",
        "        raise ValueError(f\"Number of examples {tokenized_inputs['input_ids'].shape[0]} does not match number of labels {labels_tensor.shape[0]}\")\n",
        "\n",
        "    return Dataset.from_dict({\n",
        "        'input_ids': tokenized_inputs['input_ids'],\n",
        "        'attention_mask': tokenized_inputs['attention_mask'],\n",
        "        'labels': labels_tensor\n",
        "    })\"\"\"\n",
        "\n",
        "# Now call preprocess_data to process your train and validation data\n",
        "#train_dataset = preprocess_text(train_data)\n",
        "val_dataset = preprocess_text(val_data)\n",
        "\n",
        "\"\"\"training = training_hf.map(preprocess_text, batched=True)\n",
        "validation = validation_hf.map(preprocess_text, batched=True)\n",
        "test = test_hf.map(preprocess_text, batched=True)\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-12T18:29:29.095177Z",
          "iopub.status.idle": "2024-01-12T18:29:29.095520Z",
          "shell.execute_reply": "2024-01-12T18:29:29.095374Z",
          "shell.execute_reply.started": "2024-01-12T18:29:29.095358Z"
        },
        "trusted": true,
        "id": "REXJ9ahkDn1O"
      },
      "outputs": [],
      "source": [
        "for name, param in model.named_parameters():\n",
        "    if 'embeddings' in name: # Layer names not containing 'classifier' will be frozen\n",
        "        param.requires_grad = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-12T18:29:29.098643Z",
          "iopub.status.idle": "2024-01-12T18:29:29.099012Z",
          "shell.execute_reply": "2024-01-12T18:29:29.098866Z",
          "shell.execute_reply.started": "2024-01-12T18:29:29.098850Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 414
        },
        "id": "CcSpQVBPDn1O",
        "outputId": "e725a583-e4fe-455a-a95c-69e8808e2248"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='7' max='2100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [   7/2100 00:24 < 2:51:34, 0.20 it/s, Epoch 0.01/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-127-b4b922d941db>\u001b[0m in \u001b[0;36m<cell line: 27>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;31m#compute_metrics=compute_metrics,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m )\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1643\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inner_training_loop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_batch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_find_batch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1644\u001b[0m         )\n\u001b[0;32m-> 1645\u001b[0;31m         return inner_training_loop(\n\u001b[0m\u001b[1;32m   1646\u001b[0m             \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1647\u001b[0m             \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1927\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1928\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccumulate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1929\u001b[0;31m                     \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1930\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1931\u001b[0m                 if (\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   2759\u001b[0m                 \u001b[0mscaled_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2760\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2761\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2762\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2763\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient_accumulation_steps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, loss, **kwargs)\u001b[0m\n\u001b[1;32m   1962\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1963\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1964\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1965\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1966\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mset_trigger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    485\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m             )\n\u001b[0;32m--> 487\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    488\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    198\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from transformers import TrainingArguments\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"test_dir\",                 # where to save model\n",
        "    learning_rate=1e-5,\n",
        "    per_device_train_batch_size=5,         # accelerate defines distributed training\n",
        "    per_device_eval_batch_size=50,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.1,\n",
        "    evaluation_strategy=\"epoch\",           # when to report evaluation metrics/losses\n",
        "    logging_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",                 # when to save checkpoint\n",
        "    load_best_model_at_end=True,\n",
        "    report_to='none'                       # disabling wandb (default)\n",
        ")\n",
        "from transformers import Trainer\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=val_dataset_test,\n",
        "    eval_dataset=val_dataset_test,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    #compute_metrics=compute_metrics,\n",
        ")\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#metrics = compute_metrics(test_prediction_info)\n",
        "#print(test_prediction_info)\n",
        "test_prediction_info = trainer.predict(val_dataset)\n",
        "test_prediction_info.label_ids.shape\n",
        "test_prediction_info.predictions[0],test_prediction_info.label_ids[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "N8YJOupL7TKL",
        "outputId": "8adeb6b9-a43b-44fc-999f-82d101379e34"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([ 0.27739397,  0.29370916, -0.1685992 ,  0.3684679 , -0.42971808,\n",
              "        -0.27069902,  0.37707573, -0.14887775, -0.32769036,  0.07534103,\n",
              "         0.3421814 ,  0.18997188,  0.51304376,  0.395989  ,  0.90670776,\n",
              "         0.54127747,  0.71304816,  0.76001567,  0.79307735,  0.6367639 ,\n",
              "         0.6389566 , -0.04435933,  0.5742843 ,  0.4485132 ], dtype=float32),\n",
              " array([0., 0., 0., 0., 0., 3., 2., 0., 4., 7., 7., 7., 7., 7., 7., 7., 7.,\n",
              "        7., 7., 7., 7., 7., 7., 7.], dtype=float32))"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class EmotionDataset(Dataset):\n",
        "    def __init__(self, data, labels, tokenizer, max_seq_length=128):\n",
        "        self.data = data\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_seq_length = max_seq_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        utterances = self.data[idx]  # List of strings, each representing an utterance\n",
        "        encodings = self.tokenizer(utterances, truncation=True, padding='max_length', max_length=self.max_seq_length, return_tensors='pt')\n",
        "        print(\"input_ids shape:\", encodings['input_ids'].shape)\n",
        "        print(\"attention_mask shape:\", encodings['attention_mask'].shape)\n",
        "        # Make sure 'input_ids' and 'attention_mask' are present in the encoding\n",
        "        input_ids = encodings['input_ids'].squeeze()\n",
        "        attention_mask = encodings['attention_mask'].squeeze()\n",
        "\n",
        "        label = torch.tensor(self.labels[idx], dtype=torch.float32)\n",
        "        return {'input_ids': input_ids, 'attention_mask': attention_mask, 'labels': label}\n",
        "\n",
        "\n",
        "# Replace with your actual data\n",
        "data = padded_dialogues\n",
        "\n",
        "# Replace with your one-hot encoded labels\n",
        "labels = numerical_representation\n",
        "\n",
        "# Hyperparameters\n",
        "model_name = \"bert-base-uncased\"\n",
        "num_emotions = 8\n",
        "max_seq_length = 128\n",
        "batch_size = 5\n",
        "epochs = 1\n",
        "\n",
        "# Load tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Create dataset\n",
        "dataset = EmotionDataset(data, labels, tokenizer, max_seq_length)\n",
        "\n",
        "# Define training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./emotion_classification\",\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    num_train_epochs=epochs,\n",
        "    logging_dir=\"./logs\",\n",
        ")\n",
        "\n",
        "# Initialize the model\n",
        "model = BertForSequenceClassification.from_pretrained(model_name, num_labels=num_emotions)\n",
        "\n",
        "# Define Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=dataset,\n",
        "    data_collator=lambda data: {'input_ids': torch.stack([item['input_ids'] for item in data]),\n",
        "                                'attention_mask': torch.stack([item['attention_mask'] for item in data]),\n",
        "                                'labels': torch.stack([item['labels'] for item in data])}\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "trainer.train()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 653
        },
        "id": "nipHAYDC2VhJ",
        "outputId": "a6a4dda9-a049-43af-8cb9-909c0ed185aa"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input_ids shape: torch.Size([24, 128])\n",
            "attention_mask shape: torch.Size([24, 128])\n",
            "input_ids shape: torch.Size([24, 128])\n",
            "attention_mask shape: torch.Size([24, 128])\n",
            "input_ids shape: torch.Size([24, 128])\n",
            "attention_mask shape: torch.Size([24, 128])\n",
            "input_ids shape: torch.Size([24, 128])\n",
            "attention_mask shape: torch.Size([24, 128])\n",
            "input_ids shape: torch.Size([24, 128])\n",
            "attention_mask shape: torch.Size([24, 128])\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "too many values to unpack (expected 2)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-55-b125cd6cbc7c>\u001b[0m in \u001b[0;36m<cell line: 69>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1643\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inner_training_loop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_batch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_find_batch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1644\u001b[0m         )\n\u001b[0;32m-> 1645\u001b[0;31m         return inner_training_loop(\n\u001b[0m\u001b[1;32m   1646\u001b[0m             \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1647\u001b[0m             \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1927\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1928\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccumulate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1929\u001b[0;31m                     \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1930\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1931\u001b[0m                 if (\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   2748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2749\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss_context_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2750\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2752\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_gpu\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mcompute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   2773\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2774\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2775\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2776\u001b[0m         \u001b[0;31m# Save past state if it exists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2777\u001b[0m         \u001b[0;31m# TODO: this needs to be fixed and made cleaner later.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1560\u001b[0m         \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1562\u001b[0;31m         outputs = self.bert(\n\u001b[0m\u001b[1;32m   1563\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    972\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"You have to specify either input_ids or inputs_embeds\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    973\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 974\u001b[0;31m         \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    975\u001b[0m         \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0minput_ids\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0minputs_embeds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#metrics = compute_metrics(test_prediction_info)\n",
        "#print(test_prediction_info)\n",
        "test_prediction_info = trainer.predict(val_dataset)\n",
        "test_prediction_info.label_ids.shape\n",
        "test_prediction_info.predictions[0],test_prediction_info.label_ids[0]"
      ],
      "metadata": {
        "id": "YOTBKyU1s-i1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_data['emotions'][3200]"
      ],
      "metadata": {
        "id": "0chv6R9ctHFl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PJ9XJj7DqQCe"
      },
      "source": [
        "### Nalin's scribbles below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-12T18:29:29.101779Z",
          "iopub.status.idle": "2024-01-12T18:29:29.102100Z",
          "shell.execute_reply": "2024-01-12T18:29:29.101953Z",
          "shell.execute_reply.started": "2024-01-12T18:29:29.101937Z"
        },
        "id": "006vgUiREp2_",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import f1_score\n",
        "import numpy as np\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    # Apply sigmoid to logits and threshold to get multi-label predictions\n",
        "    sigmoid_logits = 1 / (1 + np.exp(-logits))  # Sigmoid function\n",
        "    threshold = 0.5\n",
        "    predictions = (sigmoid_logits > threshold).astype(int)\n",
        "\n",
        "    # Calculate F1 score for each individual label/class\n",
        "    f1_scores = [f1_score(labels[:, i], predictions[:, i], average='binary') for i in range(num_labels)]\n",
        "\n",
        "    # Sequence F1: compute the F1-score for each dialogue and report the average score\n",
        "    sequence_f1 = np.mean(f1_scores)\n",
        "\n",
        "    # Unrolled Sequence F1: flatten all utterances and compute the F1-score\n",
        "    unrolled_labels = labels.flatten()\n",
        "    unrolled_predictions = predictions.flatten()\n",
        "    unrolled_sequence_f1 = f1_score(unrolled_labels, unrolled_predictions, average='binary')\n",
        "\n",
        "    return {\n",
        "        'sequence_f1': sequence_f1,\n",
        "        'unrolled_sequence_f1': unrolled_sequence_f1\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-12T18:29:29.103311Z",
          "iopub.status.idle": "2024-01-12T18:29:29.103686Z",
          "shell.execute_reply": "2024-01-12T18:29:29.103508Z",
          "shell.execute_reply.started": "2024-01-12T18:29:29.103491Z"
        },
        "id": "p6R1HFVT_UYS",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from datasets import Dataset\n",
        "import torch\n",
        "\n",
        "emotions = df['emotions'].explode().unique()\n",
        "num_labels = len(emotions)\n",
        "# Initialize the tokenizer\n",
        "model_card = 'bert-base-uncased'\n",
        "tokenizer = BertTokenizer.from_pretrained(model_card)\n",
        "\n",
        "# Initialize MultiLabelBinarizer for emotions\n",
        "mlb = MultiLabelBinarizer()\n",
        "mlb.fit(train_data['emotions'])\n",
        "\n",
        "def preprocess_data(data, tokenizer, mlb):\n",
        "    # Tokenize the utterances\n",
        "    tokenized_inputs = tokenizer(\n",
        "        [\" \".join(utterance) for utterance in data['utterances']],\n",
        "        padding='max_length',\n",
        "        truncation=True,\n",
        "        max_length=128, # we might wanna change this to max_len !\n",
        "        return_tensors='pt'\n",
        "    )\n",
        "\n",
        "    # Encode the emotions\n",
        "    encoded_labels = mlb.transform(data['emotions'])\n",
        "    # Convert labels to tensors\n",
        "    labels_tensor = torch.tensor(encoded_labels, dtype=torch.float)\n",
        "    # Ensure the encoded labels are the correct shape (this step is crucial to avoid the batch size mismatch)\n",
        "    if labels_tensor.shape[0] != tokenized_inputs['input_ids'].shape[0]:\n",
        "        raise ValueError(f\"Number of examples {tokenized_inputs['input_ids'].shape[0]} does not match number of labels {labels_tensor.shape[0]}\")\n",
        "\n",
        "    return Dataset.from_dict({\n",
        "        'input_ids': tokenized_inputs['input_ids'],\n",
        "        'attention_mask': tokenized_inputs['attention_mask'],\n",
        "        'labels': labels_tensor\n",
        "    })\n",
        "\n",
        "# Now call preprocess_data to process your train and validation data\n",
        "train_dataset = preprocess_data(train_data, tokenizer, mlb)\n",
        "val_dataset = preprocess_data(val_data, tokenizer, mlb)\n",
        "\n",
        "print(\"Single train example:\", train_dataset[0])\n",
        "print(\"Single validation example:\",val_dataset[0])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_dataset['input_ids'][0]"
      ],
      "metadata": {
        "id": "S4pFIyCSp9kd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-12T18:29:29.105207Z",
          "iopub.status.idle": "2024-01-12T18:29:29.105538Z",
          "shell.execute_reply": "2024-01-12T18:29:29.105392Z",
          "shell.execute_reply.started": "2024-01-12T18:29:29.105378Z"
        },
        "trusted": true,
        "id": "CVLkqwTGDn1P"
      },
      "outputs": [],
      "source": [
        "# Define training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    num_train_epochs=1,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=64,\n",
        "    warmup_steps=500,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=10,\n",
        "    evaluation_strategy = \"epoch\"\n",
        ")\n",
        "\n",
        "# Initialize the model with the number of emotion labels\n",
        "num_labels = len(mlb.classes_)\n",
        "model = BertForSequenceClassification.from_pretrained(model_card, num_labels=num_labels)\n",
        "# Freeze the BERT embedding layer weights\n",
        "for name, param in model.named_parameters():\n",
        "    if 'classifier' not in name: # Layer names not containing 'classifier' will be frozen\n",
        "        param.requires_grad = False\n",
        "\n",
        "# Initialize the Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    compute_metrics = compute_metrics\n",
        ")\n",
        "# Train the model\n",
        "trainer.train()\n",
        "# Train the model\n",
        "trainer.train()\n",
        "results = trainer.evaluate()\n",
        "\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_prediction_info = trainer.predict(val_dataset)\n",
        "#metrics = compute_metrics(test_prediction_info)\n",
        "#print(test_prediction_info)\n",
        "test_prediction_info.predictions[0],test_prediction_info.label_ids[0]"
      ],
      "metadata": {
        "id": "INbj8lLHhH-e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L-LN0VtFJ19_"
      },
      "source": [
        "## For two classifier heads, one common model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-12T18:29:29.106729Z",
          "iopub.status.idle": "2024-01-12T18:29:29.107060Z",
          "shell.execute_reply": "2024-01-12T18:29:29.106915Z",
          "shell.execute_reply.started": "2024-01-12T18:29:29.106900Z"
        },
        "id": "ePRUH-k7Yg57",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "!pip install datasets==2.13.2\n",
        "!pip install accelerate -U"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-12T18:29:29.108963Z",
          "iopub.status.idle": "2024-01-12T18:29:29.109272Z",
          "shell.execute_reply": "2024-01-12T18:29:29.109134Z",
          "shell.execute_reply.started": "2024-01-12T18:29:29.109119Z"
        },
        "id": "bTfpfqKOJz-d",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from transformers import BertPreTrainedModel, BertModel\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
        "from torch.nn import BCEWithLogitsLoss, Linear\n",
        "import torch\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from datasets import Dataset\n",
        "\n",
        "class BertForMultiLabelSequenceClassification(BertPreTrainedModel):\n",
        "    def __init__(self, config, num_labels_emotions, num_labels_triggers):\n",
        "        super().__init__(config)\n",
        "        self.num_labels_emotions = num_labels_emotions\n",
        "        self.num_labels_triggers = num_labels_triggers\n",
        "\n",
        "        self.bert = BertModel(config)\n",
        "        self.classifier_emotions = Linear(config.hidden_size, num_labels_emotions)\n",
        "        self.classifier_triggers = Linear(config.hidden_size, num_labels_triggers)\n",
        "\n",
        "        # You can initialize weights here if needed\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        input_ids=None,\n",
        "        attention_mask=None,\n",
        "        token_type_ids=None,\n",
        "        labels_emotions=None,\n",
        "        labels_triggers=None,\n",
        "        return_dict=None,\n",
        "    ):\n",
        "        outputs = self.bert(\n",
        "            input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            token_type_ids=token_type_ids\n",
        "        )\n",
        "\n",
        "        pooled_output = outputs[1]\n",
        "\n",
        "        logits_emotions = self.classifier_emotions(pooled_output)\n",
        "        logits_triggers = self.classifier_triggers(pooled_output)\n",
        "\n",
        "        loss = None\n",
        "        # Calculate loss only if both labels are provided\n",
        "        if labels_emotions is not None and labels_triggers is not None:\n",
        "            loss_fct = BCEWithLogitsLoss()\n",
        "            loss_emotions = loss_fct(logits_emotions.view(-1, self.num_labels_emotions), labels_emotions.view(-1))\n",
        "            loss_triggers = loss_fct(logits_triggers.view(-1, self.num_labels_triggers), labels_triggers.view(-1))\n",
        "            loss = loss_emotions + loss_triggers\n",
        "\n",
        "        # Adjust the return statement to match what your compute_loss method expects\n",
        "        if not return_dict:\n",
        "            outputs = (logits_emotions, logits_triggers)\n",
        "            if loss is not None:\n",
        "                outputs = (loss,) + outputs\n",
        "        else:\n",
        "            outputs = {'loss': loss, 'logits_emotions': logits_emotions, 'logits_triggers': logits_triggers}\n",
        "\n",
        "        return outputs\n",
        "        \"\"\"\n",
        "        if not return_dict:\n",
        "            print(f\"Logits Emotions: {logits_emotions.shape}, Logits Triggers: {logits_triggers.shape}\")\n",
        "            output = (logits_emotions, logits_triggers) if loss is None else (loss, logits_emotions, logits_triggers)\n",
        "            return (loss, logits_emotions, logits_triggers) if loss is not None else (logits_emotions, logits_triggers)\n",
        "        else:\n",
        "            raise NotImplementedError(\"return_dict is set to True, but this model does not support it.\")\n",
        "            \"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-12T18:29:29.110848Z",
          "iopub.status.idle": "2024-01-12T18:29:29.111189Z",
          "shell.execute_reply": "2024-01-12T18:29:29.111035Z",
          "shell.execute_reply.started": "2024-01-12T18:29:29.111019Z"
        },
        "id": "3hijFGmeMkAE",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Initialize MultiLabelBinarizers\n",
        "mlb_emotions = MultiLabelBinarizer()\n",
        "mlb_triggers = MultiLabelBinarizer()\n",
        "mlb_emotions.fit(train_data['emotions'])\n",
        "mlb_triggers.fit(train_data['triggers'])\n",
        "\n",
        "# Initialize the tokenizer\n",
        "model_card = 'bert-base-uncased'\n",
        "tokenizer = BertTokenizer.from_pretrained(model_card)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-12T18:29:29.112750Z",
          "iopub.status.idle": "2024-01-12T18:29:29.113189Z",
          "shell.execute_reply": "2024-01-12T18:29:29.112978Z",
          "shell.execute_reply.started": "2024-01-12T18:29:29.112958Z"
        },
        "id": "zuvufmF0mieE",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def preprocess_data(data, tokenizer, mlb_emotions, mlb_triggers):\n",
        "    tokenized_inputs = tokenizer(\n",
        "      [\" \".join(utterance) for utterance in data['utterances']],\n",
        "      padding='max_length',\n",
        "      truncation=True,\n",
        "      max_length=128,\n",
        "      return_tensors='pt'\n",
        "    )\n",
        "\n",
        "    # Encode the emotions and triggers\n",
        "    encoded_labels_emotions = mlb_emotions.transform(data['emotions'])\n",
        "    encoded_labels_triggers = mlb_triggers.transform(data['triggers'])\n",
        "\n",
        "    # Convert labels to tensors and reshape\n",
        "    labels_emotions = torch.tensor(encoded_labels_emotions, dtype=torch.float).view(-1, mlb_emotions.classes_.size)\n",
        "    labels_triggers = torch.tensor(encoded_labels_triggers, dtype=torch.float).view(-1, mlb_triggers.classes_.size)\n",
        "\n",
        "    return Dataset.from_dict({\n",
        "        'input_ids': tokenized_inputs['input_ids'],\n",
        "        'attention_mask': tokenized_inputs['attention_mask'],\n",
        "        'labels_emotions': labels_emotions,\n",
        "        'labels_triggers': labels_triggers\n",
        "    })\n",
        "\n",
        "# Then preprocess the training and validation data\n",
        "train_dataset = preprocess_data(train_data, tokenizer, mlb_emotions, mlb_triggers)\n",
        "val_dataset = preprocess_data(val_data, tokenizer, mlb_emotions, mlb_triggers)\n",
        "\n",
        "print(\"Single train example:\", train_dataset[0])\n",
        "print(\"Single validation example:\",val_dataset[0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-12T18:29:29.114740Z",
          "iopub.status.idle": "2024-01-12T18:29:29.115104Z",
          "shell.execute_reply": "2024-01-12T18:29:29.114945Z",
          "shell.execute_reply.started": "2024-01-12T18:29:29.114928Z"
        },
        "id": "bRKm76SLUkZt",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# Define your compute_metrics function to handle both sets of labels\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    logits_emotions = logits[0]\n",
        "    logits_triggers = logits[1]\n",
        "    labels_emotions = labels[0]\n",
        "    labels_triggers = labels[1]\n",
        "    # Sigmoid function to convert logits to probabilities\n",
        "    sigmoid = lambda x: 1 / (1 + np.exp(-x))\n",
        "    # Threshold to convert probabilities to binary predictions\n",
        "    threshold = 0.5\n",
        "\n",
        "    # Convert logits to probabilities\n",
        "    probs_emotions = sigmoid(logits_emotions)\n",
        "    probs_triggers = sigmoid(logits_triggers)\n",
        "\n",
        "    # Convert probabilities to binary predictions\n",
        "    preds_emotions = (probs_emotions > threshold).astype(int)\n",
        "    preds_triggers = (probs_triggers > threshold).astype(int)\n",
        "\n",
        "    # Calculate the f1-score for emotions\n",
        "    f1_emotions = f1_score(labels_emotions, preds_emotions, average='macro')\n",
        "    # Calculate the f1-score for triggers\n",
        "    f1_triggers = f1_score(labels_triggers, preds_triggers, average='macro')\n",
        "\n",
        "    # To calculate sequence-level metrics, we might need to modify data processing\n",
        "\n",
        "    # to include sequence IDs, and then group by sequence ID before calculating metrics.\n",
        "    return {\n",
        "        'f1_emotions': f1_emotions,\n",
        "        'f1_triggers': f1_triggers,\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-12T18:29:29.116605Z",
          "iopub.status.idle": "2024-01-12T18:29:29.116946Z",
          "shell.execute_reply": "2024-01-12T18:29:29.116806Z",
          "shell.execute_reply.started": "2024-01-12T18:29:29.116790Z"
        },
        "id": "w_IrhqCwnYw5",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "#TODO make this compatible with model class by changing the way the absence of loss is handled, similar to CustomTrainer4\n",
        "\n",
        "class CustomTrainer(Trainer):\n",
        "    def compute_loss(self, model, inputs, return_outputs=False):\n",
        "        # Unpack inputs\n",
        "        labels_emotions = inputs.pop(\"labels_emotions\", None)\n",
        "        labels_triggers = inputs.pop(\"labels_triggers\", None)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(**inputs)\n",
        "\n",
        "        # If loss is not included in outputs, calculate it using the logits\n",
        "        if len(outputs) == 2:\n",
        "            logits_emotions, logits_triggers = outputs\n",
        "            loss_fct = BCEWithLogitsLoss()\n",
        "            if labels_emotions is not None and labels_triggers is not None:\n",
        "                loss_emotions = loss_fct(logits_emotions.view(-1, self.model.num_labels_emotions), labels_emotions.view(-1, self.model.num_labels_emotions))\n",
        "                loss_triggers = loss_fct(logits_triggers.view(-1, self.model.num_labels_triggers), labels_triggers.view(-1, self.model.num_labels_triggers))\n",
        "                loss = loss_emotions + loss_triggers\n",
        "        elif len(outputs) == 3:\n",
        "            # Outputs include a loss\n",
        "            loss, logits_emotions, logits_triggers = outputs\n",
        "        else:\n",
        "            raise ValueError(f\"Unexpected number of outputs from model: {len(outputs)}\")\n",
        "\n",
        "        # If loss was not computed within the model, we compute it based on the logits and the labels\n",
        "        if loss is None and labels_emotions is not None and labels_triggers is not None:\n",
        "            loss_fct = BCEWithLogitsLoss()\n",
        "            loss_emotions = loss_fct(logits_emotions.view(-1, self.model.num_labels_emotions), labels_emotions.view(-1))\n",
        "            loss_triggers = loss_fct(logits_triggers.view(-1, self.model.num_labels_triggers), labels_triggers.view(-1))\n",
        "            loss = loss_emotions + loss_triggers\n",
        "\n",
        "        return (loss, outputs) if return_outputs else loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-12T18:29:29.117887Z",
          "iopub.status.idle": "2024-01-12T18:29:29.118226Z",
          "shell.execute_reply": "2024-01-12T18:29:29.118081Z",
          "shell.execute_reply.started": "2024-01-12T18:29:29.118065Z"
        },
        "id": "4-kDAr-dj54R",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "class CustomTrainer4(Trainer):\n",
        "    def compute_loss(self, model, inputs, return_outputs=False):\n",
        "        # Unpack inputs\n",
        "        labels_emotions = inputs.pop(\"labels_emotions\", None)\n",
        "        labels_triggers = inputs.pop(\"labels_triggers\", None)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(**inputs)\n",
        "\n",
        "        # If loss is not included in outputs, calculate it using the logits\n",
        "        if 'loss' not in outputs:\n",
        "            logits_emotions = outputs['logits_emotions']\n",
        "            logits_triggers = outputs['logits_triggers']\n",
        "            loss_fct = BCEWithLogitsLoss()\n",
        "            if labels_emotions is not None:\n",
        "                loss_emotions = loss_fct(logits_emotions.view(-1, self.model.num_labels_emotions), labels_emotions.view(-1))\n",
        "            if labels_triggers is not None:\n",
        "                loss_triggers = loss_fct(logits_triggers.view(-1, self.model.num_labels_triggers), labels_triggers.view(-1))\n",
        "            loss = loss_emotions + loss_triggers\n",
        "            outputs['loss'] = loss\n",
        "        else:\n",
        "            # Loss is included in outputs\n",
        "            loss = outputs['loss']\n",
        "\n",
        "        return (loss, outputs) if return_outputs else loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-12T18:29:29.119377Z",
          "iopub.status.idle": "2024-01-12T18:29:29.119738Z",
          "shell.execute_reply": "2024-01-12T18:29:29.119559Z",
          "shell.execute_reply.started": "2024-01-12T18:29:29.119543Z"
        },
        "id": "_tE4h1L9MzY0",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Initialize model with the number of emotion and trigger labels\n",
        "num_labels_emotions = len(mlb_emotions.classes_)\n",
        "num_labels_triggers = len(mlb_triggers.classes_)\n",
        "model = BertForMultiLabelSequenceClassification.from_pretrained(\n",
        "    model_card,\n",
        "    num_labels_emotions=num_labels_emotions,\n",
        "    num_labels_triggers=num_labels_triggers\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-12T18:29:29.121255Z",
          "iopub.status.idle": "2024-01-12T18:29:29.121597Z",
          "shell.execute_reply": "2024-01-12T18:29:29.121442Z",
          "shell.execute_reply.started": "2024-01-12T18:29:29.121426Z"
        },
        "id": "KzER6NeRe3s0",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-12T18:29:29.123103Z",
          "iopub.status.idle": "2024-01-12T18:29:29.123443Z",
          "shell.execute_reply": "2024-01-12T18:29:29.123288Z",
          "shell.execute_reply.started": "2024-01-12T18:29:29.123272Z"
        },
        "id": "zMKcMdBeQnHx",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Assuming train_dataset is a Hugging Face dataset with the correct columns\n",
        "example = train_dataset[0]\n",
        "\n",
        "# Now, before passing tensors to the model, ensure they are also on the same device\n",
        "example_tensors = {k: torch.tensor([v]).to(device) for k, v in example.items()}\n",
        "\n",
        "# Call the model\n",
        "with torch.no_grad():\n",
        "    outputs = model(**example_tensors)\n",
        "    print(outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-12T18:29:29.124452Z",
          "iopub.status.idle": "2024-01-12T18:29:29.124807Z",
          "shell.execute_reply": "2024-01-12T18:29:29.124624Z",
          "shell.execute_reply.started": "2024-01-12T18:29:29.124609Z"
        },
        "id": "BcckkL0ILyll",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Define training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    num_train_epochs=5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=64,\n",
        "    warmup_steps=500,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=10,\n",
        "    evaluation_strategy = \"epoch\"\n",
        "    report_to = \"\"\n",
        ")\n",
        "\n",
        "# # Initialize the model with the number of emotion labels\n",
        "# num_labels = len(mlb.classes_)\n",
        "# model = BertForSequenceClassification.from_pretrained(model_card,\n",
        "#                                                       num_labels=num_labels,\n",
        "#                                                        )\n",
        "\n",
        "# Freeze the BERT embedding layer weights\n",
        "for name, param in model.named_parameters():\n",
        "    if 'classifier' not in name: # Layer names not containing 'classifier' will be frozen\n",
        "        param.requires_grad = False\n",
        "\n",
        "# Initialize the Trainer\n",
        "trainer = CustomTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    compute_metrics = compute_metrics\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "trainer.train()\n",
        "results = trainer.evaluate()\n",
        "\n",
        "print(results)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5dB6fTqFKCM_"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "datasetId": 4296178,
          "sourceId": 7390484,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30636,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}