{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RgHMqcneDn1J"
      },
      "source": [
        "- We loose structure of dialogue using the tokenizer in preprocess_data\n",
        "\n",
        "- Emotions encoded using MultiLabelBinarizer doesn't tell us\n",
        "  anymore how many times a single emotion is present in the dialogue\n",
        "  and where it is"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 152,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2024-01-12T18:25:52.423261Z",
          "iopub.status.busy": "2024-01-12T18:25:52.422488Z",
          "iopub.status.idle": "2024-01-12T18:29:06.936875Z",
          "shell.execute_reply": "2024-01-12T18:29:06.935874Z",
          "shell.execute_reply.started": "2024-01-12T18:25:52.423224Z"
        },
        "id": "vc-YdlGVyh9_",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "e624115d-acee-4553-8837-fb9cf4b04870",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: accelerate in /Users/antoniospantelis/anaconda3/lib/python3.11/site-packages (0.26.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /Users/antoniospantelis/anaconda3/lib/python3.11/site-packages (from accelerate) (1.24.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /Users/antoniospantelis/anaconda3/lib/python3.11/site-packages (from accelerate) (23.1)\n",
            "Requirement already satisfied: psutil in /Users/antoniospantelis/anaconda3/lib/python3.11/site-packages (from accelerate) (5.9.0)\n",
            "Requirement already satisfied: pyyaml in /Users/antoniospantelis/anaconda3/lib/python3.11/site-packages (from accelerate) (6.0)\n",
            "Requirement already satisfied: torch>=1.10.0 in /Users/antoniospantelis/anaconda3/lib/python3.11/site-packages (from accelerate) (2.1.2)\n",
            "Requirement already satisfied: huggingface-hub in /Users/antoniospantelis/anaconda3/lib/python3.11/site-packages (from accelerate) (0.19.4)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /Users/antoniospantelis/anaconda3/lib/python3.11/site-packages (from accelerate) (0.3.2)\n",
            "Requirement already satisfied: filelock in /Users/antoniospantelis/anaconda3/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (3.9.0)\n",
            "Requirement already satisfied: typing-extensions in /Users/antoniospantelis/anaconda3/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (4.7.1)\n",
            "Requirement already satisfied: sympy in /Users/antoniospantelis/anaconda3/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (1.11.1)\n",
            "Requirement already satisfied: networkx in /Users/antoniospantelis/anaconda3/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (3.1)\n",
            "Requirement already satisfied: jinja2 in /Users/antoniospantelis/anaconda3/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /Users/antoniospantelis/anaconda3/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (2023.10.0)\n",
            "Requirement already satisfied: requests in /Users/antoniospantelis/anaconda3/lib/python3.11/site-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /Users/antoniospantelis/anaconda3/lib/python3.11/site-packages (from huggingface-hub->accelerate) (4.65.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /Users/antoniospantelis/anaconda3/lib/python3.11/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/antoniospantelis/anaconda3/lib/python3.11/site-packages (from requests->huggingface-hub->accelerate) (2.0.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/antoniospantelis/anaconda3/lib/python3.11/site-packages (from requests->huggingface-hub->accelerate) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/antoniospantelis/anaconda3/lib/python3.11/site-packages (from requests->huggingface-hub->accelerate) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/antoniospantelis/anaconda3/lib/python3.11/site-packages (from requests->huggingface-hub->accelerate) (2023.11.17)\n",
            "Requirement already satisfied: mpmath>=0.19 in /Users/antoniospantelis/anaconda3/lib/python3.11/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "!pip install torch==1.13.0+cu116 --extra-index-url https://download.pytorch.org/whl/cu116\n",
        "!pip install transformers==4.30.0\n",
        "!pip install datasets==2.13.2\n",
        "!pip install evaluate\n",
        "\"\"\"\n",
        "!pip install accelerate -U"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 153,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-01-12T18:29:06.939068Z",
          "iopub.status.busy": "2024-01-12T18:29:06.938752Z",
          "iopub.status.idle": "2024-01-12T18:29:27.003689Z",
          "shell.execute_reply": "2024-01-12T18:29:27.002668Z",
          "shell.execute_reply.started": "2024-01-12T18:29:06.939042Z"
        },
        "id": "pD7fWLEPyh-B",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# system packages\n",
        "from pathlib import Path\n",
        "import shutil\n",
        "import urllib\n",
        "import tarfile\n",
        "import sys\n",
        "import os\n",
        "# data and numerical management packages\n",
        "import pandas as pd\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "# useful during debugging (progress bars)\n",
        "from tqdm import tqdm\n",
        "from transformers import set_seed\n",
        "\n",
        "seed = 852\n",
        "\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "set_seed(seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 154,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-01-12T18:29:27.005734Z",
          "iopub.status.busy": "2024-01-12T18:29:27.004994Z",
          "iopub.status.idle": "2024-01-12T18:29:27.161176Z",
          "shell.execute_reply": "2024-01-12T18:29:27.160394Z",
          "shell.execute_reply.started": "2024-01-12T18:29:27.005698Z"
        },
        "id": "6Vnl6q1Qyh-C",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "dataset_folder = Path.cwd().joinpath(\"Datasets\")\n",
        "dataset_path = dataset_folder.joinpath('MELD_train_efr.json')\n",
        "\n",
        "df = pd.read_json(dataset_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 155,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 597
        },
        "id": "oq9_ohFH3yeX",
        "outputId": "e2f2accf-19b7-440b-d0b2-0c8ba04893f7"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>episode</th>\n",
              "      <th>speakers</th>\n",
              "      <th>emotions</th>\n",
              "      <th>utterances</th>\n",
              "      <th>triggers</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>utterance_0</td>\n",
              "      <td>[Chandler, The Interviewer, Chandler, The Inte...</td>\n",
              "      <td>[neutral, neutral, neutral, neutral, surprise]</td>\n",
              "      <td>[also I was the point person on my company's t...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 1.0, 0.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>utterance_1</td>\n",
              "      <td>[Chandler, The Interviewer, Chandler, The Inte...</td>\n",
              "      <td>[neutral, neutral, neutral, neutral, surprise,...</td>\n",
              "      <td>[also I was the point person on my company's t...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>utterance_2</td>\n",
              "      <td>[Chandler, The Interviewer, Chandler, The Inte...</td>\n",
              "      <td>[neutral, neutral, neutral, neutral, surprise,...</td>\n",
              "      <td>[also I was the point person on my company's t...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>utterance_3</td>\n",
              "      <td>[Chandler, The Interviewer, Chandler, The Inte...</td>\n",
              "      <td>[neutral, neutral, neutral, neutral, surprise,...</td>\n",
              "      <td>[also I was the point person on my company's t...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>utterance_4</td>\n",
              "      <td>[Joey, Rachel, Joey, Rachel]</td>\n",
              "      <td>[surprise, sadness, surprise, fear]</td>\n",
              "      <td>[But then who? The waitress I went out with la...</td>\n",
              "      <td>[0.0, 0.0, 1.0, 0.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3995</th>\n",
              "      <td>utterance_3995</td>\n",
              "      <td>[Chandler, All, Monica, Chandler, Ross, Chandl...</td>\n",
              "      <td>[neutral, joy, neutral, neutral, surprise, dis...</td>\n",
              "      <td>[Hey., Hey!, So how was Joan?, I broke up with...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3996</th>\n",
              "      <td>utterance_3996</td>\n",
              "      <td>[Chandler, All, Monica, Chandler, Ross, Chandl...</td>\n",
              "      <td>[neutral, joy, neutral, neutral, surprise, dis...</td>\n",
              "      <td>[Hey., Hey!, So how was Joan?, I broke up with...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3997</th>\n",
              "      <td>utterance_3997</td>\n",
              "      <td>[Chandler, All, Monica, Chandler, Ross, Chandl...</td>\n",
              "      <td>[neutral, joy, neutral, neutral, surprise, dis...</td>\n",
              "      <td>[Hey., Hey!, So how was Joan?, I broke up with...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3998</th>\n",
              "      <td>utterance_3998</td>\n",
              "      <td>[Chandler, All, Monica, Chandler, Ross, Chandl...</td>\n",
              "      <td>[neutral, joy, neutral, neutral, surprise, dis...</td>\n",
              "      <td>[Hey., Hey!, So how was Joan?, I broke up with...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3999</th>\n",
              "      <td>utterance_3999</td>\n",
              "      <td>[Chandler, All, Monica, Chandler, Ross, Chandl...</td>\n",
              "      <td>[neutral, joy, neutral, neutral, surprise, dis...</td>\n",
              "      <td>[Hey., Hey!, So how was Joan?, I broke up with...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4000 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "             episode                                           speakers  \\\n",
              "0        utterance_0  [Chandler, The Interviewer, Chandler, The Inte...   \n",
              "1        utterance_1  [Chandler, The Interviewer, Chandler, The Inte...   \n",
              "2        utterance_2  [Chandler, The Interviewer, Chandler, The Inte...   \n",
              "3        utterance_3  [Chandler, The Interviewer, Chandler, The Inte...   \n",
              "4        utterance_4                       [Joey, Rachel, Joey, Rachel]   \n",
              "...              ...                                                ...   \n",
              "3995  utterance_3995  [Chandler, All, Monica, Chandler, Ross, Chandl...   \n",
              "3996  utterance_3996  [Chandler, All, Monica, Chandler, Ross, Chandl...   \n",
              "3997  utterance_3997  [Chandler, All, Monica, Chandler, Ross, Chandl...   \n",
              "3998  utterance_3998  [Chandler, All, Monica, Chandler, Ross, Chandl...   \n",
              "3999  utterance_3999  [Chandler, All, Monica, Chandler, Ross, Chandl...   \n",
              "\n",
              "                                               emotions  \\\n",
              "0        [neutral, neutral, neutral, neutral, surprise]   \n",
              "1     [neutral, neutral, neutral, neutral, surprise,...   \n",
              "2     [neutral, neutral, neutral, neutral, surprise,...   \n",
              "3     [neutral, neutral, neutral, neutral, surprise,...   \n",
              "4                   [surprise, sadness, surprise, fear]   \n",
              "...                                                 ...   \n",
              "3995  [neutral, joy, neutral, neutral, surprise, dis...   \n",
              "3996  [neutral, joy, neutral, neutral, surprise, dis...   \n",
              "3997  [neutral, joy, neutral, neutral, surprise, dis...   \n",
              "3998  [neutral, joy, neutral, neutral, surprise, dis...   \n",
              "3999  [neutral, joy, neutral, neutral, surprise, dis...   \n",
              "\n",
              "                                             utterances  \\\n",
              "0     [also I was the point person on my company's t...   \n",
              "1     [also I was the point person on my company's t...   \n",
              "2     [also I was the point person on my company's t...   \n",
              "3     [also I was the point person on my company's t...   \n",
              "4     [But then who? The waitress I went out with la...   \n",
              "...                                                 ...   \n",
              "3995  [Hey., Hey!, So how was Joan?, I broke up with...   \n",
              "3996  [Hey., Hey!, So how was Joan?, I broke up with...   \n",
              "3997  [Hey., Hey!, So how was Joan?, I broke up with...   \n",
              "3998  [Hey., Hey!, So how was Joan?, I broke up with...   \n",
              "3999  [Hey., Hey!, So how was Joan?, I broke up with...   \n",
              "\n",
              "                                               triggers  \n",
              "0                             [0.0, 0.0, 0.0, 1.0, 0.0]  \n",
              "1                   [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]  \n",
              "2     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...  \n",
              "3     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
              "4                                  [0.0, 0.0, 1.0, 0.0]  \n",
              "...                                                 ...  \n",
              "3995  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
              "3996  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
              "3997  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
              "3998  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
              "3999  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
              "\n",
              "[4000 rows x 5 columns]"
            ]
          },
          "execution_count": 155,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 156,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-01-12T18:29:27.164488Z",
          "iopub.status.busy": "2024-01-12T18:29:27.164068Z",
          "iopub.status.idle": "2024-01-12T18:29:27.353387Z",
          "shell.execute_reply": "2024-01-12T18:29:27.352697Z",
          "shell.execute_reply.started": "2024-01-12T18:29:27.164451Z"
        },
        "id": "PK4MQkLvyh-C",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "triggers = df['triggers']\n",
        "for row in range(triggers.shape[0]):\n",
        "    for trigger in range(len(triggers[row])):\n",
        "        if triggers[row][trigger] == None:\n",
        "            triggers[row][trigger] = 0.0\n",
        "\n",
        "df['triggers'] = triggers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 157,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-01-12T18:29:27.354645Z",
          "iopub.status.busy": "2024-01-12T18:29:27.354368Z",
          "iopub.status.idle": "2024-01-12T18:29:27.374027Z",
          "shell.execute_reply": "2024-01-12T18:29:27.373203Z",
          "shell.execute_reply.started": "2024-01-12T18:29:27.354621Z"
        },
        "id": "QFfykazN2xDw",
        "outputId": "862c56ba-fff9-4500-a761-b5a13edf0d91",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['neutral', 'surprise', 'fear', 'sadness', 'joy', 'disgust',\n",
              "       'anger'], dtype=object)"
            ]
          },
          "execution_count": 157,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "emotions = df['emotions'].explode().unique()\n",
        "emotions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 158,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-01-12T18:29:27.375319Z",
          "iopub.status.busy": "2024-01-12T18:29:27.375078Z",
          "iopub.status.idle": "2024-01-12T18:29:27.390235Z",
          "shell.execute_reply": "2024-01-12T18:29:27.389245Z",
          "shell.execute_reply.started": "2024-01-12T18:29:27.375298Z"
        },
        "id": "p10v1luzDn1M",
        "outputId": "fcbbdd4f-8320-40e8-cbbb-18b424217a6d",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0.0, 1.0], dtype=object)"
            ]
          },
          "execution_count": 158,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "triggers = df['triggers'].explode().unique()\n",
        "triggers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 159,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-01-12T18:29:27.392361Z",
          "iopub.status.busy": "2024-01-12T18:29:27.391490Z",
          "iopub.status.idle": "2024-01-12T18:29:27.412862Z",
          "shell.execute_reply": "2024-01-12T18:29:27.411917Z",
          "shell.execute_reply.started": "2024-01-12T18:29:27.392329Z"
        },
        "id": "q39q6ZPh-tCy",
        "outputId": "f6b48818-5079-4e6b-cdcb-01da074fdf25",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(24, 219)"
            ]
          },
          "execution_count": 159,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dialogues = df['utterances']\n",
        "#print(sentences)\n",
        "max_len_dialogue = 0\n",
        "index = 0\n",
        "for idx, dialogue in enumerate(dialogues):\n",
        "  if len(dialogue) > max_len_dialogue:\n",
        "    max_len_dialogue = len(dialogue)\n",
        "    index = idx\n",
        "max_len_dialogue,index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 160,
      "metadata": {
        "id": "H6K5IJ0-NLlL"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelBinarizer\n",
        "sorted_emotions = sorted(emotions)  #sort the array because Binarizer will automatically do that for one hot encoding\n",
        "label_binarizer = LabelBinarizer()\n",
        "label_binarizer.fit(sorted_emotions)\n",
        "\n",
        "dialogues = df['emotions']\n",
        "one_hot_emotions = []\n",
        "for dialogue_emotion in dialogues:\n",
        "  dialogue_emotions_list = []\n",
        "  for emotion in dialogue_emotion:\n",
        "    encoded_emotion=label_binarizer.transform([emotion])\n",
        "    dialogue_emotions_list.append(np.ravel(encoded_emotion).tolist())\n",
        "  one_hot_emotions.append(dialogue_emotions_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 161,
      "metadata": {
        "id": "fNaWF4KIgIys"
      },
      "outputs": [],
      "source": [
        "df['emotions'] = one_hot_emotions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 162,
      "metadata": {
        "id": "ALZyV8V-kk5k"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_data, temp_data = train_test_split(df, train_size=0.8, shuffle=False)\n",
        "val_data, test_data = train_test_split(temp_data, test_size=0.5, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 163,
      "metadata": {
        "id": "_-uiT5rdGAE9"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import Trainer, TrainingArguments\n",
        "\n",
        "class CustomDataCollator:\n",
        "    def __init__(self, tokenizer, counter=0):\n",
        "        self.tokenizer = tokenizer\n",
        "        # self.max_length = max_length\n",
        "\n",
        "    def __call__(self, examples, index=None):\n",
        "        if index is not None:\n",
        "            example = examples[index]\n",
        "            input_ids = example['input_ids'].squeeze()\n",
        "            attention_mask = example['attention_mask'].squeeze()\n",
        "            emotion_labels = example['emotion_labels'].squeeze()\n",
        "            trigger_label = example['trigger_label'].squeeze()\n",
        "        else:\n",
        "            input_ids = torch.stack([example['input_ids'].squeeze() for example in examples])\n",
        "            attention_mask = torch.stack([example['attention_mask'].squeeze() for example in examples])\n",
        "            emotion_labels = torch.stack([example['emotion_labels'].squeeze() for example in examples])\n",
        "            trigger_label = torch.stack([example['trigger_label'].squeeze() for example in examples])\n",
        "\n",
        "        return {\n",
        "            'input_ids': input_ids,\n",
        "            'attention_mask': attention_mask,\n",
        "            'emotion_labels': emotion_labels,\n",
        "            'trigger_label': trigger_label\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 164,
      "metadata": {
        "id": "HiiN1Qs9k0DM"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import BertTokenizer, BertModel, BertForSequenceClassification, AdamW, Trainer, TrainingArguments\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, dialogues, emotions, triggers, tokenizer, max_length=10):\n",
        "        self.dialogues = dialogues\n",
        "        self.emotions = emotions\n",
        "        self.triggers = triggers\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dialogues)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        dialogue = self.dialogues[idx]\n",
        "        emotion = self.emotions[idx]\n",
        "        trigger = self.triggers[idx]\n",
        "\n",
        "        input_ids_list = []\n",
        "        attention_mask_list = []\n",
        "\n",
        "        for utterance in dialogue:\n",
        "          tokenized_utterance = self.tokenizer(utterance, max_length=self.max_length, padding='max_length', truncation=True, return_tensors='pt')\n",
        "          # Extract relevant information\n",
        "          #input_ids = torch.stack([inputs['input_ids'].squeeze() for inputs in tokenized_dialogue])\n",
        "          input_ids_list.extend(tokenized_utterance['input_ids'])\n",
        "          attention_mask_list.extend(tokenized_utterance['attention_mask'])\n",
        "\n",
        "        emotion_labels = torch.tensor(emotion, dtype=torch.float32)\n",
        "        trigger_label = torch.tensor(trigger, dtype=torch.long)\n",
        "        #print('input',torch.stack(input_ids_list).shape)\n",
        "        #print('attention',torch.stack(attention_mask_list).shape)\n",
        "        #print('emotion',emotion_labels.shape)\n",
        "        #print('trigeeer',trigger_label.shape)\n",
        "        return {\n",
        "            'input_ids': torch.stack(input_ids_list),\n",
        "            'attention_mask': torch.stack(attention_mask_list),\n",
        "            'emotion_labels': emotion_labels,\n",
        "            'trigger_label': trigger_label\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 165,
      "metadata": {
        "id": "MfLGTU4Mkw3V"
      },
      "outputs": [],
      "source": [
        "class CustomBERTModel(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CustomBERTModel, self).__init__()\n",
        "        # Replace this with your custom BERT model architecture for multihead classification\n",
        "        self.bert = BertModel.from_pretrained('bert-base-uncased')#BertForSequenceClassification.from_pretrained\n",
        "        #LSTM\n",
        "        self.emotion_head = torch.nn.Linear(self.bert.config.hidden_size, len(emotions))\n",
        "        self.trigger_head = torch.nn.Linear(self.bert.config.hidden_size, len(triggers))\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        \"\"\"emotion_outputs = []\n",
        "        trigger_outputs = []\n",
        "        for utterance,attention in zip(input_ids,attention_mask):\n",
        "            outputs,random = self.bert(input_ids=utterance, attention_mask=attention,return_dict=True)\n",
        "            print('fafafawfaf')\n",
        "            pooled_output = outputs['pooler_output']\n",
        "            # Emotion head\n",
        "            emotion_logits = self.emotion_head(pooled_output)\n",
        "            emotion_outputs.append(emotion_logits)\n",
        "\n",
        "            # Trigger head\n",
        "            trigger_logits = self.trigger_head(pooled_output)\n",
        "            trigger_outputs.append(trigger_logits)\n",
        "            print('input',input_ids.shape)\n",
        "            print('utterance',utterance.shape)\n",
        "            print('pooled_output',pooled_output.shape)\n",
        "            print('emotion_logits',emotion_logits.shape)\n",
        "            print('trigger_logits',trigger_logits.shape)\n",
        "            #print('utterance',utterance)\n",
        "            #print(emotion_outputs)\"\"\"\n",
        "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask, return_dict=True)\n",
        "        pooled_output = outputs['pooler_output']\n",
        "\n",
        "        # Emotion head\n",
        "        emotion_logits = self.emotion_head(pooled_output)\n",
        "\n",
        "        # Trigger head\n",
        "        trigger_logits = self.trigger_head(pooled_output)\n",
        "        return emotion_logits, trigger_logits\n",
        "        #return emotion_outputs, trigger_outputs\n",
        "        #return torch.stack(emotion_outputs), torch.stack(trigger_outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 166,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bUR8qBNelMMl",
        "outputId": "a720cc29-6cbe-408d-90b7-cb72b5de36e5"
      },
      "outputs": [],
      "source": [
        "# Assuming train_dialogues, train_emotions, train_triggers, test_dialogues, test_emotions, test_triggers are defined\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "train_dataset = CustomDataset(train_data['utterances'], train_data['emotions'], train_data['triggers'], tokenizer)\n",
        "test_dataset = CustomDataset(val_data['utterances'], val_data['emotions'], val_data['triggers'], tokenizer)\n",
        "\n",
        "custom_Bert_Model = CustomBERTModel()\n",
        "optimizer = AdamW(custom_Bert_Model.parameters(), lr=5e-5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 167,
      "metadata": {
        "id": "OkWDocsIg6Bf"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    # Apply sigmoid to logits and threshold to get multi-label predictions\n",
        "    predicted_classes = torch.argmax(predictions, dim=1)\n",
        "    predicted_labels = torch.argmax(labels, dim=1)\n",
        "\n",
        "    # Calculate F1 score for each individual label/class\n",
        "    f1 = f1_score(predicted_labels.cpu().numpy(), predicted_classes.cpu().numpy(), average='macro')\n",
        "\n",
        "    # Convert F1 score to PyTorch tensor and make it part of the computation graph\n",
        "    f1_tensor = torch.tensor(f1, dtype=torch.float32, requires_grad=True)\n",
        "\n",
        "    return f1_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 168,
      "metadata": {},
      "outputs": [],
      "source": [
        "neutral = (1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)\n",
        "surprise =(0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0)\n",
        "fear = (0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0)\n",
        "sadness = (0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0)\n",
        "joy = (0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0)\n",
        "disgust = (0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0)\n",
        "anger = (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0)\n",
        "misclassified = (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)\n",
        "\n",
        "emotions_dictionary = {neutral : 'neutral',\n",
        "                       surprise : 'surprise',\n",
        "                       fear : 'fear',\n",
        "                       sadness : 'sadness',\n",
        "                       joy : 'joy',\n",
        "                       disgust : 'disgust',\n",
        "                       anger : 'anger',\n",
        "                       misclassified : 'misclassified'\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 169,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "id": "RiM7PzNfsHBm",
        "outputId": "2ccd0efb-ffc6-4f71-c0f9-ee885f42745c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                            "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1, Average Loss: 0.05083827520429622\n",
            "\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "num_epochs = 1\n",
        "batch_size = 1\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    custom_Bert_Model.train()\n",
        "    total_loss = 0.0\n",
        "    all_trigger_labels = []\n",
        "    all_predicted_trigger_labels = []\n",
        "    all_emotion_labels = []\n",
        "    all_predicted_emotion_labels = []\n",
        "\n",
        "    for batch in tqdm(train_loader, desc=f'Epoch {epoch + 1}', leave=False):\n",
        "        input_ids = batch['input_ids'].squeeze()\n",
        "        attention_mask = batch['attention_mask'].squeeze()\n",
        "        emotion_labels = batch['emotion_labels'].squeeze()\n",
        "        trigger_labels = batch['trigger_label'].squeeze()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        emotion_logits, trigger_logits = custom_Bert_Model(input_ids, attention_mask)\n",
        "\n",
        "        # Assuming you have defined loss functions for emotion and trigger\n",
        "        emotion_loss = compute_metrics((emotion_logits, emotion_labels))\n",
        "        # trigger_loss = your_trigger_loss_function(trigger_logits, trigger_labels)\n",
        "\n",
        "        loss = emotion_loss  # + trigger_loss\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Collect true and predicted labels for triggers and emotions\n",
        "        all_trigger_labels.extend(trigger_labels.cpu().numpy())\n",
        "        all_predicted_trigger_labels.extend(trigger_logits.argmax(dim=1).cpu().numpy())\n",
        "        all_emotion_labels.extend(emotion_labels.cpu().tolist())\n",
        "        all_predicted_emotion_labels.extend(emotion_logits.cpu().tolist())\n",
        "\n",
        "    average_loss = total_loss / len(train_loader)\n",
        "    print(f\"Epoch {epoch + 1}, Average Loss: {average_loss}\")\n",
        "    print()\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 170,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification Report for Triggers:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.80      0.82     23524\n",
            "           1       0.17      0.22      0.19      4289\n",
            "\n",
            "    accuracy                           0.71     27813\n",
            "   macro avg       0.51      0.51      0.51     27813\n",
            "weighted avg       0.74      0.71      0.73     27813\n",
            "\n",
            "\n",
            "\n",
            "Classification Report for Emotions:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "        anger       0.00      0.00      0.00    3775.0\n",
            "      disgust       0.00      0.00      0.00    1929.0\n",
            "         fear       0.00      0.00      0.00     917.0\n",
            "          joy       0.00      0.00      0.00   12228.0\n",
            "misclassified       0.00      0.00      0.00       0.0\n",
            "      neutral       0.00      0.00      0.00    3025.0\n",
            "      sadness       0.00      0.00      0.00    5123.0\n",
            "     surprise       0.00      0.00      0.00     816.0\n",
            "\n",
            "     accuracy                           0.00   27813.0\n",
            "    macro avg       0.00      0.00      0.00   27813.0\n",
            " weighted avg       0.00      0.00      0.00   27813.0\n",
            "\n"
          ]
        }
      ],
      "source": [
        "all_predicted_emotion_labels = [[torch.argmax(torch.tensor(val)).item() for val in labels] for labels in                         \n",
        "                                        all_predicted_emotion_labels]\n",
        "\n",
        "# Substitute all_emotion_labels with the corresponding emotion (probably can just simply take df['emotions'])\n",
        "for i in range(len(all_emotion_labels)):\n",
        "    all_emotion_labels_list = tuple(all_emotion_labels[i])\n",
        "    if all_emotion_labels_list in emotions_dictionary:\n",
        "        all_emotion_labels[i] = emotions_dictionary[all_emotion_labels_list]\n",
        "\n",
        "# Substitute all_predicted_emotion_labels with the correspoding emotion\n",
        "for i in range(len(all_predicted_emotion_labels)):\n",
        "    all_predicted_emotion_labels_list = tuple(all_predicted_emotion_labels[i])\n",
        "    if all_predicted_emotion_labels_list in emotions_dictionary:\n",
        "        all_predicted_emotion_labels[i] = emotions_dictionary[all_predicted_emotion_labels_list]\n",
        "\n",
        "# Print classification report for triggers\n",
        "print(\"Classification Report for Triggers:\")\n",
        "print(classification_report(all_trigger_labels, all_predicted_trigger_labels))\n",
        "print()\n",
        "print()\n",
        "\n",
        "# Print classification report for emotions\n",
        "print(\"Classification Report for Emotions:\")\n",
        "print(classification_report(all_emotion_labels, all_predicted_emotion_labels))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "datasetId": 4296178,
          "sourceId": 7390484,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30636,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
